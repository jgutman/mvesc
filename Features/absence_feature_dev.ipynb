{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, join, abspath, basename\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "parentdir = os.path.abspath('/home/xcheng/mvesc/ETL')\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "\n",
    "import inspect\n",
    "import datetime\n",
    "from itertools import chain, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pandas.tools.plotting import table\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "get_ipython().magic('matplotlib')\n",
    "from mvesc_utility_functions import *\n",
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning: what features to include\n",
    "\n",
    "1. number of absent days & unexecused absence days;\n",
    "2. number of tardy & unexecused tardy;\n",
    "3. number of consecutive absences;\n",
    "4. number of consecutive tardy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Table model.absence created!\n",
      " - updated model.absence.days_absent_gr_7 from clean.all_snapshots.days_absent for grade 7; \n",
      " - updated model.absence.days_absent_gr_8 from clean.all_snapshots.days_absent for grade 8; \n",
      " - updated model.absence.days_absent_unexcused_gr_7 from clean.all_snapshots.days_absent_unexcused for grade 7; \n",
      " - updated model.absence.days_absent_unexcused_gr_8 from clean.all_snapshots.days_absent_unexcused for grade 8; \n",
      " - updated model.absence.discipline_incidents_gr_7 from clean.all_snapshots.discipline_incidents for grade 7; \n",
      " - updated model.absence.discipline_incidents_gr_8 from clean.all_snapshots.discipline_incidents for grade 8; \n",
      " - updated model.absence.tardy_gr_7 from clean.all_absences.tardy_gr_7 for grade 7; \n",
      " - updated model.absence.tardy_gr_8 from clean.all_absences.tardy_gr_8 for grade 8; \n",
      " - updated model.absence.tardy_unexcused_gr_7 from clean.all_absences.tardy_unexcused_gr_7 for grade 7; \n",
      " - updated model.absence.tardy_unexcused_gr_8 from clean.all_absences.tardy_unexcused_gr_8 for grade 8; \n",
      " - updated model.absence.medical_gr_7 from clean.all_absences.medical_gr_7 for grade 7; \n",
      " - updated model.absence.medical_gr_8 from clean.all_absences.medical_gr_8 for grade 8; \n",
      " - updated model.absence.absence_consec_gr_7 from clean.all_absences.absence_conseq_count for grade 7; \n",
      " - updated model.absence.absence_consec_gr_8 from clean.all_absences.absence_conseq_count for grade 8; \n",
      " - updated model.absence.tardy_consec_gr_7 from clean.all_absences.tardy_conseq_count for grade 7; \n",
      " - updated model.absence.tardy_consec_gr_8 from clean.all_absences.tardy_conseq_count for grade 8; \n",
      "time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# functions\n",
    "def set_null_as_0(cursor, column, schema='clean', table='absence'):\n",
    "    sqlcmd = \"\"\"\n",
    "    update {schema}.{table}\n",
    "    set {column}=0 \n",
    "    where {column} is null;\"\"\".format(schema=schema, table=table, column=column)\n",
    "    cursor.execute(sqlcmd)\n",
    "\n",
    "def create_feature_table(cursor, table, schema = 'model', replace = False):\n",
    "    \"\"\"\n",
    "    The current feature table is dropped and re-created with a single column\n",
    "    containing unique student lookups numbers, set as an index\n",
    "    :param pg_cursor cursor:\n",
    "    :param str table: feature table name \n",
    "    :param str schema: schema name for feature table\n",
    "    :param bool replace: if true the table will be replaced, \n",
    "        if false an existing table will not be altered\n",
    "    \"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    select count(*) from information_schema.tables\n",
    "    where table_schema = '{schema}' and table_name = '{table}'\n",
    "    \"\"\".format_map({'schema':schema,'table':table}))\n",
    "    table_exists = cursor.fetchall()[0][0]\n",
    "    if (not table_exists) or replace:\n",
    "        sql_drop = \"drop table if exists {schema}.{table};\"\\\n",
    "            .format(schema=schema, table=table)\n",
    "        sql_create = \"\"\"                                                     \n",
    "        create table {schema}.{table} as                                     \n",
    "        ( select distinct student_lookup                                     \n",
    "        from clean.wrk_tracking_students                                   \n",
    "        where outcome_category is not null                                 \n",
    "        );\"\"\".format(schema=schema, table=table)\n",
    "        cursor.execute(sql_drop);\n",
    "        cursor.execute(sql_create);\n",
    "        sql_create_index = \"\"\"                                               \n",
    "        create index {schema}_{table}_lookup_index on {schema}.{table}(student_lookup)\n",
    "        \"\"\".format(schema=schema, table=table)\n",
    "        cursor.execute(sql_create_index)\n",
    "        print(\"\"\" - Table {schema}.{table} created!\"\"\"\\\n",
    "        .format(schema=schema, table=table))\n",
    "\n",
    "def update_column_with_join(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', dtype='varchar(64)', grade=9):\n",
    "    \"\"\" \n",
    "    Update column using join to match another table                 \n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select {source_column} from {source_schema_and_table} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.{source_column} is not null\n",
    "    and t2.grade={grade}\n",
    "    order by {source_column} desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column,\n",
    "               source_schema_and_table=source_schema_and_table, \n",
    "               source_column=source_column, grade=grade)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "    \n",
    "def update_join_type_cnt(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', dtype='varchar(64)', type_str = 'tardy', grade=9):\n",
    "    \"\"\" \n",
    "    Update column using join to match another table                 \n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    sql_drop_temp = \"\"\"drop table if exists {table};\"\"\".format(table=tab_temp)\n",
    "    cursor.execute(sql_drop_temp)\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, count(*) from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "                                          source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index tdy_cnt_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, tab_temp, 'count')\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select count from {tab_temp} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.count is not null\n",
    "    order by count desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column, tab_temp=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "    \n",
    "def update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'absence', grade=9):\n",
    "    \"\"\" \n",
    "     Update column using consec aggreated data                 \n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    source_column = type_str+'_conseq_count'\n",
    "    sql_drop_temp = \"\"\"drop table if exists {table};\"\"\".format(table=tab_temp)\n",
    "    cursor.execute(sql_drop_temp)\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, sum(t2.{source_column}) as csum from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "        source_column=source_column, source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index consec_agg_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format(schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update only {schema}.{table} t1\n",
    "    set {column}=\n",
    "    ( select csum from {tmp_tab} t2\n",
    "      where t2.student_lookup=t1.student_lookup\n",
    "      limit 1\n",
    "    );\"\"\".format(schema=schema, table=table, column=column, tmp_tab=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema}.{s_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema=source_schema, s_table=source_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "    \n",
    "    \n",
    "\n",
    "def main():\n",
    "    schema, table = \"model\" ,\"absence\"\n",
    "    source_schema = \"clean\"\n",
    "    tab_snapshots, tab_absence = \"all_snapshots\", \"all_absences\"\n",
    "    gr_min, gr_max = 7, 8\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            create_feature_table(cursor, table, schema = 'model', replace = True)\n",
    "            \n",
    "            # days_absent columns\n",
    "            source_table, source_column = tab_snapshots, 'days_absent'\n",
    "            new_col_name = '_'.join(source_column.split('-')[1:])\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name+'_gr_'+str(grd)\n",
    "                update_column_with_join(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = source_column, source_schema = 'clean',\n",
    "                                schema='model', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "            # days_absent_unexecused\n",
    "            source_table, source_column = tab_snapshots, 'days_absent_unexcused'\n",
    "            new_col_name = '_'.join(source_column.split('-')[1:])\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name+'_gr_'+str(grd)\n",
    "                update_column_with_join(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = source_column, source_schema = 'clean',\n",
    "                                schema='model', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "            # discipline_incidents\n",
    "            source_table, source_column = tab_snapshots, 'discipline_incidents'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = source_column+'_gr_'+str(grd)\n",
    "                update_column_with_join(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = source_column, source_schema = 'clean',\n",
    "                                schema='model', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "                \n",
    "            # tardy\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'tardy'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_gr_' + str(grd)\n",
    "                update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = None, source_schema = 'clean',\n",
    "                                schema='model', type_str='tardy', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "            # tardy_unexecused\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'tardy_unexcused'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_gr_' + str(grd)\n",
    "                update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = None, source_schema = 'clean',\n",
    "                                schema='model', type_str='tardy_unexcused', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "            # med\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'medical'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_gr_' + str(grd)\n",
    "                update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = None, source_schema = 'clean',\n",
    "                                schema='model', type_str='med', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "            # consequtive absence days\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'absence'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'absence', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "                    \n",
    "            # consequtive tardy days\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'tardy'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'tardy', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "        \n",
    "            connection.commit()\n",
    "        \n",
    "if __name__ =='__main__':\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['days', 'absent']\n",
      "\n",
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "source_table, source_column = 'abc', 'days_absent'\n",
    "new_col_name = '_'.join(source_column.split('-')[1:])\n",
    "print(source_column.split('_'))\n",
    "print(new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 64.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Hannah Functions\n",
    "def get_column(connection, column_list, table, schema='clean'):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe with student lookup and the given list of columns\n",
    "\n",
    "    :param list column_list: desired list of columns (student lookup automatically included)\n",
    "    :rtype: pandas dataframe\n",
    "    \"\"\" \n",
    "    sqlcmd = (\"\"\"select student_lookup, {cols} from {schema}.\"{table}\";\"\"\"\n",
    "        .format_map({'schema':schema,'table': table, 'cols': ', '.join(column_list)}))\n",
    "    df = pd.read_sql(sqlcmd, connection)\n",
    "    return df\n",
    "\n",
    "def next_day(row):\n",
    "    \"\"\"\n",
    "    Returns 1 if the given pair of days is consecutive, else 0\n",
    "    row of the form  [student_lookup1,date1, student_lookup2, date2]\n",
    "    \"\"\"\n",
    "    if row['s1']==row['s2']:\n",
    "        if (row['d2']- row['d1']).days == 1:\n",
    "            return 1\n",
    "        elif row['d2'].weekday()==1 and row['d1'].weekday() > 4 and (row['d2']-row['d1']).days < 4:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "def all_consecutive_absences(absences, date_range=None):\n",
    "    \"\"\"\n",
    "    Returns the all instances of multiple consecutive absences/tardies\n",
    "    :param dataframe absences: dataframe with student_lookup and date columns\n",
    "    :param pair date_range: pair of dates, (lower_bound, upper_bound)\n",
    "    :rtype: list of ints\n",
    "    \"\"\"\n",
    "    if date_range:\n",
    "        absences = absences[(absences['date']>date_range[0]) & (absences['date']<date_range[1])]\n",
    "    absent_dates = absences.sort_values(['student_lookup','date'])[['student_lookup','date']]\n",
    "    date_pairs = pd.DataFrame()\n",
    "    date_pairs['s1'] = absent_dates[:-1]['student_lookup'].values\n",
    "    date_pairs['s2'] = absent_dates[1:]['student_lookup'].values\n",
    "    date_pairs['d1'] = absent_dates[:-1]['date'].values\n",
    "    date_pairs['d2'] = absent_dates[1:]['date'].values\n",
    "    delta = date_pairs.apply(next_day, axis=1)\n",
    "    return [sum(1 for i in g)+1 for d, g in groupby(delta) if (d==1)] # check this logic\n",
    "\n",
    "def consecutive_absences(absences, student_lookup, date_range=None):\n",
    "    \"\"\"\n",
    "    Returns instances of multiple consecutive absences/tardies for a \n",
    "    particular student\n",
    "    :param dataframe absences: dataframe with student_lookup and date columns\n",
    "    :param int student_lookup:\n",
    "    :param pair date_range: pair of dates, (lower_bound, upper_bound)\n",
    "    :rtype: list of ints\n",
    "    \"\"\"\n",
    "    if date_range:\n",
    "        absences = absences[(absences['date']>date_range[0]) & (absences['date']<date_range[1])]\n",
    "    student = absences[absences['student_lookup']==student_lookup]\n",
    "    student = student.sort_values('date')['date']\n",
    "    delta = student[1:].reset_index()- student[:-1].reset_index()\n",
    "    delta_list = [d.days for d in delta['date']]\n",
    "    return [sum(1 for i in g)+1 for d, g in groupby(delta_list) if (d==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if i==0 and date_pairs.iloc[i, 4]==1.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i, 2]\n",
    "    elif date_pairs.iloc[i, 4]==1.0 and date_pairs.iloc[i-1, 4]==0.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i, 2]\n",
    "    elif date_pairs.iloc[i, 4]==1.0 and date_pairs.iloc[i-1, 4]==1.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i-1, 5]\n",
    "    else:\n",
    "        date_pairs.iloc[i, 5] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>date</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_lookup        date  delta\n",
       "0               1  2012-12-17    1.0\n",
       "1               1  2012-12-20    1.0\n",
       "2               1  2013-01-08    3.0\n",
       "3               1  2013-02-11    2.0\n",
       "4               1  2013-04-10    1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "df = date_pairs.iloc[:1000, :]\n",
    "df = pd.DataFrame(df.groupby(['s1', 'starting_date'])['delta'].sum()).reset_index()\n",
    "df = df.rename(columns={'s1':'student_lookup', 'starting_date':'date'})\n",
    "df.head()\n",
    "df.merge(absences[['student_lookup', 'grade', 'date']], how='left', on=['student_lookup', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constructing 4 columns of clean.all_absences: aggregate consecutive days from clean.absences\n",
    "\"\"\" Generate consecutive absences columns (not generating features year)\n",
    " Generate New Columns in clean.absence: \n",
    " - absence_starting_date, \n",
    " - absence_consec_count, \n",
    " - tardy_starting_date, \n",
    " - tardy_consec_count\n",
    " \n",
    " Procedures:\n",
    " - obtain all distinct lookups from clean.absences;\n",
    " - break them into chunks to process chunk by chunk(memory cannot hold all data);\n",
    " - generate dataframes with number of consecutive days for a starting date\n",
    " - export to postgres and index student_lookups and date\n",
    " - join and update to clean.all_absences\n",
    "\"\"\"\n",
    "import os, sys\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def read_absences_lookups(conn, lookups = None):\n",
    "    \"\"\" Read data of certain lookup-chunk\n",
    "    \"\"\"\n",
    "    sqlcmd = \"\"\"select * from clean.all_absences \n",
    "    where student_lookup in {0} \n",
    "    order by student_lookup, date; \"\"\".format(str(tuple(lookups)))\n",
    "    return pd.read_sql_query(sqlcmd, conn)\n",
    "\n",
    "\n",
    "def consec_agg(df, desc_str='absence'):\n",
    "    \"\"\" Aggreate consective days of a certain type\n",
    "    :return pd.dataframe sumdf: sumdf with lookups, dates, counts \n",
    "    \"\"\"\n",
    "    new_date_col, new_cnt_col = desc_str+'_starting_date', desc_str+'_consec_count'\n",
    "    subdf = df[[desc_str in desc for desc in df.absence_desc]]\n",
    "    starting_dates=[None] * (subdf.shape[0])\n",
    "    for i in range(subdf.shape[0]-1):\n",
    "        row1, row2 = subdf.iloc[[i]], subdf.iloc[[i+1]]\n",
    "        index = row1.index[0]\n",
    "        if row1.student_lookup.values[0]==row2.student_lookup.values[0]:\n",
    "            if (((row2.date.values[0]  - row1.date.values[0]).days == 1) or  \n",
    "            (row2.weekday.values[0]==1 and row1.weekday.values[0]>4 and \n",
    "             (row2.date.values[0]-row1.date.values[0]).days<4)):\n",
    "                if starting_dates[i]==None:\n",
    "                    starting_dates[i]=row1.date.values[0]\n",
    "                    starting_dates[i+1]=row1.date.values[0]\n",
    "                else:\n",
    "                    starting_dates[i]=starting_dates[i-1]\n",
    "                    starting_dates[i+1]=starting_dates[i-1]\n",
    "    subdf[new_date_col] = starting_dates\n",
    "    sumdf = subdf.groupby(by=['student_lookup', new_date_col]).count().reset_index()[['student_lookup', new_date_col,'month']]\n",
    "    sumdf = sumdf.rename(columns={'month':new_cnt_col})\n",
    "    sumdf = sumdf.merge(subdf[['student_lookup', 'date']], how='left', left_on=['student_lookup', new_date_col], right_on=['student_lookup', 'date'])\n",
    "    return(sumdf.drop('date', axis=1))\n",
    "\n",
    "\n",
    "def update_absence(cursor, table='clean.all_absences', col='absence'):\n",
    "    col_date, dtype_date = col+'_starting_date', 'date'\n",
    "    col_cnt, dtype_cnt = col+'_consec_count', 'int'\n",
    "    if col=='absence':\n",
    "        table_intermed = 'public.intermed_'+col[:3]+'_agg'\n",
    "    else:\n",
    "        table_intermed='public.intermed_tdy_agg'\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {table} drop column if exists {column};\n",
    "    alter table {table} add column {column} {dtype} default null;\n",
    "    \"\"\".format(table=table, column=col_date, dtype=dtype_date )\n",
    "    cursor.execute(sql_add_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {table} drop column if exists {column};\n",
    "    alter table {table} add column {column} {dtype} default null;\n",
    "    \"\"\".format(table=table, column=col_cnt, dtype=dtype_cnt)\n",
    "    cursor.execute(sql_add_column)\n",
    "    \n",
    "    sql_join_cmd = \"\"\"\n",
    "    update only {table} t1\n",
    "    set {column_date}=t2.{column_date},\n",
    "        {column_cnt} =t2.{column_cnt}\n",
    "    from {table_intermed} t2\n",
    "    where t1.student_lookup=t2.student_lookup \n",
    "    and t1.date=t2.{column_date}\n",
    "    and t1.absence_desc like '%{col}%';\n",
    "    \"\"\".format(table=table, column_date=col_date, column_cnt=col_cnt,\n",
    "               table_intermed=table_intermed, col=col)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    \n",
    "    print(\"\"\" - updated {table}.({col1}, {col2}) from {tab_int}; \"\"\".format(\n",
    "            table=table, col1=col_date, col2=col_cnt, tab_int=table_intermed))\n",
    "    \n",
    "def main():\n",
    "    chunksize = 100\n",
    "    schema, table = 'clean', 'all_absences'\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            print('------ Running generate_consec_absence_columns.py -------')\n",
    "            lookups = list(pd.read_sql_query('select distinct student_lookup from clean.all_absences;', connection).student_lookup)\n",
    "            random.shuffle(lookups)\n",
    "            lookups = lookups[:2000]\n",
    "    #         sql_add_column = \"\"\"alter table {schema}.{table} drop if exists column {column};\n",
    "    #         alter table {schema}.{table} add column {column} {dtype} default null;\n",
    "    #         \"\"\".format( schema=schema, table=table, column=new_date_col, dtype=dtype_date)\n",
    "    #         #cursor.execute(sql_add_column)\n",
    "    #         sql_add_column = \"\"\"alter table {schema}.{table} drop if exists column {column};\n",
    "    #         alter table {schema}.{table} add column {column} {dtype} default null;\n",
    "    #         \"\"\".format( schema=schema, table=table, column=new_cnt_col, dtype=dtype_cnt)\n",
    "            #cursor.execute(sql_add_column)\n",
    "\n",
    "            print(' - generating agggated dataframe of absences...')\n",
    "            final_abs_df = pd.DataFrame()\n",
    "            final_tdy_df = pd.DataFrame()\n",
    "            for chunk_lookups in chunks(lookups, chunksize):\n",
    "                df = read_absences_lookups(connection, lookups=chunk_lookups)\n",
    "                final_abs_df = final_abs_df.append(consec_agg(df, desc_str='absence'), ignore_index=True)\n",
    "                final_tdy_df = final_tdy_df.append(consec_agg(df, desc_str='tardy'), ignore_index=True)\n",
    "\n",
    "            print(' - writing agg-dataframes to public...')\n",
    "            eng = postgres_engine_generator()\n",
    "            final_abs_df.to_sql('intermed_abs_agg', eng, index=False, if_exists='replace')\n",
    "            final_tdy_df.to_sql('intermed_tdy_agg', eng, index=False, if_exists='replace')\n",
    "\n",
    "            sql_index_intermed=\"\"\"create index public_intmed_abs_sl on public.intermed_abs_agg (student_lookup);\n",
    "            create index public_intmed_tdy_sl on public.intermed_tdy_agg (student_lookup);\n",
    "            create index public_intmed_abs_sl_dt on public.intermed_abs_agg (student_lookup, absence_starting_date);\n",
    "            create index public_intmed_tdy_sl_dt on public.intermed_tdy_agg (student_lookup, tardy_starting_date);\n",
    "            \"\"\"\n",
    "            cursor.execute(sql_index_intermed)\n",
    "\n",
    "            print(' - updating clean.absence by joining...')\n",
    "            update_absence(cursor, table='clean.all_absences', col='absence') # changed from absence_test to absence; run again\n",
    "            update_absence(cursor, table='clean.all_absences', col='tardy')\n",
    "            print(' - Done!')\n",
    "            \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 765 ms\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "    connection.autocommit = True\n",
    "    with connection.cursor() as cursor:\n",
    "        absence = read_table_to_df(connection, table_name='absence', schema='model', nrows=-1)\n",
    "        outcome = read_table_to_df(connection, table_name='outcome', schema='model', nrows=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "abs_cols = list(filter(lambda x: 'absence_gr_' in x, list(absence.columns)))\n",
    "cons_cols = list(filter(lambda x: 'absence_consec_gr_' in x, list(absence.columns)))\n",
    "\n",
    "dfabs = pd.DataFrame()\n",
    "dfabs['student_lookup'] = absence['student_lookup']\n",
    "dfabs['abs_sum'] = absence[abs_cols].sum(axis=1)\n",
    "\n",
    "dfcons = pd.DataFrame()\n",
    "dfcons['student_lookup'] = absence['student_lookup']\n",
    "dfcons['cons_sum'] = absence[cons_cols].sum(axis=1)\n",
    "\n",
    "outcome_col = 'definite'\n",
    "dfabs = dfabs.merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "dfcons = dfcons.merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "\n",
    "\n",
    "outcome_col = 'not_on_time'\n",
    "dfabs2 = dfabs.merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "dfcons2 = dfcons.merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>abs_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>34542.439661</td>\n",
       "      <td>39.187299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>118745.622785</td>\n",
       "      <td>55.212759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          student_lookup    abs_sum\n",
       "definite                           \n",
       "0.0         34542.439661  39.187299\n",
       "1.0        118745.622785  55.212759"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.9 ms\n"
     ]
    }
   ],
   "source": [
    "dfabs.groupby(by='definite').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>cons_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definite</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>34542.439661</td>\n",
       "      <td>0.135512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>118745.622785</td>\n",
       "      <td>0.346835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          student_lookup  cons_sum\n",
       "definite                          \n",
       "0.0         34542.439661  0.135512\n",
       "1.0        118745.622785  0.346835"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.2 ms\n"
     ]
    }
   ],
   "source": [
    "dfcons.groupby(by='definite').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>abs_sum</th>\n",
       "      <th>definite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_on_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34555.955796</td>\n",
       "      <td>39.218413</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96489.247851</td>\n",
       "      <td>39.209416</td>\n",
       "      <td>0.801217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             student_lookup    abs_sum  definite\n",
       "not_on_time                                     \n",
       "0              34555.955796  39.218413  0.000000\n",
       "1              96489.247851  39.209416  0.801217"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.5 ms\n"
     ]
    }
   ],
   "source": [
    "dfabs2.groupby(by='not_on_time').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>cons_sum</th>\n",
       "      <th>definite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_on_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34555.955796</td>\n",
       "      <td>0.135882</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96489.247851</td>\n",
       "      <td>0.191475</td>\n",
       "      <td>0.801217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             student_lookup  cons_sum  definite\n",
       "not_on_time                                    \n",
       "0              34555.955796  0.135882  0.000000\n",
       "1              96489.247851  0.191475  0.801217"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "dfcons2.groupby(by='not_on_time').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
