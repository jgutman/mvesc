{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, join, abspath, basename\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "parentdir = os.path.abspath('/home/xcheng/mvesc/ETL')\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "\n",
    "import inspect\n",
    "import datetime\n",
    "from itertools import chain, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pandas.tools.plotting import table\n",
    "from feature_utilities import *\n",
    "matplotlib.style.use('ggplot')\n",
    "get_ipython().magic('matplotlib')\n",
    "from mvesc_utility_functions import *\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check mobility features, set negative data points to be null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 649 ms\n"
     ]
    }
   ],
   "source": [
    "schema, table = 'model', 'mobility'\n",
    "\n",
    "with postgres_pgconnection_generator() as connection:\n",
    "    connection.autocommit = True\n",
    "    with connection.cursor() as cursor:\n",
    "        table_df = pd.read_sql_query(\"select * from {schema}.{table} limit 1000;\".format(\n",
    "                schema=schema, table=table), connection)\n",
    "        table_df = table_df.select_dtypes(include=[np.number])\n",
    "        numeric_columns = table_df.columns\n",
    "        for column in numeric_columns:\n",
    "            sql_set_null_0 = \"\"\"\n",
    "            update only {schema}.{table}\n",
    "            set {column}=NULL\n",
    "            where {column}<0.0;\n",
    "            \"\"\".format(schema=schema, table=table, column=column)\n",
    "            cursor.execute(sql_set_null_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 654 ms\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "    connection.autocommit = True\n",
    "    with connection.cursor() as cursor:\n",
    "        table_df = pd.read_sql_query(\"select * from {schema}.{table};\".format(\n",
    "                schema=schema, table=table), connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.7 ms\n"
     ]
    }
   ],
   "source": [
    "(table_df<0.0).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    51\n",
      "True      8\n",
      "Name: mid_year_withdraw_gr_4, dtype: int64\n",
      "time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(table_df.iloc[:, -10:].iloc[:, i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning: what features to include\n",
    "\n",
    "1. number of absent days & unexecused absence days;\n",
    "2. number of tardy & unexecused tardy;\n",
    "3. number of consecutive absences;\n",
    "4. number of consecutive tardy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Table model.absence_test created!\n",
      "length:  (11175,)\n",
      " - updated absence_gr_3 in model.absence_test\n",
      "    from absence_gr_3; \n",
      " - updated absence_gr_4 in model.absence_test\n",
      "    from absence_gr_4; \n",
      " - updated absence_gr_5 in model.absence_test\n",
      "    from absence_gr_5; \n",
      " - updated absence_gr_6 in model.absence_test\n",
      "    from absence_gr_6; \n",
      " - updated absence_gr_7 in model.absence_test\n",
      "    from absence_gr_7; \n",
      " - updated absence_gr_8 in model.absence_test\n",
      "    from absence_gr_8; \n",
      " - updated absence_gr_9 in model.absence_test\n",
      "    from absence_gr_9; \n",
      " - updated absence_gr_10 in model.absence_test\n",
      "    from absence_gr_10; \n",
      " - updated absence_gr_11 in model.absence_test\n",
      "    from absence_gr_11; \n",
      "length:  (11175,)\n",
      " - updated absence_unexcused_gr_3 in model.absence_test\n",
      "    from absence_unexcused_gr_3; \n",
      " - updated absence_unexcused_gr_4 in model.absence_test\n",
      "    from absence_unexcused_gr_4; \n",
      " - updated absence_unexcused_gr_5 in model.absence_test\n",
      "    from absence_unexcused_gr_5; \n",
      " - updated absence_unexcused_gr_6 in model.absence_test\n",
      "    from absence_unexcused_gr_6; \n",
      " - updated absence_unexcused_gr_7 in model.absence_test\n",
      "    from absence_unexcused_gr_7; \n",
      " - updated absence_unexcused_gr_8 in model.absence_test\n",
      "    from absence_unexcused_gr_8; \n",
      " - updated absence_unexcused_gr_9 in model.absence_test\n",
      "    from absence_unexcused_gr_9; \n",
      " - updated absence_unexcused_gr_10 in model.absence_test\n",
      "    from absence_unexcused_gr_10; \n",
      " - updated absence_unexcused_gr_11 in model.absence_test\n",
      "    from absence_unexcused_gr_11; \n",
      "length:  (11175,)\n",
      " - updated tardy_gr_3 in model.absence_test\n",
      "    from tardy_gr_3; \n",
      " - updated tardy_gr_4 in model.absence_test\n",
      "    from tardy_gr_4; \n",
      " - updated tardy_gr_5 in model.absence_test\n",
      "    from tardy_gr_5; \n",
      " - updated tardy_gr_6 in model.absence_test\n",
      "    from tardy_gr_6; \n",
      " - updated tardy_gr_7 in model.absence_test\n",
      "    from tardy_gr_7; \n",
      " - updated tardy_gr_8 in model.absence_test\n",
      "    from tardy_gr_8; \n",
      " - updated tardy_gr_9 in model.absence_test\n",
      "    from tardy_gr_9; \n",
      " - updated tardy_gr_10 in model.absence_test\n",
      "    from tardy_gr_10; \n",
      " - updated tardy_gr_11 in model.absence_test\n",
      "    from tardy_gr_11; \n",
      "length:  (11175,)\n",
      " - updated tardy_unexcused_gr_3 in model.absence_test\n",
      "    from tardy_unexcused_gr_3; \n",
      " - updated tardy_unexcused_gr_4 in model.absence_test\n",
      "    from tardy_unexcused_gr_4; \n",
      " - updated tardy_unexcused_gr_5 in model.absence_test\n",
      "    from tardy_unexcused_gr_5; \n",
      " - updated tardy_unexcused_gr_6 in model.absence_test\n",
      "    from tardy_unexcused_gr_6; \n",
      " - updated tardy_unexcused_gr_7 in model.absence_test\n",
      "    from tardy_unexcused_gr_7; \n",
      " - updated tardy_unexcused_gr_8 in model.absence_test\n",
      "    from tardy_unexcused_gr_8; \n",
      " - updated tardy_unexcused_gr_9 in model.absence_test\n",
      "    from tardy_unexcused_gr_9; \n",
      " - updated tardy_unexcused_gr_10 in model.absence_test\n",
      "    from tardy_unexcused_gr_10; \n",
      " - updated tardy_unexcused_gr_11 in model.absence_test\n",
      "    from tardy_unexcused_gr_11; \n",
      "length:  (11175,)\n",
      " - updated medical_gr_3 in model.absence_test\n",
      "    from medical_gr_3; \n",
      " - updated medical_gr_4 in model.absence_test\n",
      "    from medical_gr_4; \n",
      " - updated medical_gr_5 in model.absence_test\n",
      "    from medical_gr_5; \n",
      " - updated medical_gr_6 in model.absence_test\n",
      "    from medical_gr_6; \n",
      " - updated medical_gr_7 in model.absence_test\n",
      "    from medical_gr_7; \n",
      " - updated medical_gr_8 in model.absence_test\n",
      "    from medical_gr_8; \n",
      " - updated medical_gr_9 in model.absence_test\n",
      "    from medical_gr_9; \n",
      " - updated medical_gr_10 in model.absence_test\n",
      "    from medical_gr_10; \n",
      " - updated medical_gr_11 in model.absence_test\n",
      "    from medical_gr_11; \n",
      "length:  (11175,)\n",
      " - updated absence_consec_gr_3 in model.absence_test\n",
      "    from absence_consec_gr_3; \n",
      " - updated absence_consec_gr_4 in model.absence_test\n",
      "    from absence_consec_gr_4; \n",
      " - updated absence_consec_gr_5 in model.absence_test\n",
      "    from absence_consec_gr_5; \n",
      " - updated absence_consec_gr_6 in model.absence_test\n",
      "    from absence_consec_gr_6; \n",
      " - updated absence_consec_gr_7 in model.absence_test\n",
      "    from absence_consec_gr_7; \n",
      " - updated absence_consec_gr_8 in model.absence_test\n",
      "    from absence_consec_gr_8; \n",
      " - updated absence_consec_gr_9 in model.absence_test\n",
      "    from absence_consec_gr_9; \n",
      " - updated absence_consec_gr_10 in model.absence_test\n",
      "    from absence_consec_gr_10; \n",
      " - updated absence_consec_gr_11 in model.absence_test\n",
      "    from absence_consec_gr_11; \n",
      "length:  (11175,)\n",
      " - updated tardy_consec_gr_3 in model.absence_test\n",
      "    from tardy_consec_gr_3; \n",
      " - updated tardy_consec_gr_4 in model.absence_test\n",
      "    from tardy_consec_gr_4; \n",
      " - updated tardy_consec_gr_5 in model.absence_test\n",
      "    from tardy_consec_gr_5; \n",
      " - updated tardy_consec_gr_6 in model.absence_test\n",
      "    from tardy_consec_gr_6; \n",
      " - updated tardy_consec_gr_7 in model.absence_test\n",
      "    from tardy_consec_gr_7; \n",
      " - updated tardy_consec_gr_8 in model.absence_test\n",
      "    from tardy_consec_gr_8; \n",
      " - updated tardy_consec_gr_9 in model.absence_test\n",
      "    from tardy_consec_gr_9; \n",
      " - updated tardy_consec_gr_10 in model.absence_test\n",
      "    from tardy_consec_gr_10; \n",
      " - updated tardy_consec_gr_11 in model.absence_test\n",
      "    from tardy_consec_gr_11; \n",
      "length:  (11175,)\n",
      "time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate Absence related features\n",
    "For Each Grade, generate features:\n",
    "- absence\n",
    "- absence_unexecused\n",
    "- tardy \n",
    "- tardy_unexecused\n",
    "- medical\n",
    "- absence_consec\n",
    "- tardy_consec\n",
    "\n",
    "Note: features from top to bottom, there are more and more missing values,\n",
    "espeically for some specific grades\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os, sys\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_utilities import *\n",
    "\n",
    "def set_null_as_0(cursor, column, schema='clean', table='absence'):\n",
    "    \"\"\" Set null data points as 0 (be careful to assume so)\n",
    "\n",
    "    :param pg.connection.cursor cursor: postgres cursor\n",
    "    :param str column: column name\n",
    "    :param str schema: schema name\n",
    "    :param str table: table name\n",
    "    \"\"\"\n",
    "    sqlcmd = \"\"\"\n",
    "    update {schema}.{table}\n",
    "    set {column}=0 \n",
    "    where {column} is null;\"\"\".format(schema=schema, table=table, column=column)\n",
    "    cursor.execute(sqlcmd)\n",
    "    return None\n",
    "    \n",
    "\n",
    "def create_simple_temp_table(cursor, temp_table, source_table, source_column, \n",
    "                             new_column, grade, source_schema='clean'):\n",
    "    \"\"\"\n",
    "    Create simple temp table using `create table as select *`\n",
    "    :param pg.cursor curosr: postgres pg.cursor\n",
    "    :param str temp_table: name of temp table to create\n",
    "    :param str source_table: name of source table to create temp table\n",
    "    :param str source_column: name of source column in source_table\n",
    "    :param str new_column: new column name in temp table\n",
    "    :param int grade: the grade to subset\n",
    "    :param str source_scheam: name of source schema, default 'clean'\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    sql_tmp_table = \"\"\"\n",
    "    drop table if exists {tmp};\n",
    "    create temporary table {tmp} as\n",
    "        select student_lookup, max({sc}) as {nc} from {ss}.{st}\n",
    "        where grade={grd}\n",
    "        group by student_lookup;\n",
    "    \"\"\".format(tmp=temp_table, sc=source_column, nc=new_column, ss=source_schema, st=source_table, grd=grade)\n",
    "    cursor.execute(sql_tmp_table)\n",
    "    sql_index = \"create index lookup_index on {t}(student_lookup)\".format(t=temp_table)\n",
    "    cursor.execute(sql_tmp_table)\n",
    "    return None\n",
    "    \n",
    "def create_absence_type_temp_table(cursor, temp_table, source_table, \n",
    "                                   new_column, type_str, grade, source_schema='clean'):\n",
    "    \"\"\"\n",
    "    Create temp table for only certain type of absences\n",
    "    :param pg.cursor curosr: postgres pg.cursor\n",
    "    :param str temp_table: name of temp table to create\n",
    "    :param str source_table: name of source table to create temp table\n",
    "    :param str new_column: new column name in temp table\n",
    "    :param int grade: the grade to subset\n",
    "    :param str source_scheam: name of source schema, default 'clean'\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    drop table if exists {tmp};\n",
    "    create temporary table {tmp} as \n",
    "    select student_lookup, count(*) as {nc} from {ss}.{st}\n",
    "    where grade={grd} and absence_desc like '%{type_str}%'\n",
    "    group by student_lookup;\n",
    "    \"\"\".format(tmp=temp_table, nc=new_column, ss=source_schema, st=source_table, type_str=type_str, grd=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index {tmp}_ind on {tmp}(student_lookup);\"\"\".format(tmp=temp_table);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    return None\n",
    "\n",
    "def create_consec_absence_temp_table(cursor, temp_table, source_table, source_column, \n",
    "                                     new_column, grade, source_schema='clean'):\n",
    "    \"\"\"\n",
    "    Create temp table for only consecutive absences\n",
    "    :param pg.cursor curosr: postgres pg.cursor\n",
    "    :param str temp_table: name of temp table to create\n",
    "    :param str source_table: name of source table to create temp table\n",
    "    :param str source_column: name of source column in source_table\n",
    "    :param str new_column: new column name in temp table\n",
    "    :param int grade: the grade to subset\n",
    "    :param str source_scheam: name of source schema, default 'clean'\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    drop table if exists {tmp};\n",
    "    create temporary table {tmp} as \n",
    "    select student_lookup, sum({sc}) as {nc} from {ss}.{st}\n",
    "    where grade={grd}\n",
    "    group by student_lookup;\n",
    "    \"\"\".format(tmp=temp_table, sc=source_column, ss=source_schema, st=source_table, \n",
    "               nc=new_column, grd=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index {tmp}_index on {tmp}(student_lookup);\"\"\".format(tmp=temp_table);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    return None\n",
    "\n",
    "    \n",
    "def main():\n",
    "    schema, table = \"model\" ,\"absence_test\"\n",
    "    source_schema = \"clean\"\n",
    "    tab_snapshots, tab_absence = \"all_snapshots\", \"all_absences\"\n",
    "    gr_min, gr_max = 3, 11\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            create_feature_table(cursor, table, schema = 'model', replace = True)\n",
    "\n",
    "            # days_absent columns\n",
    "            source_table, source_column, new_col_name = tab_snapshots, 'days_absent', 'absence'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name+'_gr_'+str(grd)\n",
    "                create_simple_temp_table(cursor, temp_table, source_table, source_column, column, grade=grd)\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "            # days_absent_unexecused\n",
    "            source_table, source_column = tab_snapshots, 'days_absent_unexcused'\n",
    "            new_col_name = 'absence_unexcused'\n",
    "            for grd in range(gr_min, gr_max+1):                \n",
    "                temp_table = column = new_col_name+'_gr_'+str(grd)\n",
    "                create_simple_temp_table(cursor, temp_table, source_table, source_column, column, grade=grd)\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "\n",
    "            # tardy\n",
    "            source_table, new_col_name = tab_absence, 'tardy'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name + '_gr_' + str(grd)\n",
    "                create_absence_type_temp_table(cursor, temp_table, source_table, column, type_str=new_col_name, grade=grd, source_schema='clean')\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "            # tardy_unexecused\n",
    "            source_table, new_col_name = tab_absence, 'tardy_unexcused'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name + '_gr_' + str(grd)\n",
    "                create_absence_type_temp_table(cursor, temp_table, source_table, column, \n",
    "                                               type_str=new_col_name, grade=grd, source_schema='clean')\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "         \n",
    "            # med\n",
    "            source_table, new_col_name = tab_absence, 'medical'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name + '_gr_' + str(grd)\n",
    "                create_absence_type_temp_table(cursor, temp_table, source_table, column, \n",
    "                                               type_str='med', grade=grd, source_schema='clean')\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "            # consecutive absence days\n",
    "            source_table, new_col_name = tab_absence, 'absence'\n",
    "            source_column = new_col_name + '_consec_count'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                create_consec_absence_temp_table(cursor, temp_table, source_table, source_column, \n",
    "                                                 column, grade=grd, source_schema='clean')\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "                    \n",
    "            # consecutive tardy days\n",
    "            source_table, new_col_name = tab_absence, 'tardy'\n",
    "            source_column = new_col_name + '_consec_count'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                temp_table = column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                create_consec_absence_temp_table(cursor, temp_table, source_table, source_column, \n",
    "                                                 column, grade=grd, source_schema='clean')\n",
    "                update_column_with_join(cursor, table, [column], source_table=temp_table, schema=schema)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "        \n",
    "            connection.commit()\n",
    "        \n",
    "if __name__ =='__main__':\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "# check model.absence and model.absence_test\n",
    "with postgres_pgconnection_generator() as connection:\n",
    "    connection.autocommit = True\n",
    "    with connection.cursor() as cursor:\n",
    "        absence = read_table_to_df(connection, table_name='absence', schema='model', nrows=-1)\n",
    "        absence_test = read_table_to_df(connection, table_name='absence_test', schema='model', nrows=-1)\n",
    "        #create_feature_table(cursor, 'absence_del', schema = 'model', replace = True)\n",
    "        absence=absence.sort_values('student_lookup')\n",
    "        absence_test=absence_test.sort_values('student_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size diff:  0\n",
      "shape diff:  [0 0]\n",
      "time: 4.73 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"size diff: \", len(absence.student_lookup.unique())- len(absence_test.student_lookup.unique()))\n",
    "print(\"shape diff: \", np.subtract(absence.shape, absence_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>absence_gr_3</th>\n",
       "      <th>absence_gr_4</th>\n",
       "      <th>absence_gr_5</th>\n",
       "      <th>absence_gr_6</th>\n",
       "      <th>absence_gr_7</th>\n",
       "      <th>absence_gr_8</th>\n",
       "      <th>absence_gr_9</th>\n",
       "      <th>absence_gr_10</th>\n",
       "      <th>absence_gr_11</th>\n",
       "      <th>...</th>\n",
       "      <th>absence_consec_gr_11</th>\n",
       "      <th>tardy_consec_gr_3</th>\n",
       "      <th>tardy_consec_gr_4</th>\n",
       "      <th>tardy_consec_gr_5</th>\n",
       "      <th>tardy_consec_gr_6</th>\n",
       "      <th>tardy_consec_gr_7</th>\n",
       "      <th>tardy_consec_gr_8</th>\n",
       "      <th>tardy_consec_gr_9</th>\n",
       "      <th>tardy_consec_gr_10</th>\n",
       "      <th>tardy_consec_gr_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_lookup  absence_gr_3  absence_gr_4  absence_gr_5  absence_gr_6  \\\n",
       "414            46.0           0.0          12.5           6.0          12.5   \n",
       "415            47.0           0.0           9.5          15.5          13.5   \n",
       "416            48.0           0.0          16.0          11.0           9.5   \n",
       "417            49.0           0.0           1.0           3.5          16.0   \n",
       "418            50.0           3.0           5.0          10.0          11.0   \n",
       "\n",
       "     absence_gr_7  absence_gr_8  absence_gr_9  absence_gr_10  absence_gr_11  \\\n",
       "414          12.0          19.5          19.0           11.0           17.0   \n",
       "415           9.5          20.0          22.0           16.5            0.0   \n",
       "416           6.5           9.0           9.0           12.0            0.0   \n",
       "417           7.0           6.5          15.0            5.0            0.0   \n",
       "418           3.0           9.0           3.0            3.0            1.5   \n",
       "\n",
       "            ...          absence_consec_gr_11  tardy_consec_gr_3  \\\n",
       "414         ...                             0                  0   \n",
       "415         ...                             0                  0   \n",
       "416         ...                             0                  0   \n",
       "417         ...                             0                  0   \n",
       "418         ...                             0                  0   \n",
       "\n",
       "     tardy_consec_gr_4  tardy_consec_gr_5  tardy_consec_gr_6  \\\n",
       "414                  0                  0                  0   \n",
       "415                  0                  0                  0   \n",
       "416                  0                  0                  0   \n",
       "417                  0                  0                  0   \n",
       "418                  0                  0                  0   \n",
       "\n",
       "     tardy_consec_gr_7  tardy_consec_gr_8  tardy_consec_gr_9  \\\n",
       "414                  0                  0                  0   \n",
       "415                  0                  0                  2   \n",
       "416                  0                  0                  0   \n",
       "417                  0                  0                  0   \n",
       "418                  0                  0                  0   \n",
       "\n",
       "     tardy_consec_gr_10  tardy_consec_gr_11  \n",
       "414                   0                   0  \n",
       "415                   0                   0  \n",
       "416                   0                   0  \n",
       "417                   0                   0  \n",
       "418                   0                   0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.2 ms\n"
     ]
    }
   ],
   "source": [
    "absence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>absence_gr_3</th>\n",
       "      <th>absence_gr_4</th>\n",
       "      <th>absence_gr_5</th>\n",
       "      <th>absence_gr_6</th>\n",
       "      <th>absence_gr_7</th>\n",
       "      <th>absence_gr_8</th>\n",
       "      <th>absence_gr_9</th>\n",
       "      <th>absence_gr_10</th>\n",
       "      <th>absence_gr_11</th>\n",
       "      <th>...</th>\n",
       "      <th>absence_consec_gr_11</th>\n",
       "      <th>tardy_consec_gr_3</th>\n",
       "      <th>tardy_consec_gr_4</th>\n",
       "      <th>tardy_consec_gr_5</th>\n",
       "      <th>tardy_consec_gr_6</th>\n",
       "      <th>tardy_consec_gr_7</th>\n",
       "      <th>tardy_consec_gr_8</th>\n",
       "      <th>tardy_consec_gr_9</th>\n",
       "      <th>tardy_consec_gr_10</th>\n",
       "      <th>tardy_consec_gr_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_lookup  absence_gr_3  absence_gr_4  absence_gr_5  absence_gr_6  \\\n",
       "414            46.0           0.0          12.5           6.0          12.5   \n",
       "415            47.0           0.0           9.5          15.5          13.5   \n",
       "416            48.0           0.0          16.0          11.0           9.5   \n",
       "417            49.0           0.0           1.0           3.5          16.0   \n",
       "418            50.0           3.0           5.0          10.0          11.0   \n",
       "\n",
       "     absence_gr_7  absence_gr_8  absence_gr_9  absence_gr_10  absence_gr_11  \\\n",
       "414          12.0          19.5          19.0           11.0           17.0   \n",
       "415           9.5          20.0          22.0           16.5            0.0   \n",
       "416           6.5           9.0           9.0           12.0            0.0   \n",
       "417           7.0           6.5          15.0            5.0            0.0   \n",
       "418           3.0           9.0           3.0            3.0            1.5   \n",
       "\n",
       "            ...          absence_consec_gr_11  tardy_consec_gr_3  \\\n",
       "414         ...                             0                  0   \n",
       "415         ...                             0                  0   \n",
       "416         ...                             0                  0   \n",
       "417         ...                             0                  0   \n",
       "418         ...                             0                  0   \n",
       "\n",
       "     tardy_consec_gr_4  tardy_consec_gr_5  tardy_consec_gr_6  \\\n",
       "414                  0                  0                  0   \n",
       "415                  0                  0                  0   \n",
       "416                  0                  0                  0   \n",
       "417                  0                  0                  0   \n",
       "418                  0                  0                  0   \n",
       "\n",
       "     tardy_consec_gr_7  tardy_consec_gr_8  tardy_consec_gr_9  \\\n",
       "414                  0                  0                  0   \n",
       "415                  0                  0                  2   \n",
       "416                  0                  0                  0   \n",
       "417                  0                  0                  0   \n",
       "418                  0                  0                  0   \n",
       "\n",
       "     tardy_consec_gr_10  tardy_consec_gr_11  \n",
       "414                   0                   0  \n",
       "415                   0                   0  \n",
       "416                   0                   0  \n",
       "417                   0                   0  \n",
       "418                   0                   0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.9 ms\n"
     ]
    }
   ],
   "source": [
    "absence_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.9 ms\n"
     ]
    }
   ],
   "source": [
    "np.abs(np.array(absence) - np.array(absence_test)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['days', 'absent']\n",
      "\n",
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "def update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'absence', grade=None):\n",
    "    \"\"\" Update column using consec aggreated data \n",
    "                \n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    source_column = type_str+'_consec_count'\n",
    "    sql_drop_temp = \"\"\"drop table if exists {table};\"\"\".format(table=tab_temp)\n",
    "    cursor.execute(sql_drop_temp)\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, sum(t2.{source_column}) as csum from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "        source_column=source_column, source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index consec_agg_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format(schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update only {schema}.{table} t1\n",
    "    set {column}=\n",
    "    ( select csum from {tmp_tab} t2\n",
    "      where t2.student_lookup=t1.student_lookup\n",
    "      limit 1\n",
    "    );\"\"\".format(schema=schema, table=table, column=column, tmp_tab=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema}.{s_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema=source_schema, s_table=source_table, \n",
    "            s_col=source_column, grade=grade)\n",
    "         )\n",
    "\n",
    "def update_join_type_cnt(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'tardy', grade=9):\n",
    "    \"\"\"Update column using join to match another table                 \n",
    "\n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    drop table if exists {temp_table};\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, count(*) from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "                                          source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index tdy_cnt_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, tab_temp, 'count')\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select count from {tab_temp} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.count is not null\n",
    "    order by count desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column, tab_temp=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "\n",
    "\n",
    "def update_column_with_join(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', dtype='varchar(64)', grade=9):\n",
    "    \"\"\"Update column using join to match another table               \n",
    "\n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select {source_column} from {source_schema_and_table} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.{source_column} is not null\n",
    "    and t2.grade={grade}\n",
    "    order by {source_column} desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column,\n",
    "               source_schema_and_table=source_schema_and_table, \n",
    "               source_column=source_column, grade=grade)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 64.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Hannah Functions\n",
    "def get_column(connection, column_list, table, schema='clean'):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe with student lookup and the given list of columns\n",
    "\n",
    "    :param list column_list: desired list of columns (student lookup automatically included)\n",
    "    :rtype: pandas dataframe\n",
    "    \"\"\" \n",
    "    sqlcmd = (\"\"\"select student_lookup, {cols} from {schema}.\"{table}\";\"\"\"\n",
    "        .format_map({'schema':schema,'table': table, 'cols': ', '.join(column_list)}))\n",
    "    df = pd.read_sql(sqlcmd, connection)\n",
    "    return df\n",
    "\n",
    "def next_day(row):\n",
    "    \"\"\"\n",
    "    Returns 1 if the given pair of days is consecutive, else 0\n",
    "    row of the form  [student_lookup1,date1, student_lookup2, date2]\n",
    "    \"\"\"\n",
    "    if row['s1']==row['s2']:\n",
    "        if (row['d2']- row['d1']).days == 1:\n",
    "            return 1\n",
    "        elif row['d2'].weekday()==1 and row['d1'].weekday() > 4 and (row['d2']-row['d1']).days < 4:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "def all_consecutive_absences(absences, date_range=None):\n",
    "    \"\"\"\n",
    "    Returns the all instances of multiple consecutive absences/tardies\n",
    "    :param dataframe absences: dataframe with student_lookup and date columns\n",
    "    :param pair date_range: pair of dates, (lower_bound, upper_bound)\n",
    "    :rtype: list of ints\n",
    "    \"\"\"\n",
    "    if date_range:\n",
    "        absences = absences[(absences['date']>date_range[0]) & (absences['date']<date_range[1])]\n",
    "    absent_dates = absences.sort_values(['student_lookup','date'])[['student_lookup','date']]\n",
    "    date_pairs = pd.DataFrame()\n",
    "    date_pairs['s1'] = absent_dates[:-1]['student_lookup'].values\n",
    "    date_pairs['s2'] = absent_dates[1:]['student_lookup'].values\n",
    "    date_pairs['d1'] = absent_dates[:-1]['date'].values\n",
    "    date_pairs['d2'] = absent_dates[1:]['date'].values\n",
    "    delta = date_pairs.apply(next_day, axis=1)\n",
    "    return [sum(1 for i in g)+1 for d, g in groupby(delta) if (d==1)] # check this logic\n",
    "\n",
    "def consecutive_absences(absences, student_lookup, date_range=None):\n",
    "    \"\"\"\n",
    "    Returns instances of multiple consecutive absences/tardies for a \n",
    "    particular student\n",
    "    :param dataframe absences: dataframe with student_lookup and date columns\n",
    "    :param int student_lookup:\n",
    "    :param pair date_range: pair of dates, (lower_bound, upper_bound)\n",
    "    :rtype: list of ints\n",
    "    \"\"\"\n",
    "    if date_range:\n",
    "        absences = absences[(absences['date']>date_range[0]) & (absences['date']<date_range[1])]\n",
    "    student = absences[absences['student_lookup']==student_lookup]\n",
    "    student = student.sort_values('date')['date']\n",
    "    delta = student[1:].reset_index()- student[:-1].reset_index()\n",
    "    delta_list = [d.days for d in delta['date']]\n",
    "    return [sum(1 for i in g)+1 for d, g in groupby(delta_list) if (d==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if i==0 and date_pairs.iloc[i, 4]==1.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i, 2]\n",
    "    elif date_pairs.iloc[i, 4]==1.0 and date_pairs.iloc[i-1, 4]==0.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i, 2]\n",
    "    elif date_pairs.iloc[i, 4]==1.0 and date_pairs.iloc[i-1, 4]==1.0:\n",
    "        date_pairs.iloc[i, 5] = date_pairs.iloc[i-1, 5]\n",
    "    else:\n",
    "        date_pairs.iloc[i, 5] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_lookup</th>\n",
       "      <th>date</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_lookup        date  delta\n",
       "0               1  2012-12-17    1.0\n",
       "1               1  2012-12-20    1.0\n",
       "2               1  2013-01-08    3.0\n",
       "3               1  2013-02-11    2.0\n",
       "4               1  2013-04-10    1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "df = date_pairs.iloc[:1000, :]\n",
    "df = pd.DataFrame(df.groupby(['s1', 'starting_date'])['delta'].sum()).reset_index()\n",
    "df = df.rename(columns={'s1':'student_lookup', 'starting_date':'date'})\n",
    "df.head()\n",
    "df.merge(absences[['student_lookup', 'grade', 'date']], how='left', on=['student_lookup', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constructing 4 columns of clean.all_absences: aggregate consecutive days from clean.absences\n",
    "\"\"\" Generate consecutive absences columns (not generating features year)\n",
    " Generate New Columns in clean.absence: \n",
    " - absence_starting_date, \n",
    " - absence_consec_count, \n",
    " - tardy_starting_date, \n",
    " - tardy_consec_count\n",
    " \n",
    " Procedures:\n",
    " - obtain all distinct lookups from clean.absences;\n",
    " - break them into chunks to process chunk by chunk(memory cannot hold all data);\n",
    " - generate dataframes with number of consecutive days for a starting date\n",
    " - export to postgres and index student_lookups and date\n",
    " - join and update to clean.all_absences\n",
    "\"\"\"\n",
    "import os, sys\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def read_absences_lookups(conn, lookups = None):\n",
    "    \"\"\" Read data of certain lookup-chunk\n",
    "    \"\"\"\n",
    "    sqlcmd = \"\"\"select * from clean.all_absences \n",
    "    where student_lookup in {0} \n",
    "    order by student_lookup, date; \"\"\".format(str(tuple(lookups)))\n",
    "    return pd.read_sql_query(sqlcmd, conn)\n",
    "\n",
    "\n",
    "def consec_agg(df, desc_str='absence'):\n",
    "    \"\"\" Aggreate consective days of a certain type\n",
    "    :return pd.dataframe sumdf: sumdf with lookups, dates, counts \n",
    "    \"\"\"\n",
    "    new_date_col, new_cnt_col = desc_str+'_starting_date', desc_str+'_consec_count'\n",
    "    subdf = df[[desc_str in desc for desc in df.absence_desc]]\n",
    "    starting_dates=[None] * (subdf.shape[0])\n",
    "    for i in range(subdf.shape[0]-1):\n",
    "        row1, row2 = subdf.iloc[[i]], subdf.iloc[[i+1]]\n",
    "        index = row1.index[0]\n",
    "        if row1.student_lookup.values[0]==row2.student_lookup.values[0]:\n",
    "            if (((row2.date.values[0]  - row1.date.values[0]).days == 1) or  \n",
    "            (row2.weekday.values[0]==1 and row1.weekday.values[0]>4 and \n",
    "             (row2.date.values[0]-row1.date.values[0]).days<4)):\n",
    "                if starting_dates[i]==None:\n",
    "                    starting_dates[i]=row1.date.values[0]\n",
    "                    starting_dates[i+1]=row1.date.values[0]\n",
    "                else:\n",
    "                    starting_dates[i]=starting_dates[i-1]\n",
    "                    starting_dates[i+1]=starting_dates[i-1]\n",
    "    subdf[new_date_col] = starting_dates\n",
    "    sumdf = subdf.groupby(by=['student_lookup', new_date_col]).count().reset_index()[['student_lookup', new_date_col,'month']]\n",
    "    sumdf = sumdf.rename(columns={'month':new_cnt_col})\n",
    "    sumdf = sumdf.merge(subdf[['student_lookup', 'date']], how='left', left_on=['student_lookup', new_date_col], right_on=['student_lookup', 'date'])\n",
    "    return(sumdf.drop('date', axis=1))\n",
    "\n",
    "\n",
    "def update_absence(cursor, table='clean.all_absences', col='absence'):\n",
    "    col_date, dtype_date = col+'_starting_date', 'date'\n",
    "    col_cnt, dtype_cnt = col+'_consec_count', 'int'\n",
    "    if col=='absence':\n",
    "        table_intermed = 'public.intermed_'+col[:3]+'_agg'\n",
    "    else:\n",
    "        table_intermed='public.intermed_tdy_agg'\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {table} drop column if exists {column};\n",
    "    alter table {table} add column {column} {dtype} default null;\n",
    "    \"\"\".format(table=table, column=col_date, dtype=dtype_date )\n",
    "    cursor.execute(sql_add_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {table} drop column if exists {column};\n",
    "    alter table {table} add column {column} {dtype} default null;\n",
    "    \"\"\".format(table=table, column=col_cnt, dtype=dtype_cnt)\n",
    "    cursor.execute(sql_add_column)\n",
    "    \n",
    "    sql_join_cmd = \"\"\"\n",
    "    update only {table} t1\n",
    "    set {column_date}=t2.{column_date},\n",
    "        {column_cnt} =t2.{column_cnt}\n",
    "    from {table_intermed} t2\n",
    "    where t1.student_lookup=t2.student_lookup \n",
    "    and t1.date=t2.{column_date}\n",
    "    and t1.absence_desc like '%{col}%';\n",
    "    \"\"\".format(table=table, column_date=col_date, column_cnt=col_cnt,\n",
    "               table_intermed=table_intermed, col=col)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    \n",
    "    print(\"\"\" - updated {table}.({col1}, {col2}) from {tab_int}; \"\"\".format(\n",
    "            table=table, col1=col_date, col2=col_cnt, tab_int=table_intermed))\n",
    "    \n",
    "def main():\n",
    "    chunksize = 100\n",
    "    schema, table = 'clean', 'all_absences'\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            print('------ Running generate_consec_absence_columns.py -------')\n",
    "            lookups = list(pd.read_sql_query('select distinct student_lookup from clean.all_absences;', connection).student_lookup)\n",
    "            random.shuffle(lookups)\n",
    "            lookups = lookups[:2000]\n",
    "    #         sql_add_column = \"\"\"alter table {schema}.{table} drop if exists column {column};\n",
    "    #         alter table {schema}.{table} add column {column} {dtype} default null;\n",
    "    #         \"\"\".format( schema=schema, table=table, column=new_date_col, dtype=dtype_date)\n",
    "    #         #cursor.execute(sql_add_column)\n",
    "    #         sql_add_column = \"\"\"alter table {schema}.{table} drop if exists column {column};\n",
    "    #         alter table {schema}.{table} add column {column} {dtype} default null;\n",
    "    #         \"\"\".format( schema=schema, table=table, column=new_cnt_col, dtype=dtype_cnt)\n",
    "            #cursor.execute(sql_add_column)\n",
    "\n",
    "            print(' - generating agggated dataframe of absences...')\n",
    "            final_abs_df = pd.DataFrame()\n",
    "            final_tdy_df = pd.DataFrame()\n",
    "            for chunk_lookups in chunks(lookups, chunksize):\n",
    "                df = read_absences_lookups(connection, lookups=chunk_lookups)\n",
    "                final_abs_df = final_abs_df.append(consec_agg(df, desc_str='absence'), ignore_index=True)\n",
    "                final_tdy_df = final_tdy_df.append(consec_agg(df, desc_str='tardy'), ignore_index=True)\n",
    "\n",
    "            print(' - writing agg-dataframes to public...')\n",
    "            eng = postgres_engine_generator()\n",
    "            final_abs_df.to_sql('intermed_abs_agg', eng, index=False, if_exists='replace')\n",
    "            final_tdy_df.to_sql('intermed_tdy_agg', eng, index=False, if_exists='replace')\n",
    "\n",
    "            sql_index_intermed=\"\"\"create index public_intmed_abs_sl on public.intermed_abs_agg (student_lookup);\n",
    "            create index public_intmed_tdy_sl on public.intermed_tdy_agg (student_lookup);\n",
    "            create index public_intmed_abs_sl_dt on public.intermed_abs_agg (student_lookup, absence_starting_date);\n",
    "            create index public_intmed_tdy_sl_dt on public.intermed_tdy_agg (student_lookup, tardy_starting_date);\n",
    "            \"\"\"\n",
    "            cursor.execute(sql_index_intermed)\n",
    "\n",
    "            print(' - updating clean.absence by joining...')\n",
    "            update_absence(cursor, table='clean.all_absences', col='absence') # changed from absence_test to absence; run again\n",
    "            update_absence(cursor, table='clean.all_absences', col='tardy')\n",
    "            print(' - Done!')\n",
    "            \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definite</th>\n",
       "      <th>abs_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.444407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.658087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   definite    abs_sum\n",
       "0       0.0  39.444407\n",
       "1       1.0  56.658087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>definite</th>\n",
       "      <th>cons_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.982605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.840580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   definite  cons_sum\n",
       "0       0.0  2.982605\n",
       "1       1.0  7.840580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>abs_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.479433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.822493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_on_time    abs_sum\n",
       "0            0  39.479433\n",
       "1            1  39.822493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>cons_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.98076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.08261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_on_time  cons_sum\n",
       "0            0   2.98076\n",
       "1            1   5.08261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 844 ms\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        absence = read_table_to_df(connection, table_name='absence', schema='model', nrows=-1)\n",
    "        outcome = read_table_to_df(connection, table_name='outcome', schema='model', nrows=-1)\n",
    "abs_cols = list(filter(lambda x: 'absence_gr_' in x, list(absence.columns)))\n",
    "cons_cols = list(filter(lambda x: 'absence_consec_gr_' in x, list(absence.columns)))\n",
    "\n",
    "dfabs = pd.DataFrame()\n",
    "dfabs['student_lookup'] = absence['student_lookup']\n",
    "dfabs['abs_sum'] = absence[abs_cols].sum(axis=1)\n",
    "\n",
    "dfcons = pd.DataFrame()\n",
    "dfcons['student_lookup'] = absence['student_lookup']\n",
    "dfcons['cons_sum'] = absence[cons_cols].sum(axis=1)\n",
    "\n",
    "outcome_col = 'definite'\n",
    "dfabs1 = dfabs.copy().merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "dfcons1 = dfcons.copy().merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "\n",
    "\n",
    "outcome_col = 'not_on_time'\n",
    "dfabs2 = dfabs.copy().merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "dfcons2 = dfcons.copy().merge(outcome[['student_lookup', outcome_col]], how='left', on=['student_lookup'])\n",
    "\n",
    "display(dfabs1.groupby(by='definite').mean().reset_index().iloc[:,[0, 2]])\n",
    "display(dfcons1.groupby(by='definite').mean().reset_index().iloc[:,[0, 2]])\n",
    "display(dfabs2.groupby(by='not_on_time').mean().reset_index().iloc[:,[0, 2]])\n",
    "display(dfcons2.groupby(by='not_on_time').mean().reset_index().iloc[:,[0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.61744966442953"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "7.8/2.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fef3fabc7f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFCCAYAAAB8Ye0uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucD/Xix/HXLLkvqyzSV4g65ZI6EY5E5Ra5nnxIN7lU\nx9GJVKTaJKxkSYgSp+jCUIR16xSRW8rPSipyv7ZyWdZlWfv9/THf/bbf3e8yu75rXd7Px+P7YGc+\nM/OZ3Zl5z3zmM/O1vF4vIiIicnZhuV0BERGRS4ECU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMC9j\nxpgGuV0HkSuR9r3LkwLz8tYgtysgcoVqkPYHy7KusiyruWVZYy3LWm1Z1j7LspIsy9plWdY0y7Lq\nh2KhlmUNtiwrxfd5Lsj4xr5xBy3LKnOW+UzylZsdinpdLhSYIiI5725gNvAkUAb4HvgCOAC0BRZZ\nltX/fBZgWVZN4AUgBQj6gL3X610IjAcifP8Gm09L4BHgIND1fOp0uVFgiojkvBRgOlDP6/Ve5/V6\nW3q93oe8Xm91oANwBng1u1ealmXlAz4C9gFfnqP488BOoKllWZ3Tzac48B5O4D7r9Xr/yE59Llte\nr/dsHxERyWFdu3b1hoWFebt27Zqt6V988UVvWFiYd86cOd5OnTp5w8LCvDExMZmWX7hwodeyLG9E\nRIR3165d/uEdOnTwWpblbd26dbbqcZnJkIl5zxWoe/bsuRC5LTkgPDyco0eP5nY1RK44Wd33KlSo\ngNfrZfPmzVk+5q5Zs4bhw4fTpk0bbr/9diZNmgRAQkJCpvOqUqUKHTt25NNPP+XRRx/l448/Zu7c\nuUydOpXixYvTv3//K/rYX6ZM8Nu7apIVEcllW7ZsAaBkyZJZmi4pKYmePXtSvHhxBgwYkKVpX3vt\nNa677jq+/fZbRo0aRb9+/bAsi4EDBxIZGZmleV0pFJgiIrlo//79TJ8+HcuyaN68eZamHTJkCFu3\nbmXgwIFERERkadrChQszbNgwvF4vb775JgcOHKBp06a0atUqS/O5kigwRURyyZkzZ+jRowdHjhyh\nXr163Hfffa6nXb16NRMmTKBp06Y88MAD2Vp+vXr1qF69OgB58+Zl8ODB2ZrPlUKBKSKSS/r06cOy\nZcvweDy88847rqc7efIkvXr1omjRokRHR2d7+bGxscTFxWFZFsnJycTGxmZ7XlcCBaaISC6Iiopi\nypQplCpViqlTp1KiRAnX00ZHR7N9+3aioqKyNF1aBw8e9N+37Ny5s3++u3btytb8rgSW9+xfIO29\nkntKXerUS1Ykd5xr33v99dcZP348kZGRTJs2jUqVKmVp/rVr12bv3r3UrFkzw7jNmzfz559/cv31\n13PttddSoUIF3nrrrQzlnnrqKWJjY2nRogVjx46lX79+TJo0ibp16zJ16tQs1edy4+sla6Uffs7H\nSkREJHQGDhzI+PHjueaaa5gyZUqWwzJVSkoKq1atynT8jh072LFjB4mJiRnGzZ49m9jYWCIjIxk0\naBAAr7zyCt988w3Lly9n8uTJPProo9mq1+VMV5iXMV1hiuSOzPa9wYMH8+6771K8eHGmTp1K5cqV\nQ77sXr16MX36dF599VWefPLJDOMPHjxIgwYNOHToEO+99x7NmjXzj1uyZAkdO3akSJEifP3111x3\n3XUhr9+lIEevMIsUKYJlZZi35LI8efIQHh6e29WQHOD1eoNeOcjF68033+Tdd9+lWLFifPbZZ67C\nMjo6mvnz53P//ffTt2/fLC0vs4uhPn36cPDgQVq2bBkQlgB33323/4UGL774Ip988kmWlnm5C0lg\nWpalKxmRC0gnQpeWhQsXMmrUKCzLokKFCkyYMCFouUqVKvHvf//b/3N8fDybN28mPj4+S8vLLCy/\n/PJL5s2bR2RkJAMHDgxaJioqikWLFrFkyRI+/fRTOnbsmKVlX850D1NEJIcdPnzY3woXFxdHXFxc\n0HK1a9cOCExwLkiy2oIXrPyBAwd49dVXCQsLY9CgQVx99dVBpy1SpAhDhw7lscceY+DAgdxzzz1c\ne+21WVr+5Sok9zB1r0zkwtI+d3HT3+fSpl6yIiIXiDchgUKXcWCeKVCApPz5c7saF5wCU0QkxKzj\nx4lYujS3q5FjDterB1dgYOpNPyIiIi4oMEVERFxQYF6BevbsicfjYffu3bldlRwVExODx+Nh5cqV\nuV0VEbkMXJB7mCesvBw7c/Fmc+E8KRT0Jodsflu2bGHSpEmsXLmSnTt3cuzYMQoXLkyFChWoVasW\nrVu3plq1aiFbXlZlp5t6qHg8HurUqcO0adNyfFm5uZ4icvm5IIF57EwYc/dfiCVlT7PIMAqGKM+H\nDx/O22+/jdfrpVq1arRq1YqIiAgSExP55Zdf+PDDD3n//fcZOHAgjz/+eGgWKiIiOU69ZENo+PDh\nDB8+HI/Hw5gxY7jjjjsylDl48CDjx4/XM1oiIpeYi7ed9BKzY8cO3nnnHfLnz8/HH38cNCwBrr76\navr06UP37t39w1LvKe7cuZOJEyfSsGFDKlasSLt27QA4ffo0//3vf3n00UepVasWN9xwA1WqVKFD\nhw4sWrQo0zotWbKENm3acOONN1KlShW6dOnC77//HrTsihUr8Hg8jBgxIuj4WrVqUadOnYBhR48e\nZezYsRhjqFGjBhUqVODWW2/liSee4Mcffwwoa9s2Ho8Hy7L8y0r9pF/mmjVr6NatG7fffjsVKlSg\nZs2a9OnThz/++CNo3datW8fDDz/M3/72N26++WY6dOiQYfkiIudLV5ghMmXKFJKTk2nZsqWrr+sJ\nC/vrXCX1Xturr77K6tWruffee7nvvvvIkycP4LxW67XXXqNmzZrUr1+fq6++mvj4eL766iseffRR\nhg0bRocOHQLmP2fOHLp3706+fPlo1aoVkZGRrF69mlatWnHLLbdkef2C3QvctGkTQ4cOpXbt2jRs\n2JBixYqxZ88eFi5cyKJFi/joo4+oX78+AFWrVqV3797ExMRQtmxZjDH++aQN4ilTptCnTx/y589P\n48aNKVOmDFu3bmXKlCn873//Y/bs2alv4QBg9erVPPTQQyQnJ9OsWTPKlSvHzz//TLt27ahbt26W\n11NEJDMKzBD54YcfsCwr2wdpr9fL+vXrWbhwYYav1ClWrBjff/89pUuXDhiemJhIq1atGDhwIG3a\ntCG/70Hi48eP06dPH/LkycPMmTOpWrWqf5rUL64NRWeYm266iTVr1lC8ePGA4fv27aN58+b079/f\nfwVcuXJlKleu7O+52qtXrwzz27JlCy+99BLXX389n3/+OSVLlvSPW7ZsGQ899BCvvfYa48eP9w/v\n3bs3SUlJTJw4kUaNGvmHT5w4kaioKHX6EZGQUZNsiOzf7/RqSh9qALt27SImJsZ/j3P48OF88MEH\nAWUsy+Lf//530O+fy5cvX9D5FilShPbt25OQkBDwMucFCxaQkJBAmzZtAsIS4LnnnqNo0aLZWsdg\ny08fluD8Dpo3b87vv/9OVr5P9aOPPiI5OZnXX389ICwB6tatS+PGjfnqq684fvw44Fxdbtmyhdq1\naweEJUCnTp0oV65cNtZKRCQ4XWFeADt37mTEiBH+qx2v10vZsmXp2rVrQLnq1atnOo+NGzfy7rvv\n8v333/PHH3+QlJTkH2dZFnv37vX//NNPP2FZFrVq1cown/DwcCpXrnzWb2rPitWrV/PBBx+wZs0a\nDhw4wKlTpwLqtW/fvoAm1LNZs2YN4NxPXbt2bYbxf/75J2fOnGHLli1UrVqV9evXA843PKQXFhbG\nnXfeyY4dO7KzWiIiGSgwQyQyMpLff/+dffv2ZRhXp04ddu3aBUBKSgrXX3990Hmkv6pK9eOPP9K+\nfXtSUlL8V1rh4eGEhYXx888/s2DBgoCgSu2BGxkZmaXlZNW8efN46qmnKFCgAHfffTflypWjUKFC\nhIWFsWzZMlatWhVQr3M5dOgQAOPGjcu0jGVZHDt2DIAjR45gWRYlSpQIWjZU6ykiAgrMkKlZsybL\nly/nu+++o3379pmWO9vXqWV2v23kyJEkJSUxffr0DFeNo0ePZsGCBQHDUr9cOLWZOL1gX0ab2gkp\nOTn4CxyOHDlCsWLFAoa99dZb5MuXj3nz5lGxYsWAcfv27cvyVWxqU/Fvv/1GoUKFXJX3er38+eef\nQcdn9Ut3RUTORvcwQ8QYQ968eZk7d26mj25k1/bt24mIiAjaxLpixYoMw6pVq4bX6w36SrijR4+y\nYcOGDMNTwzDYPcetW7dy5MiRoPW66aabMoSl1+vl+++/D7ouYWFhpKSkBB3397//HcD1q+xS788G\n+x2kpKRkWgcRkexQYIZIuXLlePbZZ0lKSuKRRx7hhx9+CFouISEhy/MuW7Yshw8f5tdffw0Y/tln\nn/Htt99mKN+kSROKFSvGzJkzWbduXcC4YcOGBQ2/SpUqER4ezsKFCzl48KB/+MmTJ4mKigpaL4/H\nw9atWzNcyQ0bNoxNmzYFnaZ48eKZdgTq1KkTefPmpX///mzZsiXD+NOnTweEYM2aNalYsSKrVq1i\n4cKFAWUnTpzI9u3bgy5HRCQ71CQbQqmPSrz99tu0bt2aW2+9ldtuu42IiAiOHDnCzp07+e6777As\nK2hHlcx07dqVxYsX07p1a1q0aEF4eDjr1q1j9erVPPDAA8yZMyegfKFChRg6dCjdu3enTZs2tGzZ\nkpIlS7J69Wp+++03ateunaG5NG/evHTp0oWRI0fSqFEj7r//fpKTk1m6dCmlS5emVKlSGerVrVs3\nXnrpJRo3bkyzZs3ImzcvP/zwA5s2bfL3aE3vrrvuYtasWXTq1Ilq1aqRN29eateuTa1atahUqRIx\nMTE8//zz3HvvvTRo0IAbbriB5ORkdu/ezapVqyhRogSLFy/2z2/YsGF07NiRbt26cf/991O+fHl+\n/vlnli9fzj333BNQVkTkfCgwQ6xXr160atWKyZMns3z5cr788kuOHz9O4cKFKV++PI8//jht27bN\n8LjH2Z4XbNCgAR999BEjR45k9uzZ5MmTh9tvv51p06axbds2YmNjM0zTvHlzPv74Y0aMGMGcOXPI\nly8fderUYdasWYwePTpoc+Xzzz9PoUKF+OSTT/j000+JjIykdevW9OrViwYNGmSo4yOPPEL+/Pn5\n4IMPmD59OgUKFKBWrVqMGDGC2NjYoIE5YMAAwsLC+O6771i0aBEpKSk899xz/ubmtm3bUqVKFd57\n7z2WL1/O0qVLKViwIKVLl+aBBx6gZcuWAfOrWbMmM2bM4M033/SH49///nemTZvG4sWLFZgiEjLW\n2TqhAF43z9GFh4ef9d2oV9q3lYjktHPtc5K7whMTCb+MT9YO16vH8XSdAC8nvkfhMlzFXJArzILe\n5JB9G0iOOOs5g4iIiDr9iIiIuKLAFBERcUGBKSIi4oICU0RExAUFpoiIiAsKTBERERcUmCIiIi4o\nMEVERFxQYIqIiLigwBQREXFBgSkiIuKCAlNERMQFBaZctHbt2oXH4+G5557L7arkOI/HQ7t27XK7\nGiJyFhfk20ryJyWR5+TJC7GobDlToABJ+fOf93w8Ho//3yVLlpAvX74MZWrVqsWePXvYvn07YWHZ\nP1+pVasWYWFhrFixIlvTJycnM2PGDObPn8+6des4ePAglmURGRlJlSpVuO+++2jdujUFCxbMdh0v\nZTExMYwYMYLp06dn6cu+ReTydUECM8/Jk0QsXXohFpUth+vVgxAEJjhfBL17924++OADunfvHnR8\nqJaTXb///jvdunVj06ZNFCtWjLp163L99deTJ08e9u3bx6pVq5g/fz5DhgwhLi4uJPW91FiWFbK/\nlYhcHi5IYF5JihUrhmVZjBkzhoceeojixYvndpUCxMfH0759e+Lj4+nSpQt9+/YNehW5dOlSBg4c\nmAs1vDic44vVReQKpHuYIVawYEF69uxJQkICI0aMyNK0s2bNom3bttxyyy1UrFiRhg0bMnr0aE6d\nOuUvs2LFCjweD7t372bnzp14PB7/x829viFDhvDHH3/Qpk0bXn/99UybXOvVq8e8efMChqW9p7hl\nyxaefvppqlevTtmyZVm5ciUAP/30E1FRUTRq1IgqVapQsWJF7rrrLgYMGEBCQkLQZR07doz+/ftT\no0YNKlasSP369Xn//fdJSUkJWv7BBx/0N3+nZ9s2Ho+HadOmBQxfvnw5L774Ivfccw8333wzFStW\n5L777mPEiBEkJSUFlK1du7b/b5e6LI/HQ9myZQPKnThxglGjRtG4cWNuvPFGbrrpJlq2bMmXX34Z\ntG6nT59mxIgR1K1blxtuuIE6deowdOjQgL+viFy8dIWZAzp16sTEiRP5+OOP6dy5M+XLlz/nNNHR\n0YwZM4ZrrrmGNm3aULhwYRYtWsSQIUP49ttv+eyzz8ibNy9ly5ald+/ejB8/Hsuy6Nq1q38eVapU\nOesyTpw4wZdffollWa7CNbN7rNu2baNFixbccMMNtG3blpMnT1KkSBEAPvnkExYsWEDt2rW5++67\nSUlJ4aeffuL9999n8eLFzJkzh0KFCvnnderUKYwxxMXFUaVKFf75z3+SkJDAyJEj/SEczNmaS4ON\ne/fdd9m8eTM1atSgYcOGJCUlsXr1amJiYlixYgVTp071T9etWzfmz5/PypUrMcZkCEqAI0eO0K5d\nOzZs2EC1atV46KGHSElJYfHixfz73/9m48aNvPDCCwHTPPXUUyxcuJDy5cvzxBNPcPr0aaZOncqv\nv/6a6bqIyMVDgZkD8uTJQ79+/XjqqacYNGgQ48ePP2v5H3/8kTFjxuDxeIiNjeWaa64B4KWXXqJz\n5858/fXXjBs3jh49euDxeOjVq5f/AN+rVy/X9Vq3bh1JSUmUKVPGVYhnZvXq1TzzzDO8+OKLGcY9\n88wzREdHZwitqVOn0rt3bz766CP+9a9/+YePGzeOuLg4mjdvznvvvecf3qNHD5o0aRKy+4jR0dFB\ng2/YsGGMHDmSOXPm0KJFCwC6dOlCQkKCPzCDdfqJiopiw4YNvPzyyzz99NP+4adOnaJz586MGjWK\n5s2bU7lyZQBmzJjBwoULqVGjBrZt+zuE9e7dm2bNmul+qcglQE2yOaR58+bccccdzJ8/n9WrV5+1\n7JQpU7Asi2effdYfluBc4UVFRWFZFp999tl51yk+Ph6A0qVLBx1v2zbDhw8P+GzYsCFDucjIyEyD\n+rrrrgt68DfGEB4ezuLFiwOGT506lTx58vDyyy8HDPd4PHTp0iVk9xKDhSXgX8a3337rel6HDh1i\nxowZVK9ePSAsAfLly0e/fv1ISUlh5syZ/uGpJzh9+/YN6D1drFgxnn32Wd0zFbkE6AozB0VFRdGq\nVSveeOMNZs2alWm59evXA/CPf/wjw7gbbriBa6+9lh07dpCYmOhv+swJtm2zatUqwOn0YlkWZcuW\n9V8lpapcuTJXXXVV0HkkJyczefJkZs2axcaNGzl69GjAvch9+/b5/3/s2DG2b9/Oddddx/XXX59h\nXnXq1AnFagFOc/T48eNZsGABW7ZsITEx0R9SlmUF1Otc4uLiOHPmDADDhw/PMD71nuSmTZv8w9av\nX09YWBg1a9bMUD7Y311ELj4KzBx0xx130Lx5c+bOncvs2bP9TX7pHTlyBICSJUsGHV+yZEn27NlD\nQkLCeQVm6vz/+OOPoOOnT5/u///QoUMZNWpU0HKRkZGZLuPpp59m/vz5lCtXjqZNmxIZGUl+3yM7\n48ePD+jgkrremc3vbMvJiuTkZNq1a8fatWu5+eabadmyJddcc40/9GNiYjJ0/DmbQ4cOAU5wZvbY\njWVZHD9+3P/z0aNHiYiIIE+ePBnKhmo9RSRnKTBz2EsvvcTChQsZMmQITZs2DVqmaNGiAOzfvz/o\nlVZqU2pquey69dZbyZ8/P3v27GHbtm3Zvo+Z2f22devWMX/+fOrXr8/kyZMDOg15vV7GjBkTUD7t\negeT2fDU+aakpGTomJQawmktWLCAtWvX0qFDB4YNGxYwLj4+npiYmKDLyUx4eDjgdA6KiopyPc3h\nw4c5c+ZMhtDMbD1F5OKie5g5rHz58jz22GPs2LGDiRMnBi1TtWpVgKBv7dm2bRt79+7l+uuv9x+o\nwelYlNos6FbBggVp1aoVXq83y4+8uLF161YAGjVqlCHI1qxZw8l0b3sqXLgw5cuXZ9++fezYsSPD\n/JYvXx50OcWKFQNgz549GcYFu+Lbtm0blmUFPWHJ7E1JqfUP9ju+/fbbCQsL4/vvvw86bTDVqlUj\nJSUl6DTLli1zPR8RyT0KzAugV69eFC1alHfeeYdjx45lGN++fXu8Xi8jR47k4MGD/uEpKSkMGDAA\nr9fLQw89FDBN8eLFOXDgQJaaEgH69OlDqVKl+OKLL+jfvz8nTpwIWi7Yldq5pHasSR90f/75J6+8\n8krQadq3b8+ZM2cYNGhQQMeX1BOMYFezt99+O16vl08++SRg+NKlS4M+A+nxePB6vRnCcfv27Qwe\nPDjoMooXL47X62X37t0ZxqU++hMXF8fbb78d9HnR7du3s3PnzoD19Hq9vPnmmwF/s0OHDvHOO++o\nl6zIJUBNshdAREQEzzzzjP/NOekPjjVq1KB79+6MHTuWe++9l+bNm1OoUCEWLVrEb7/9Rq1atTL0\nxqxbty5xcXE8/PDD1KpVi3z58lG5cmUaNWp01rqUKlUK27bp1q0bEyZMYNq0adStW5dy5coRFhZG\nfHw8P/zwA1u3bqVkyZJUqlTJ9Xredttt1KxZk3nz5tGqVSvuvPNO9u/fz6JFi6hUqRKlSpXKMM1T\nTz3FggULmDt3Lk2aNKFBgwYcPnyY2NhYateuzYIFCzJM0759e8aOHcvo0aP5+eefuemmm9iyZQuL\nFy/m/vvvJzY2NqB848aNKV++PO+//z6//PILVatWZdeuXXz99dc0bNgwaMjWrVuXsLAwoqOj+fXX\nX/1Xtc8++ywAgwYNYtu2bcTExPD5559z5513UqJECf744w9+//134uLiGDNmjP8konXr1syaNYuv\nvvqKe++9lyZNmpCcnExsbCy33XYb27dvd/17FpHcYZ2jO7s3WLNXeuHh4Rw9ejTT8YUSEi76d8ke\n9x0Qz4fH46FMmTJBm91OnTpFgwYN2LlzJ5ZlsW3btgzNlrNmzeLDDz9kw4YNnD59mvLly9OmTRue\nfPLJDC9yP3HiBG+88QZfffUV+/fv58yZM7Rr1y5or81gkpOTmTlzJnPnzmXdunUcOnQIy7IoUaIE\nVapUoXHjxrRs2TLgTUC7du2iTp06GGMyve+XkJDA0KFD+eabb4iPj6d06dK0atWK//znPzRo0ICw\nsLAMV6DHjh0jJiaGWbNmcejQIcqWLcvDDz9MkyZNqFu3btDlbdq0iTfeeIPvv/8er9fLrbfeygsv\nvMC2bdvo3bs3w4cPD/j2j7179zJ48GBWrFjB4cOHKVeuHO3ataNbt26UL1+eOnXqYNt2wDJmzJjB\nuHHj2Lx5M0lJSViWFdB0nJyczMcff8zMmTPZuHEjSUlJlChRggoVKtC4cWPatm1LREREQPnRo0cz\nbdo09u3bR8mSJWnbti09e/b0v/knfR0yc659TnJXeGIi4ekeobqchOqYebEqU6YMQIZmnwsSmFfK\nt5WIXCgKzIubAvPSlllgXpAm2aT8+UP2bSAiIiK5QZ1+REREXFBgioiIuKDAFBERcUGBKSIi4oIC\nU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLgQklfjeb3egO9qlItDdr4zUy4N53gH\ntIjkgJAEZmJiYihmIyGmF3SLiISOmmRFRERcUGCKiIi4oMAUERFxQYEpIiLiggJTRETEBQWmiIiI\nCwpMERERFxSYIiIiLigwRUREXFBgioiIuKDAFBERcUGBKSIi4oICU0RExAUFpoiIiAsKTBERERcU\nmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKCAlNERMQFBaaIiIgLCkwREREXFJgiIiIuKDBF\nRERcUGCKiIi4oMAUERFxQYF5hdm8eTMTJkzgmWeeoX79+pQtWxaPx8PcuXNDtozo6Gg8Hg8ej4f3\n3nsvw/hvv/0Wj8dDlSpV2LdvX6bz+c9//oPH4+Hxxx8PWd1ERLJLgXmFmTRpEq+99hozZ85ky5Yt\nAFiWFbL5r127lnHjxhEWFpbpfOvXr0/Hjh1JSEjghRdeCFpm4cKFfPHFF0RERDBs2LCQ1U9EJLsU\nmFeYW265he7duzNu3DiWLVtGrVq1QjbvU6dO0bNnTyIjI2nSpMlZy0ZFRVGmTBkWL17MlClTAsYd\nPnyYPn36YFkWAwYMIDIyMmR1FBHJrry5XQG5sDp06JBj837rrbfYvHkz//3vf4mNjT1r2SJFijBs\n2DA6duzIgAEDqF+/Ptdeey0A/fr1Y//+/TRp0oS2bdvmWH1FRLJCV5gSEmvWrOH999+nTZs2NGzY\n0NU0d999Nx07duTIkSP+ptm5c+cya9YsihcvzpAhQ3KyyiIiWaLAlPOWlJREz549KV68OAMGDMjS\ntK+99hrXXXcd3377LaNGjaJfv35YlsXAgQPVFCsiFxUFppy3IUOGsHXrVgYOHEhERESWpi1cuDDD\nhg3D6/Xy5ptvcuDAAZo2bUqrVq1yqLYiItmjwJTzsnr1aiZMmEDTpk154IEHsjWPevXqUb16dQDy\n5s3L4MGDQ1lFEZGQUGBKtp08eZJevXpRtGhRoqOjsz2f2NhY4uLisCyL5OTkc3YYEhHJDQpMybbo\n6Gi2b99OVFQUJUqUyNY8Dh486L9v2blzZ/98d+3aFcqqioicNz1WItm2YMECwsLCsG0b27YDxm3e\nvBlwXpTw1VdfUaFCBd56660M83jppZc4cOAALVq04PXXX+f06dNMmjSJ3r17M3Xq1AuyHiIibigw\n5bykpKSwatWqTMfv2LGDHTt2kJiYmGHc7NmziY2NJTIykkGDBgHwyiuv8M0337B8+XImT57Mo48+\nmmN1FxG9R5kcAAAWS0lEQVTJCjXJSratXLmSnTt3Bv08+OCDALz66qvs3LmT+fPnB0x78OBBXn75\nZSzLYtCgQVx99dUAFCpUiKFDh+L1ehk0aBC7d+++4OslIhKMAlPOKTo6mvr162frRQJerzfo8D59\n+nDw4EFatGhBs2bNAsalvtAgMTGRF198MVt1FhEJNTXJXmHWr19P3759/S9G37RpE16vl+joaMaO\nHesvN3v2bP//4+Pj2bx5M/Hx8VlaVmZh+eWXXzJv3jwiIyMZOHBg0DJRUVEsWrSIJUuW8Omnn9Kx\nY8csLVtEJNQUmFeYo0ePEhcXFzDMsiy2bdsW8HN6lmVl+VtNgpU/cOAAr776KmFhYQFNsekVKVKE\noUOH8thjjzFw4EDuuece/7tmRURyg5XZVYCPd8+ePReqLhJi4eHhHD16NLerIXLFCU9MJHzx4tyu\nRo45XK8ex4sVy+1q5JgyZcoAZDjj1z1MERERFxSYIiIiLuge5mXMm5BAocu4SfZMgQIk5c+f29UQ\nkSuEAvMyZh0/TsTSpbldjRxzuF49UGCKyAWiJlkREREXFJgiIiIuKDBFRERcUGCKiIi4oMAUERFx\nQYEpIiLiggJTRETEBQWmiIiICwpMERERFxSYIiIiLigwRUREXFBgioiIuKDAFBERcUGBKSIi4oIC\nU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKCAlNERMQFBaaI\niIgLCkwREREX8uZ2BS5lmzdvZvHixaxdu5Z169axZcsWvF4v77//Ps2aNcv2fGfMmMGkSZP49ddf\nOXPmDJUqVcIYw+OPP45lWSFcA5FLk/Y9yQ0KzPMwadIkJkyYELAjne9O1a9fPyZNmkSBAgW46667\nuOqqq/juu+945ZVXWLZsGePHjz/faotc8rTvSW5QYJ6HW265he7du1O9enWqVavGc889x6pVq7I9\nv9jYWCZNmkSpUqX44osvKFeuHAAHDhzgwQcfZP78+UycOJHOnTuHahVELkna9yQ3KDDPQ4cOHUI6\nv9GjR2NZFi+//LJ/hwW45ppriI6O5sEHH2TMmDHaaeWKp31PcoM6/Vwk9u7dy08//US+fPlo3rx5\nhvG1a9emdOnSxMfH8+OPP+ZCDUUuT9r3xC0F5kVi/fr1ANx0003kz58/aJnbbrstoKyInD/te+KW\nAvMisXPnTgA8Hk+mZcqUKRNQVkTOn/Y9cUuBeZE4duwYAAULFsy0TOHChfF6vSQmJl6oaolc9rTv\niVsKTBERERcUmBeJwoULA3DixIlMyxw7dgzLsihSpMiFqpbIZU/7nrilwLxIpN4/2bVrV6Zl9u7d\nG1BWRM6f9j1xS4F5kahatSoAGzduJCkpKWiZtWvXBpQVkfOnfU/cUmBeJMqUKUO1atU4deoUc+bM\nyTB+xYoV7N27l5IlS1KjRo1cqKHI5Un7nrilwLzAoqOjqV+/PkOGDMkwrkePHni9XgYPHsy2bdv8\nw//880/69euHZVn06NHjAtZW5PKhfU/Ol16Ndx7Wr19P3759/S993rRpE16vl+joaMaOHesvN3v2\nbP//4+Pj2bx5M/Hx8Rnm17x5cx5//HEmTZrEfffdR7169fwvgE5MTKRp06Z06tQpx9dL5GKnfU9y\ngwLzPBw9epS4uLiAYZZlBZyhBvsGBcuyMv1mhUGDBnHnnXfy4YcfsmrVKv9XDHXo0IHHHnsspPUX\nuVRp35PcYHm93rON9+7Zs+dC1UVCLDwxkfDFi3O7GjnmcL16HC9WLLerIZKB9r1Lm+/NThnOrHQP\nU0RExIUrukn2hJWXY2cu33OGgilnbT0QyTXa9+RSdEUH5rEzYczdn9u1yDndCuR2DUSC074nl6LL\n9xRPREQkhBSYIiIiLigwRUREXFBgioiIuKDAFBERcUGBKSIi4oICU0RExAUFpoiIiAsKTBERERcU\nmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKCAlNERMQFBaaIiIgLCkwREREXFJgiIiIuKDBF\nRERcUGCKiIi4oMAUERFxQYEpIiLiggJTRETEBQWmiIiICwpMERERFxSYIiIiLigwRUREXFBgioiI\nuKDAFBERcUGBKSIi4oICU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLigwBQREXFB\ngSkiIuKCAlNERMQFBaaIiIgLCkwREREXFJgiIiIuKDBFRERcUGCKiIi4oMAUERFxQYEpIiLiggJT\nRETEBQWmiIiICwpMERERFxSYIiIiLigwRUREXFBgioiIuKDAFBERcUGBKSIi4oICU0RExAUFpoiI\niAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKCAlNERMQFBaaIiIgLCkwREREX\nFJgiIiIuKDBFRERcUGCKiIi4oMAUERFxQYEpIiLiggJTRETEBQWmiIiICwpMERERFxSYIiIiLigw\nRUREXFBgioiIuKDAFBERcUGBKSIi4oICU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqI\niLigwBQREXFBgSkiIuKCAlNERMQFBaaIiIgLCkwREREXFJgiIiIuKDBFRERcUGCKiIi4oMAUERFx\nQYEpIiLiggJTRETEBQWmiIiICwpMERERFxSYIiIiLigwRUREXFBgioiIuKDAFBERcUGBKSIi4oIC\nU0RExAUFpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKC5fV6zzb+rCNF\nREQuU1b6Aee6wrT0uXQ/xpjXc7sO+uhzJX60710WnwzUJCsiIuKCAlNERMQFBeblbXFuV0DkCrU4\ntysgoXeuTj8iIiKCrjBFRERcUWCKiIi4oMDMJcaYFGPMxNyuh4i4Y4z50BiTktv1yApjzGJjzJbc\nrsflIm9uV+ByZIyJAPYC+YFHbdv+JJerJFcwY0xB4CmgLVAFCAcOAj8CNvCxbdtncq+GFw9jzONA\nhG3bI4OM9gIXTWAaY1YBNYEJtm13y6SYOqmEkK4wc8YjOGGZCHTO5brIFcwYUwlYC8QAJ4DBQDff\nz3mBicCgXKvgxacT8Gwm47oChS5cVTJnjKmCE5aJzo+mYC5X6YqgK8yc0Rn4CfgS6GeMKW/b9rbc\nrZJcaYwxBYA5QHmgrW3bX6Yr8pYx5g6cA6+cg+8q/GK5Eu8KnAaeBj4GDPBRrtboCqDADDFjzN+B\n23DOUmcDL+MEaFQm5e8DBgK3AkeAqcDLtm0fS1OmuG/6FsB1wDFgGzDFtu1h6ebXHugBVAfy4AT3\nW7Ztf56uXArwIfA+MASoAZwEZgDP2rZ9PF35Ur51ae6rQwIQB7xp2/bXacpVAl4D7gOuAfYA04D+\n6ecpOa4bcBMQHSQsAbBt+0ecplk/Y0xr4AWcbciL83ceatv2rHTltgFbgH8Bw4F6OE2WXwE9bNv+\nI03ZkG/DvrL3AM8DtYDCONvbIuBF27YPGmPq+37uZNv2pHTTfgg8Ztt2mO/nrUA53/9Tm169wD22\nbS8JUn4I8CJwq23b69PNuyjwBzDPtu22aYY39P1u7wQKABuBd23bfi/9umXGGHMV8DAwx7btT40x\nbwBdOEtgGmMqAG8D9XFe+/Y10Nu27a1pylg4x60ngAq+dd8LfAc8lbbZ3hhTA+d4cBdOE/82YBLO\n8SBtucXA9UBdnG2kCU7r21LgGdu2NwVZt17AQzjb7mlgE/Chbdtj0pQr6lt+W6AszrHzfzjHzq3k\nEDXJhl4XIAnnvtA24Bvg8UzK3oETUMuB3sAS4D/AzHTlpgPdca4WegD9gVU4G7+fMWYg8BnOxvMK\n0AfnwDTNGPOvIMu/HSfUv8fZSBf46j883XzLAWtwzma/AXoCQ3FCs2GacncAP+DsRON8dZ7tW6eF\nxpg8mfweJGc8iHPQG+92AmNMd+ALIAJ4HRgAFAdmGmO6pivuBTw4gbQNJ7g+wTmIpT94h3wbNsY8\nhXOQrAq865vvx8DfffVKW89gvOnGPQv8CuzHCaRHgEeBXzIpn7qOjwWZd3sgH85JaWp9n8TZxwrj\nnCT3An4Hxhpj3sykjsG0xjkZneD7eSJQ1xhzYybli+C8SOEk0Bf4AGgGfGeMKZmm3Cs4+/4WnBOB\n53G2hdo4IZe6Hs1xQrQSMAx4BucYNgD4NN2yvb71XYITfi8Bo4AGONuU/52tvrBcCEQD+4BXgX44\nx5Q2acoVBVbgHI9St6dRwD3ASmNM2Ux+D+dNV5ghZIzJj3NmNMO27UO+wR8Anxpjmti2vSDdJFWB\n1rZtz/b9PM4Ysxd4xhhjbNu2fRvHPThnoT3Psuy/42xcg2zbfjXNqNHGmBlAtDFmUtorV6AaUNu2\n7R98P483xhQDnjDGPJfminAsUBpoYtv2/87yK5gI7AZqpr2aNMZ8jXNi8DDOWahcGFWAI25vB/g6\nq72Jc0Z/Z+q2YowZi+8+qG+zPJJmsoqASXv1Z4zxAv8yxtxo2/amnNiGjTHXASOBDcA/bNs+mqb8\na+lmHfRF2unZtj3LGNMLKGDb9mcuyv9ijPkB6GiM6WPbdtowfQw4AMz1rVtpX30/tW370TTlxhlj\n3gaeM8aMdfm36oxzJT3P9/N/cU5AOuMEUnrXAG/btt07dYAxZilOGPbHOZEBJ4g32LbdJt30/dJM\nlx/nmLYCuDfNOo83xsQBw40xd9u2vSTN9CVwWihi0sznT5xtrSFOiwQ4JxD1yfj3T+8NnNsMtdJe\n2ftaANbjnOjlSN8RBWZo/RMoxl9nfuAExUGcP2D6wPwtTVimGoJzRdYGpwfjCZwr1lrGmHK2bW/P\nZNkP4zSHTTLGXJNu3GygFVAH54w81Yo0YZnqG+B+nA1yg68prQlO01KmYWmMqYoTwFFAwXSdEJbj\nXCU0RoF5IRXFOVN3qxHO1cA7aU+sbNtONMa8A4zAOcB9kWaaPUGaSr/Baaa9ESd8c2IbNsBVwOvp\nwvJC+wh4B+d3txDAGFMe+AcwyrbtZF+5djhXnBODrNscnH2+IU4YZcoY4/EtKzo1rGzb3mOMmQ88\nZox52bbtYD15A65gbdueaYz5DSckUwMzAbjdGFPXtu1lmVShEVAK50r1amNM2nHzcbaRxjhXlKlS\ncK4A0/oG50TmRv4KzI44x8o3Mlk2acotAfam+12eAFb6lp8jFJih1QX4E9hhjKmYZvgC4J/GmKtt\n2z6YZvgvpGPb9j5jzGHgBt/Pp40xPXHuP2w1xmzA2dhm2rb9TZpJb8ZpYv8tk7p5cTb0tII9n3XA\n92/qhlgJZ8Nem8l8U93i+ze1Gc/N8iVnHcG5v+RW6n2rDUHG/YyzHdyQbnhm25CFbxvKoW24ku/f\nc22XOe0znB7Hj+ELTP66BTM5Tbmb+eveYTBu948nfPNZmu4YsxCnmbUZTgCnddi27fgg8/oFaGWM\nKWjb9gmcK8kZwBJfS9diIBaYbtv2ad80qfv5f7OwHnts2z6Vblj64ww44fl/Qcr6GWMifdM0xmk6\nD7b8HOuYpXuYIeI7q2yA0/zwG86ZdernIZyzy0eyM29fh4DyOD3jfsS5kv2fMSbt/QIL50yuMc6Z\navpPIwKvLuHsG5arZqwg5WPOsvwXszhPOT/rgaK+bTOnuNqGcnAbPpezPYd43hcMvhPguUBrY0xh\n3+BHgF98HapSWb66PELm6+bmee1Ovn/nE3iMSX1uNNtNkbZtr8RpYn8QpxWhuq9Oa33N9WnXo/dZ\n1iMmcM45cpz5H07HwmDLb5rFebqmK8zQSd1Qu+I0baQ3yFfmnTTDbklfyHevI4J0Z+6+HocTcZp0\nLJzODR2MMTG+HXMTTtPpTtu2MztDz47fcXaQ285RLrW325l0Vw2Sez4H7sbZJl9xUX4LzgGpCk5H\nnrSq4GwH2X5rTIi34Y2+f2/D2UYzk9qic3WQcRWDDMvOg/4f4TRttjPGbPTNN/3JYer+cSC7+4cx\n5l6cVoDhOLc50usItDDGRNq2nfbqK8IYUzLIVeYtQLzv6hIAX9+DGb4Pvo5WY3Baz2J862EBx3Ng\nP98I3GyMuSrNFW16+4HDQFHbttNvozlOV5gh4Nv5Hwd+sm37v7Ztf5H+g9N0U83XkzTV34wxrdLN\nri/OTpu6waa/H4jv3sVPvh9TDwSTcTbkwcaYDH/XdL3hXPN1XpoH3G+cR2AyK/d/OFc0T/u6sKdf\nfh7f/VC5cD7Aae143hjTMlgBY8wdaXqffoVzr/kZY0yRNGXCcXpCJvLX/SbXcmgbno7T6/I1X/0y\nsxVIJk1vbt+8/oHzKEp6iTi9grMiFudWzGO+zxkyXi3awCngdeM8HxvAGFPUGJPvHMvpgrMu0Zkc\nY97Bua8brNdu33TLawP8Dd9xxjcs/b1VgP/z/Zv6N1oAxAN9g+3PxpgCabedLPrEt5xMT+58280n\nwJ3GmH8GK+Nrts0RusIMjSY4zwKdrfv+5zg90rrw13NvPwGTjTEf4Jy53YvTVLXItm3bV+Ym4Ftf\nL8H1wCGgMk6X6i04zzNh2/YPxpj+OD0E1xpjpuH0pLsW5xnLpjjPfbmRvpmkB7AMmGeM+chX/4I4\nB5yttm2n9sx7FOcezTrjvCf3Z5w3o1TCedSgL+r0c8HYtn3CGPMAzj2tGcaYr3AC7wAQidNztQnO\nI0LYtp1gjHkRGA2s8vU6TD0ZvAF4MpsdbEK+Ddu2vdt3X3Q08JMxZhKwHedxkpbAE7Ztr/P1qP0Q\n6OJr/l2Mc6/sCWAdzvPPaa0EmhtjRuNcxZ0BvrZt+8/MVs627WRjzGc4+0kN4H+2be9NV2a378Rk\nPPCLMWayr76Rvjq09P1OdgRbhq/3ehtgqW3bB4KV8f0e43FastI2ix4A2vp6Fi/G+Xv8C+cZy9fT\nlPvFGLMS53Gf1N/7kzgdtqb41uO4MeYxnKD9zbef/47TKnaLr46tCez049ZInOd0XzHG3IlzX/Yk\nTuvGTbZtp3bmeRmnU9VU3zayEudkpBzOPdwfyKFesrrCDI3OOPdeZmRWwLbtn3GaHNr7zjC9OMHT\nGuePPwzn+cV3cHaeVDtxet1Wx9lQRvnGvwfcZdv2yTTLGAA8gPNox7M4B5NuOGedz6SrUvpnytKP\nS1v3bTgHgg9w7hG8jdPkFMFfHR2wbTsO59nOyTgb/ju+OtfCaYrLrMOD5BDbtjfj/E2ewzl56Yez\n7fTmrzB8OU35sTgnN4dwejy/6vt/a9u2J5CRm20oR7Zh27bH4YTob75xo3BO2lb7lpmql2/5jXCa\nM+/0LWNtkPqPwNlW/4nT1PopTpCda31Tn8ksRCYvELBt+0OcJvI1OEE0BidkS+FcVZ2tR/PDOM9C\nZnh5Q5r5e3Ge4b7ZGFM7zaijOP0r8uM849gZ575rPTvNyyVwjkFFcX6X7+K8f3glUMe27dTWAGzb\nXojzdqj5vnqNxtme/uabx7p0VXP1HKyvGbYRzu/Cg3Mba5BvWZ+nKXcE50UIr+H8bQbjPF3QAudx\nl7GZLO+86QukRUREXNAVpoiIiAsKTBERERcUmCIiIi4oMEVERFxQYIqIiLigwBQREXFBgSkiIuKC\nAlNERMQFBaaIiIgLCkwREREX/h9jma23BqoCywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef3f666748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "abs_avg = np.array([39.19/39.19, 2.87/2.87])\n",
    "cons_avg = np.array([55.21/39.19, 6.8/2.87])\n",
    "dddf = pd.DataFrame()\n",
    "dddf['Graduated']=abs_avg\n",
    "dddf['Not Graduated']=cons_avg\n",
    "#dddf['ind'] = ['Graudated', 'Not Graduated']\n",
    "#dddf = dddf.reset_index(['ind'])[['Absence', 'Consecutive Absence']]\n",
    "ax = dddf.plot(kind='bar', title=\"\",figsize=(8,5),legend=True, fontsize=12, color=['skyblue', '#FF9999'])\n",
    "xticks=['Absence', 'Consecutive Absence']\n",
    "ax.set_xticklabels(xticks, rotation=0, fontsize=18)\n",
    "ax.set_yticks([])\n",
    "plt.legend(loc='upper left', fontsize=20, ncol=1)\n",
    "\n",
    "plt.text(-0.19, 1.02, '1.0', fontsize=22)\n",
    "plt.text(0.012, 1.435, '1.4X', fontsize=22)\n",
    "plt.text(0.81, 1.02, '1.0', fontsize=22)\n",
    "plt.text(1.011, 2.38, '2.4X', fontsize=22)\n",
    "#plt.savefig('absence_compare_dd.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.7 ms\n"
     ]
    }
   ],
   "source": [
    "#check consecutive students\n",
    "(absence[cons_cols]>1).sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absence_consec_gr_3',\n",
       " 'absence_consec_gr_4',\n",
       " 'absence_consec_gr_5',\n",
       " 'absence_consec_gr_6',\n",
       " 'absence_consec_gr_7',\n",
       " 'absence_consec_gr_8',\n",
       " 'absence_consec_gr_9',\n",
       " 'absence_consec_gr_10',\n",
       " 'absence_consec_gr_11']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "cons_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Table model.absence_test created!\n",
      " - updated model.absence_test.absence_gr_7 from clean.all_snapshots.days_absent for grade 7; \n",
      " - updated model.absence_test.absence_gr_8 from clean.all_snapshots.days_absent for grade 8; \n",
      " - updated model.absence_test.absence_unexcused_gr_7 from clean.all_snapshots.days_absent_unexcused for grade 7; \n",
      " - updated model.absence_test.absence_unexcused_gr_8 from clean.all_snapshots.days_absent_unexcused for grade 8; \n",
      " - updated model.absence_test.absence_consec_gr_7 from clean.all_absences.absence_consec_count for grade 7; \n",
      " - updated model.absence_test.absence_consec_gr_8 from clean.all_absences.absence_consec_count for grade 8; \n",
      " - updated model.absence_test.tardy_consec_gr_7 from clean.all_absences.tardy_consec_count for grade 7; \n",
      " - updated model.absence_test.tardy_consec_gr_8 from clean.all_absences.tardy_consec_count for grade 8; \n",
      "time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate Absence related features\n",
    "For Each Grade, generate features:\n",
    "- absence\n",
    "- absence_unexecused\n",
    "- tardy \n",
    "- tardy_unexecused\n",
    "- medical\n",
    "- absence_consec\n",
    "- tardy_consec\n",
    "\n",
    "Note: features from top to bottom, there are more and more missing values,\n",
    "espeically for some specific grades\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os, sys\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_utilities import *\n",
    "\n",
    "def set_null_as_0(cursor, column, schema='clean', table='absence'):\n",
    "    \"\"\" Set null data points as 0 (be careful to assume so)\n",
    "\n",
    "    :param pg.connection.cursor cursor: postgres cursor\n",
    "    :param str column: column name\n",
    "    :param str schema: schema name\n",
    "    :param str table: table name\n",
    "    \"\"\"\n",
    "    sqlcmd = \"\"\"\n",
    "    update {schema}.{table}\n",
    "    set {column}=0 \n",
    "    where {column} is null;\"\"\".format(schema=schema, table=table, column=column)\n",
    "    cursor.execute(sqlcmd)\n",
    "\n",
    "def update_column_with_join(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', dtype='varchar(64)', grade=9):\n",
    "    \"\"\"Update column using join to match another table               \n",
    "\n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select {source_column} from {source_schema_and_table} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.{source_column} is not null\n",
    "    and t2.grade={grade}\n",
    "    order by {source_column} desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column,\n",
    "               source_schema_and_table=source_schema_and_table, \n",
    "               source_column=source_column, grade=grade)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "    \n",
    "def update_join_type_cnt(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', dtype='varchar(64)', type_str = 'tardy', grade=9):\n",
    "    \"\"\"Update column using join to match another table                 \n",
    "\n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    if not source_column:\n",
    "        source_column = column\n",
    "    if not source_schema:\n",
    "        source_schema_and_table = source_table\n",
    "    else:\n",
    "        source_schema_and_table = source_schema+'.'+source_table\n",
    "    sql_drop_temp = \"\"\"drop table if exists {table};\"\"\".format(table=tab_temp)\n",
    "    cursor.execute(sql_drop_temp)\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, count(*) from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "                                          source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index tdy_cnt_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, tab_temp, 'count')\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format( schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update {schema}.{table} t1\n",
    "    set {column}=\n",
    "    (select count from {tab_temp} t2\n",
    "    where t2.student_lookup=t1.student_lookup and t2.count is not null\n",
    "    order by count desc limit 1);\n",
    "    \"\"\".format(schema=schema, table=table, column=column, tab_temp=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema_and_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema_and_table=source_schema_and_table, \n",
    "            s_col=source_column, grade=grade))\n",
    "    \n",
    "def update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'absence', grade=9):\n",
    "    \"\"\" Update column using consec aggreated data \n",
    "                \n",
    "    :param pg.cursor cursor: pg cursor\n",
    "    :param str source_schema: schema of source - None default for temp tables\n",
    "    :param str source_table: table of source\n",
    "    :param str source_column: column of source - defaults to column\n",
    "    :param str schema: schema to update\n",
    "    :param str table: table to update\n",
    "    :param str column: column to update\n",
    "    :param int grade: grade level to subset to\n",
    "    :return None:                      \n",
    "    \"\"\"\n",
    "    tab_temp = 'temp_table'\n",
    "    source_column = type_str+'_consec_count'\n",
    "    sql_drop_temp = \"\"\"drop table if exists {table};\"\"\".format(table=tab_temp)\n",
    "    cursor.execute(sql_drop_temp)\n",
    "    sql_create_agg_temp = \"\"\"\n",
    "    create temporary table {temp_table} as \n",
    "    select t1.student_lookup, sum(t2.{source_column}) as csum from {schema}.{table} t1, {source_schema}.{source_table} t2\n",
    "    where t1.student_lookup=t2.student_lookup and grade={grade} and absence_desc like '%{type_str}%'\n",
    "    group by t1.student_lookup;\"\"\".format(temp_table=tab_temp, schema=schema, table=table, type_str=type_str,\n",
    "        source_column=source_column, source_schema=source_schema, source_table=source_table, grade=grade)\n",
    "    cursor.execute(sql_create_agg_temp)\n",
    "    sql_create_temp_index = \"\"\"create index consec_agg_index on {0}(student_lookup);\"\"\".format(tab_temp);\n",
    "    cursor.execute(sql_create_temp_index)\n",
    "    \n",
    "    dtype = get_column_type(cursor, source_table, source_column)\n",
    "    sql_add_column = \"\"\"\n",
    "    alter table {schema}.{table} add column {column} {dtype} default 0;\n",
    "    \"\"\".format(schema=schema, table=table, column=column, dtype=dtype )\n",
    "    cursor.execute(sql_add_column);\n",
    "    sql_join_cmd = \"\"\"\n",
    "    update only {schema}.{table} t1\n",
    "    set {column}=\n",
    "    ( select csum from {tmp_tab} t2\n",
    "      where t2.student_lookup=t1.student_lookup\n",
    "      limit 1\n",
    "    );\"\"\".format(schema=schema, table=table, column=column, tmp_tab=tab_temp)\n",
    "    cursor.execute(sql_join_cmd)\n",
    "    print(\"\"\" - updated {schema}.{table}.{col} from {s_schema}.{s_table}.{s_col} for grade {grade}; \"\"\".format(\n",
    "            col=column, schema=schema, table=table, \n",
    "            s_schema=source_schema, s_table=source_table, \n",
    "            s_col=source_column, grade=grade)\n",
    "         )\n",
    "    \n",
    "def main():\n",
    "    schema, table = \"model\" ,\"absence_test\"\n",
    "    source_schema = \"clean\"\n",
    "    tab_snapshots, tab_absence = \"all_snapshots\", \"all_absences\"\n",
    "    gr_min, gr_max = 7, 8\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        connection.autocommit = True\n",
    "        with connection.cursor() as cursor:\n",
    "            create_feature_table(cursor, table, schema = 'model', replace = True)\n",
    "            \n",
    "            # days_absent columns\n",
    "            source_table, source_column = tab_snapshots, 'days_absent'\n",
    "            new_col_name = 'absence'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name+'_gr_'+str(grd)\n",
    "                update_column_with_join(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = source_column, source_schema = 'clean',\n",
    "                                schema='model', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "\n",
    "            # days_absent_unexecused\n",
    "            source_table, source_column = tab_snapshots, 'days_absent_unexcused'\n",
    "            new_col_name = 'absence_unexcused'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name+'_gr_'+str(grd)\n",
    "                update_column_with_join(cursor, table, column=column, source_table=source_table, \n",
    "                                source_column = source_column, source_schema = 'clean',\n",
    "                                schema='model', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "\n",
    "#             # tardy\n",
    "#             source_table = tab_absence\n",
    "#             new_col_name = 'tardy'\n",
    "#             for grd in range(gr_min, gr_max+1):\n",
    "#                 column = new_col_name + '_gr_' + str(grd)\n",
    "#                 update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "#                                 source_column = None, source_schema = 'clean',\n",
    "#                                 schema='model', type_str='tardy', grade=grd)\n",
    "#                 set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "#             # tardy_unexecused\n",
    "#             source_table = tab_absence\n",
    "#             new_col_name = 'tardy_unexcused'\n",
    "#             for grd in range(gr_min, gr_max+1):\n",
    "#                 column = new_col_name + '_gr_' + str(grd)\n",
    "#                 update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "#                                 source_column = None, source_schema = 'clean',\n",
    "#                                 schema='model', type_str='tardy_unexcused', grade=grd)\n",
    "#                 set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "            \n",
    "#             # med\n",
    "#             source_table = tab_absence\n",
    "#             new_col_name = 'medical'\n",
    "#             for grd in range(gr_min, gr_max+1):\n",
    "#                 column = new_col_name + '_gr_' + str(grd)\n",
    "#                 update_join_type_cnt(cursor, table, column=column, source_table=source_table, \n",
    "#                                 source_column = None, source_schema = 'clean',\n",
    "#                                 schema='model', type_str='med', grade=grd)\n",
    "#                 set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "\n",
    "            # consecutive absence days\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'absence'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'absence', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "                    \n",
    "            # consecutive tardy days\n",
    "            source_table = tab_absence\n",
    "            new_col_name = 'tardy'\n",
    "            for grd in range(gr_min, gr_max+1):\n",
    "                column = new_col_name + '_consec_gr_' + str(grd)\n",
    "                update_consec(cursor, table, column, source_table, \n",
    "                            source_column = None, source_schema = 'clean',\n",
    "                            schema='model', type_str = 'tardy', grade=grd)\n",
    "                set_null_as_0(cursor, column, schema=schema, table=table)\n",
    "        \n",
    "            connection.commit()\n",
    "        \n",
    "if __name__ =='__main__':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
