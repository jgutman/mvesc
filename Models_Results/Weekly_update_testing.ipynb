{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "parentdir = os.path.abspath('/home/xcheng/mvesc/ETL')\n",
    "sys.path.insert(0,parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "pathname = os.path.dirname(sys.argv[0])\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0, parentdir)\n",
    "from mvesc_utility_functions import *\n",
    "from save_reports import *\n",
    "from optparse import OptionParser\n",
    "\n",
    "# all model import statements\n",
    "from sklearn import svm # use svm.SVC kernel = 'linear' or 'rbf'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "#from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, RobustScaler\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from my_timer import Timer\n",
    "from custom_scorers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features_included': {'grades': ['gpa*'], 'snapshots': ['disadvantagement*', 'disability*', 'district*', 'gifted*', 'iss*', 'oss*', 'limited_english*', 'special_ed*', 'status*', 'days_absent*', 'days_absent_unexcused*', 'discipline_incidents*'], 'demographics': ['ethnicity', 'gender'], 'mobility': ['n_addresses_to*', 'n_cities_to*', 'n_districts_to*']}, 'cohort_grade_level_begin': 'cohort_9th', 'outcome_name': 'definite', 'cohorts_held_out': [2011], 'random_seed': 2187, 'cohorts_training': [2009, 2010], 'missing_impute_strategy': 'median_plus_dummies', 'user_description': 'expand features and grade range', 'validation_criterion': 'custom_recall_10', 'feature_grade_range': [9], 'prediction_grade_level': 10, 'n_folds': 10, 'file_save_name': 'auto_expand_features_test_xc', 'parameter_cross_validation_scheme': 'leave_cohort_out', 'feature_scaling': 'robust', 'model_classes_selected': ['logit'], 'model_test_holdout': 'temporal_cohort', 'write_predictions_to_database': False}\n",
      "joined_label_features1    student_lookup  definite  cohort_9th  gpa_gr_9 district_gr_9  iss_gr_9  \\\n",
      "0         58539.0       0.0        2006  1.108333     TriValley       0.0   \n",
      "1         58539.0       0.0        2006  1.108333     TriValley       0.0   \n",
      "2         58539.0       0.0        2006  1.108333     TriValley       0.0   \n",
      "3         58539.0       0.0        2006  1.108333     TriValley       0.0   \n",
      "4         58538.0       0.0        2006  2.300000     TriValley       1.0   \n",
      "\n",
      "  disability_gr_9  days_absent_unexcused_gr_9  days_absent_gr_9 status_gr_9  \\\n",
      "0            none                         0.0               9.0      active   \n",
      "1            none                         0.0               9.0      active   \n",
      "2            none                         0.0               9.0      active   \n",
      "3            none                         0.0               9.0      active   \n",
      "4            none                         0.0               7.5      active   \n",
      "\n",
      "          ...           special_ed_gr_9 limited_english_gr_9  \\\n",
      "0         ...                       100                    N   \n",
      "1         ...                       100                    N   \n",
      "2         ...                       100                    N   \n",
      "3         ...                       100                    N   \n",
      "4         ...                       100                    N   \n",
      "\n",
      "  discipline_incidents_gr_9  gifted_gr_9 disadvantagement_gr_9 ethnicity  \\\n",
      "0                       5.0            N                  none         W   \n",
      "1                       5.0            N                  none         W   \n",
      "2                       5.0            N                  none         W   \n",
      "3                       5.0            N                  none         W   \n",
      "4                       3.0            N                  none         W   \n",
      "\n",
      "  gender n_addresses_to_gr_9  n_cities_to_gr_9  n_districts_to_gr_9  \n",
      "0      F                   1                 1                    1  \n",
      "1      F                   1                 1                    1  \n",
      "2      F                   1                 1                    1  \n",
      "3      F                   1                 1                    1  \n",
      "4      M                   1                 1                    1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "joined_label_features2                 definite  cohort_9th  gpa_gr_9 district_gr_9  iss_gr_9  \\\n",
      "student_lookup                                                           \n",
      "58539.0              0.0        2006  1.108333     TriValley       0.0   \n",
      "58539.0              0.0        2006  1.108333     TriValley       0.0   \n",
      "58539.0              0.0        2006  1.108333     TriValley       0.0   \n",
      "58539.0              0.0        2006  1.108333     TriValley       0.0   \n",
      "58538.0              0.0        2006  2.300000     TriValley       1.0   \n",
      "\n",
      "               disability_gr_9  days_absent_unexcused_gr_9  days_absent_gr_9  \\\n",
      "student_lookup                                                                 \n",
      "58539.0                   none                         0.0               9.0   \n",
      "58539.0                   none                         0.0               9.0   \n",
      "58539.0                   none                         0.0               9.0   \n",
      "58539.0                   none                         0.0               9.0   \n",
      "58538.0                   none                         0.0               7.5   \n",
      "\n",
      "               status_gr_9  oss_gr_9 special_ed_gr_9 limited_english_gr_9  \\\n",
      "student_lookup                                                              \n",
      "58539.0             active       0.0             100                    N   \n",
      "58539.0             active       0.0             100                    N   \n",
      "58539.0             active       0.0             100                    N   \n",
      "58539.0             active       0.0             100                    N   \n",
      "58538.0             active       0.0             100                    N   \n",
      "\n",
      "                discipline_incidents_gr_9 gifted_gr_9 disadvantagement_gr_9  \\\n",
      "student_lookup                                                                \n",
      "58539.0                               5.0           N                  none   \n",
      "58539.0                               5.0           N                  none   \n",
      "58539.0                               5.0           N                  none   \n",
      "58539.0                               5.0           N                  none   \n",
      "58538.0                               3.0           N                  none   \n",
      "\n",
      "               ethnicity gender  n_addresses_to_gr_9  n_cities_to_gr_9  \\\n",
      "student_lookup                                                           \n",
      "58539.0                W      F                    1                 1   \n",
      "58539.0                W      F                    1                 1   \n",
      "58539.0                W      F                    1                 1   \n",
      "58539.0                W      F                    1                 1   \n",
      "58538.0                W      M                    1                 1   \n",
      "\n",
      "                n_districts_to_gr_9  \n",
      "student_lookup                       \n",
      "58539.0                           1  \n",
      "58539.0                           1  \n",
      "58539.0                           1  \n",
      "58539.0                           1  \n",
      "58538.0                           1  \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f3d3d77bbf51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mrun_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-f3d3d77bbf51>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;31m# run the models and generate the markdown reports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m     \u001b[0mrun_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f3d3d77bbf51>\u001b[0m in \u001b[0;36mrun_all_models\u001b[1;34m(model_options, clfs, params, save_location)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;31m# subset of various feature columns from various tables (features_included)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m     \u001b[0moutcome_plus_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_outcomes_plus_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m     \u001b[1;31m# no null in the categorical values because we have feature_nan dummies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# there may be null values in the cohort or outcome label columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f3d3d77bbf51>\u001b[0m in \u001b[0;36mbuild_outcomes_plus_features\u001b[1;34m(model_options)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mjoint_label_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'student_lookup'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joined_label_features2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint_label_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mjoint_label_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoint_label_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoint_label_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xcheng/mvesc/ETL/mvesc_utility_functions.py\u001b[0m in \u001b[0;36mdf2num\u001b[1;34m(rawdf)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mdummy_col_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy_col_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmost_class_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mnumeric_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_col_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4383\u001b[0m         \u001b[1;31m# For SparseDataFrame's benefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4384\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[1;32m-> 4385\u001b[1;33m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[0;32m   4386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4387\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   4397\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[0;32m   4398\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4399\u001b[1;33m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[0;32m   4400\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[0;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'\\nleft : DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/tools/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4543\u001b[0m                                                 copy=copy),\n\u001b[0;32m   4544\u001b[0m                          placement=placement)\n\u001b[1;32m-> 4545\u001b[1;33m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4547\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4543\u001b[0m                                                 copy=copy),\n\u001b[0;32m   4544\u001b[0m                          placement=placement)\n\u001b[1;32m-> 4545\u001b[1;33m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4547\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4640\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   4641\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 4642\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   4643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4640\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   4641\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 4642\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   4643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m   4940\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4941\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[1;32m-> 4942\u001b[1;33m                                        fill_value=fill_value)\n\u001b[0m\u001b[0;32m   4943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial v0.0 for executing a model estimation procedure\n",
    "#    \"model\" = any predictive method, not necessarily \"model-based\"\n",
    "\n",
    "\n",
    "######\n",
    "# Setup Modeling Options and Functions\n",
    "\n",
    "# maybe this should be moved to a yaml or json file as well\n",
    "def define_clfs_params(filename):\n",
    "    # model_options[model_classes_selected] determines which of these models\n",
    "    # are actually run, all parameter options in grid run for each selected model\n",
    "\n",
    "    clfs = {\n",
    "        'logit': LogisticRegression(),\n",
    "        'LR_no_penalty': LogisticRegression(C=1e6),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1,\n",
    "                                   criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                 algorithm=\"SAMME\", n_estimators=200),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=False),\n",
    "        'GB': GradientBoostingClassifier(\n",
    "            learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3)\n",
    "    }\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        grid = yaml.load(f)\n",
    "\n",
    "    return clfs, grid\n",
    "\n",
    "def clf_loop(clfs, params, train_X, train_y,\n",
    "        criterion, models_to_run, cv_folds):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where the keys are model nicknames (strings)\n",
    "    and the values are GridSearchCV objects containing attributes like\n",
    "    model.best_score_ and model.best_estimator_\n",
    "    :param dict(str:estimator) clfs: clfs as returned by define_clfs_params\n",
    "    :param dict(str:dict) params: grid of classifier hyperparameter options\n",
    "        to grid search over as returned by define_clfs_params\n",
    "    :param pandas.DataFrame train_X: index is student_lookup, columns are all\n",
    "        features to train over in the model\n",
    "    :param pandas.Series(int) train_y: index is student_lookup, value is 0 or 1\n",
    "        for outcome label\n",
    "    :param string criterion: evaluation criterion for model selection on the\n",
    "        validation set, to be read in from model_options (e.g. 'f1')\n",
    "    :param list[string] models_to_run: which models to actually run as read in\n",
    "        from model_options (e.g. ['logit', 'DT'])\n",
    "    :param sklearn.KFolds cv_folds: a KFolds generator object over the index\n",
    "        given in train_X and train_y (a list of lists of student_lookups)\n",
    "    :rtype dict(string: GridSearchCV)\n",
    "    \"\"\"\n",
    "    best_validated_models = dict()\n",
    "    validated_model_times = dict()\n",
    "    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "        model_name=models_to_run[index]\n",
    "        print(model_name)\n",
    "        parameter_values = params[model_name]\n",
    "        with Timer(model_name) as t:\n",
    "            best_validated_models[model_name] = \\\n",
    "                GridSearchCV(clf, parameter_values, scoring=criterion,\n",
    "                             cv=cv_folds)\n",
    "            best_validated_models[model_name].fit(train_X, train_y)\n",
    "            validated_model_times[model_name] = t.time_check()\n",
    "\n",
    "        model_cv_score = best_validated_models[model_name].best_score_\n",
    "        print(\"model: {model}, best {criterion} score: {score}\".format(\n",
    "            model=model_name, criterion=criterion, score=model_cv_score))\n",
    "    return best_validated_models, validated_model_times\n",
    "\n",
    "def temporal_cohort_test_split(joint_df, cohort_grade_level_begin,\n",
    "    cohorts_held_out, cohorts_training):\n",
    "    \"\"\" Splits the given joint_df of features & outcomes and\n",
    "    returns a train/test dataset\n",
    "    :param pd.DataFrame joint_df: data frame with a cohort, outcome, and features\n",
    "    :param list[int] cohorts_held_out: a list of years to split test set on\n",
    "    :param string or list[int] cohorts_training: either the string 'all' or\n",
    "        a list of years to include in the training, all years must precede\n",
    "        the test set years in cohorts_held_out\n",
    "    :returns two dataframes consisting of rows from joint_df, one for training\n",
    "        and one to be used for testing\n",
    "    :rtype pd.DataFrame, pd.DataFrame\n",
    "    \"\"\"\n",
    "    if (cohorts_training=='all'):\n",
    "        train = joint_df[~joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "        assert (np.max(train[cohort_grade_level_begin]) < min(cohorts_held_out)), \\\n",
    "            \"Training years do not completely precede test years\"\n",
    "    else:\n",
    "        assert (max(cohorts_training) < min(cohorts_held_out)), \\\n",
    "            \"Training years do not completely precede test years\"\n",
    "        train = joint_df[joint_df[cohort_grade_level_begin].\\\n",
    "                         isin(cohorts_training)]\n",
    "    test = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    return train, test\n",
    "\n",
    "def measure_performance(outcomes, predictions):\n",
    "    \"\"\" Returns a dict of model performance objects\n",
    "    :param list[int] outcomes:\n",
    "    :param list[float] predictions:\n",
    "    \"\"\"\n",
    "    performance_objects = {}\n",
    "    performance_objects['pr_curve'] = precision_recall_curve(outcomes,\n",
    "                                                             predictions)\n",
    "    performance_objects['roc_curve'] = roc_curve(outcomes, predictions)\n",
    "    return performance_objects\n",
    "\n",
    "def build_outcomes_plus_features(model_options):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe containing the student_lookup, cohort identifier,\n",
    "    outcome variable, and all numerical or binarized features.\n",
    "    Reads in the features and outcomes from database according to the\n",
    "    specification given in model_options dictionary.\n",
    "    :param dict model_options: all options read in from yaml file\n",
    "    Assumes:\n",
    "    model.outcome table contains a column (name in cohort_grade_level_begin)\n",
    "    with int values identifying each student's cohort year\n",
    "    e.g. 'cohort_9th' contains the year each student is seen in 9th grade\n",
    "    and contains an outcome column (name given in outcome_name)\n",
    "    and all feature and outcomes tables contain student_lookup\n",
    "    Usage:\n",
    "    select train, validation, and test based on values in column\n",
    "    'cohort_grade_level_begin' according to value in 'cohorts_held_out'\n",
    "    \"\"\"\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        outcomes_with_student_lookup = read_table_to_df(connection,\n",
    "            table_name = 'outcome', schema = 'model', nrows = -1,\n",
    "            columns = ['student_lookup',\n",
    "            model_options['outcome_name'],\n",
    "            model_options['cohort_grade_level_begin']])\n",
    "        # drop students without student_lookup, outcome, or cohort identifier\n",
    "        # can use subset=[colnames] to drop based on NAs in certain columns only\n",
    "        outcomes_with_student_lookup.dropna(inplace=True)\n",
    "        joint_label_features = outcomes_with_student_lookup.copy()\n",
    "\n",
    "        # get all requested input features\n",
    "        # Assumes:\n",
    "        # every features table contains 'student_lookup'\n",
    "        # plus a column for the requested possible features\n",
    "\n",
    "        model_options['features_included'] = parse_features(\n",
    "            model_options['features_included'],\n",
    "            model_options['feature_grade_range'])\n",
    "\n",
    "        for table, column_names in model_options['features_included'].items():\n",
    "            for c in column_names:\n",
    "                try:\n",
    "                    grade =  int(c.split('_')[-1])\n",
    "                except:\n",
    "                    pass # ignoring features not connected to a grade level\n",
    "                else:\n",
    "                    assert grade < model_options['prediction_grade_level'], \\\n",
    "                           \"feature {} after prediction window\".format(c)\n",
    "            features = read_table_to_df(connection, table_name = table,\n",
    "                schema = 'model', nrows = -1,\n",
    "                columns=(['student_lookup'] + column_names))\n",
    "        # join to only keep features that have labeled outcomes\n",
    "            joint_label_features = pd.merge(joint_label_features, features,\n",
    "                how = 'left', on = 'student_lookup')\n",
    "\n",
    "    # build dataframe containing student_lookup, outcome, cohort,\n",
    "    # and all features as numeric non-categorical values\n",
    "    print('joined_label_features1', joint_label_features.head())\n",
    "    joint_label_features.set_index('student_lookup', inplace=True)\n",
    "    print('joined_label_features2', joint_label_features.head())\n",
    "    joint_label_features = df2num(joint_label_features)\n",
    "    return joint_label_features\n",
    "\n",
    "def parse_features(features_included_raw, feature_grade_range):\n",
    "    features_included = dict()\n",
    "    for table, feature_list in features_included_raw.items():\n",
    "        feature_list_expanded = [feature.replace('*', '{}').format(\n",
    "                                    '_gr_' + str(i))\n",
    "                                    for i in feature_grade_range\n",
    "                                    for feature in feature_list]\n",
    "        feature_list_expanded = set(feature_list_expanded)\n",
    "        features_included[table] = list(feature_list_expanded)\n",
    "    return features_included\n",
    "\n",
    "def read_in_yaml(filename=os.path.join(base_pathname,\n",
    "        'Models_Results', 'model_options.yaml')):\n",
    "    \"\"\"\n",
    "    This function contains assertions specific to the model options yaml file.\n",
    "    Should only be used to read in the model options yaml file and not other\n",
    "    kinds of yaml files.\n",
    "    :param string filename: full path of yaml file containing model options\n",
    "    :returns: a dictionary of model options and their values\n",
    "    :rtype dict\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        model_options = yaml.load(f)\n",
    "\n",
    "    # Maybe we want to have default values for these options and replace\n",
    "    # from a new yaml file as necessary\n",
    "    assert(type(model_options) == dict), \"bad formatting in yaml file\"\n",
    "    required_keys = set(('validation_criterion', 'features_included',\n",
    "                         'cohorts_training','cohorts_held_out', 'file_save_name',\n",
    "                         'model_classes_selected', 'outcome_name',\n",
    "                         'cohort_grade_level_begin', 'model_test_holdout',\n",
    "                         'random_seed'))\n",
    "    assert (all([key in model_options.keys() for key in required_keys])), \\\n",
    "        \"missing model specifications in yaml file\"\n",
    "    assert(type(model_options['features_included']) == dict), \\\n",
    "        \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['model_classes_selected']) == list),\\\n",
    "        \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['cohorts_held_out']) == list),\\\n",
    "        \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['cohorts_training']) == list or\n",
    "        model_options['cohorts_training'] == 'all'),\\\n",
    "        \"bad formatting in yaml file\"\n",
    "    return model_options\n",
    "\n",
    "def scale_features(train, test, strategy):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_values_by_column = {x: len(train[x].unique()) for x in train.columns}\n",
    "    zero_variance_columns = [k for k,v in num_values_by_column.items()\n",
    "                             if v == 1]\n",
    "    train.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "    test.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "\n",
    "    if (strategy == 'none'):\n",
    "        return train, test\n",
    "\n",
    "    elif(strategy == 'standard' or strategy == 'robust'):\n",
    "\n",
    "        non_binary_columns = [k for k, v in num_values_by_column.items()\n",
    "                              if v > 2]\n",
    "        if (len(non_binary_columns) > 0):\n",
    "            scaler = StandardScaler() if strategy == 'standard' else RobustScaler()\n",
    "            train_non_binary = train[non_binary_columns]\n",
    "            test_non_binary = test[non_binary_columns]\n",
    "            scaler.fit(train_non_binary)\n",
    "            train_non_binary = pd.DataFrame(scaler.transform(train_non_binary),\n",
    "                columns = non_binary_columns, index = train.index)\n",
    "            test_non_binary = pd.DataFrame(scaler.transform(test_non_binary),\n",
    "                columns = non_binary_columns, index = test.index)\n",
    "\n",
    "            train_scaled = train.drop(non_binary_columns, axis=1)\n",
    "            test_scaled = test.drop(non_binary_columns, axis=1)\n",
    "            train_scaled = train_scaled.merge(train_non_binary,\n",
    "                left_index=True, right_index=True)\n",
    "            test_scaled = test_scaled.merge(test_non_binary,\n",
    "                left_index=True, right_index=True)\n",
    "            return train_scaled, test_scaled\n",
    "        else:\n",
    "            return train, test\n",
    "\n",
    "    else:\n",
    "        print('unknown feature scaling strategy. try \"{}\", \"{}\", or \"{}\"'\\\n",
    "              .format('standard', 'robust', 'none'))\n",
    "        return train, test\n",
    "\n",
    "def add_null_dummies(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data_null_columns = data[data.columns[data.isnull().sum() > 0]]\n",
    "    data_null_dummies = data_null_columns.isnull()*1.0\n",
    "    data_null_dummies.rename(columns=lambda x: x + '_isnull', inplace=True)\n",
    "    data_plus_dummies = data.merge(data_null_dummies,\n",
    "        left_index=True, right_index=True)\n",
    "    return data_plus_dummies\n",
    "\n",
    "def impute_missing_values(train, test, strategy):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if (strategy=='none'):\n",
    "        return train, test\n",
    "\n",
    "    elif(strategy == 'mean_plus_dummies' or strategy == 'median_plus_dummies'):\n",
    "        train = add_null_dummies(train) # add feature_isnull columns 0 or 1\n",
    "        test = add_null_dummies(test)\n",
    "\n",
    "        imputer = Imputer(strategy=strategy.split(\"_\")[0])\n",
    "        imputer.fit(train) # fit the imputer on the training mean/median\n",
    "        train = pd.DataFrame(imputer.transform(train), # returns a numpy array\n",
    "            columns = train.columns, index = train.index) # back to dataframe\n",
    "        test = pd.DataFrame(imputer.transform(test),\n",
    "            columns = test.columns, index = test.index)\n",
    "        return train, test\n",
    "\n",
    "    else:\n",
    "        print('unknown imputation strategy. try \"{}\", \"{}\", or \"{}\"'.format(\n",
    "            'mean_plus_dummies', 'median_plus_dummies', 'none'))\n",
    "        return train, test\n",
    "\n",
    "def run_all_models(model_options, clfs, params, save_location):\n",
    "    # Based on options, draw in data and select the appropriate\n",
    "    # labeled outcome column (outcome_name)\n",
    "    # cohort identification column (cohort_grade_level_begin)\n",
    "    # subset of various feature columns from various tables (features_included)\n",
    "\n",
    "    outcome_plus_features = build_outcomes_plus_features(model_options)\n",
    "    # no null in the categorical values because we have feature_nan dummies\n",
    "    # there may be null values in the cohort or outcome label columns\n",
    "    # just drop these students from the data\n",
    "    outcome_plus_features.dropna(subset=[model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']], inplace=True)\n",
    "    # imputation should happen after splitting into train and test\n",
    "\n",
    "    # Use the gathered DataFrame in a predictive model\n",
    "    # Steps:\n",
    "    #   - (A) manage test and validation folds\n",
    "    #   - (B) run the prediction technique across all validation folds\n",
    "    #   - (C) record the inputs and parameters used\n",
    "\n",
    "    # (4A) Choose cohort(s) for test and validation data\n",
    "    # Validation Process\n",
    "    # Use temporal split for creating the test set\n",
    "    # Use cohort-fold cross-validation for parameter search and model selection\n",
    "    #    - temporal (using recent cohorts as a validation set)\n",
    "    #    - k-fold cross (using all cohorts and all years of features)\n",
    "    #    - cohort-fold cross validation (leave one cohort out)\n",
    "\n",
    "    if model_options['model_test_holdout'] == 'temporal_cohort':\n",
    "        # if using temporal cohort model performance validation,\n",
    "        # we choose the cohorts in cohorts_held_out for the test set\n",
    "        train, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "            model_options['cohort_grade_level_begin'],\n",
    "            model_options['cohorts_held_out'],\n",
    "            model_options['cohorts_training'])\n",
    "\n",
    "    else:\n",
    "        # if not using temporal test set, split randomly\n",
    "        train, test = train_test_split(outcome_plus_features, test_size=0.20,\n",
    "            random_state=model_options['random_seed'])\n",
    "\n",
    "    # get subtables for each for easy reference\n",
    "    train_X = train.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    test_X = test.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    train_y = train[model_options['outcome_name']]\n",
    "    test_y = test[model_options['outcome_name']]\n",
    "\n",
    "    # do missing value feature imputation here\n",
    "    train_X, test_X = impute_missing_values(train_X, test_X,\n",
    "        model_options['missing_impute_strategy'])\n",
    "    assert (all(train_X.columns == test_X.columns)),\\\n",
    "        \"train and test have different columns\"\n",
    "\n",
    "    # do feature scaling here\n",
    "    train_X, test_X = scale_features(train_X, test_X,\n",
    "        model_options['feature_scaling'])\n",
    "    assert (all(train_X.columns == test_X.columns)),\\\n",
    "        \"train and test have different columns\"\n",
    "\n",
    "    # From now on, we IGNORE the `test`, `test_X`, `test_y` data\n",
    "    # until we evaluate the model\n",
    "\n",
    "    ## (4B) Fit on Training ##\n",
    "    # if we require cross-validation of parameters, we can either\n",
    "    #    (a) hold out another cohort in each fold for cross-validation\n",
    "    #    (b) fold all cohorts together for k-fold parameter estimation\n",
    "\n",
    "    if model_options['parameter_cross_validation_scheme'] == 'none':\n",
    "        # no need to further manipulate train dataset\n",
    "        cohort_kfolds = 2 # hacky way to have GridSearchCV fit to 2 k-folds\n",
    "\n",
    "    elif model_options['parameter_cross_validation_scheme'] == \\\n",
    "         'leave_cohort_out':\n",
    "        # choose another validation set amongst the training set to\n",
    "        # estimate parameters and model selection across cohort folds\n",
    "        print('leave_cohort_out')\n",
    "        cohort_kfolds = LeaveOneLabelOut(train[\n",
    "                model_options['cohort_grade_level_begin']])\n",
    "\n",
    "    elif model_options['parameter_cross_validation_scheme'] == 'k_fold':\n",
    "        # ignore cohorts and use random folds to estimate parameter\n",
    "        print('k_fold_parameter_estimation')\n",
    "        cohort_kfolds = LabelKFold(train.index,\n",
    "                n_folds = model_options['n_folds'])\n",
    "\n",
    "    else:\n",
    "        print('unknown cross-validation strategy. try \"{}\", \"{}\", or \"{}\"'\\\n",
    "              .format('leave_cohort_out', 'k_fold', 'none'))\n",
    "\n",
    "    criterion = parse_criterion_string(\n",
    "            model_options['validation_criterion'])\n",
    "    # best_validated_models is a dictionary whose keys are the model\n",
    "    # nicknames in model_classes_selected and values are objects\n",
    "    # returned by GridSearchCV\n",
    "    best_validated_models, validated_model_times = clf_loop(clfs, params, train_X, train_y,\n",
    "        criterion = criterion,\n",
    "        models_to_run = model_options['model_classes_selected'],\n",
    "        cv_folds = cohort_kfolds) # cv_folds is a k-fold generator\n",
    "\n",
    "    for model_name, model in best_validated_models.items():\n",
    "        clf = model.best_estimator_\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            test_set_scores = clf.predict_proba(test_X)[:,1]\n",
    "        else:\n",
    "            test_set_scores = clf.decision_function(test_X)\n",
    "\n",
    "        ## (4C) Save Results ##\n",
    "        # Save the recorded inputs, model, performance, and text description\n",
    "        # into a results folder\n",
    "        # according to sklearn documentation, use joblib instead of pickle\n",
    "        # save as a .pkl extension\n",
    "        # store option inputs (random_seed, train/test split rules, features)\n",
    "        # store time to completion [missing]\n",
    "\n",
    "        saved_outputs = {\n",
    "            'model_name' : model_name,\n",
    "            'estimator' : model,\n",
    "            'model_options' : model_options, # this also contains cohort_grade_level_begin for train/test split\n",
    "            'test_y' : test_y,\n",
    "            'test_set_soft_preds' : test_set_scores,\n",
    "            'train_set_balance': {0:sum(train_y==0), 1:sum(train_y==1)},\n",
    "            'features' : train_X.columns,\n",
    "            'parameter_grid' : params[model_name],\n",
    "            'performance_objects' : measure_performance(test_y, test_set_scores),\n",
    "            'time': validated_model_times[model_name]\n",
    "        }\n",
    "\n",
    "        # save outputs\n",
    "        file_name = model_options['file_save_name'] +'_' + model_name + '.pkl'\n",
    "        joblib.dump(saved_outputs, os.path.join(save_location, file_name))\n",
    "\n",
    "        # write output summary to a database\n",
    "        #    - (A) write to a database table to store summary\n",
    "        #    - (B) write to and update an HTML/Markdown file\n",
    "        #    to create visual tables and graphics for results\n",
    "\n",
    "        write_model_report(save_location, saved_outputs)\n",
    "\n",
    "def main():\n",
    "# Create options file used to generate features\n",
    "# OR Read in an existing human-created options file\n",
    "\n",
    "# The model options needs to read in what tables to draw features from\n",
    "# and what columns to draw from each of those tables\n",
    "# Also needs to read in an option to output all results to a database\n",
    "    \"\"\"\n",
    "    parser = OptionParser()\n",
    "    parser.add_option('-m','--modelpath', dest='model_options_file',\n",
    "        help=\"filename for model options; default 'model_options.yaml' \")\n",
    "    parser.add_option('-g','--gridpath', dest='grid_options_file',\n",
    "        help=\"filename for grid options; default 'grid_options_bare.yaml' \")\n",
    "    parser.add_option('-o', '--outputpath', dest='save_location',\n",
    "        help=\"location for saving output reports; default 'Reports/' \")\n",
    "\n",
    "    (options, args) = parser.parse_args()\n",
    "    \"\"\"\n",
    "    ### Parameters to entered from the options or use default####\n",
    "    model_options_file = 'model_options_weekly_update1.yaml'\n",
    "    grid_options_file = 'grid_options_bare.yaml'\n",
    "    save_location = '../Reports'\n",
    "    \"\"\"\n",
    "    if options.model_options_file:\n",
    "        model_options_file = options.model_options_file\n",
    "    if options.grid_options_file:\n",
    "        grid_options_file = options.grid_options_file\n",
    "    if options.save_location:\n",
    "        save_location = options.save_location\n",
    "    \"\"\"\n",
    "    model_options = read_in_yaml(model_options_file)\n",
    "    print(model_options)\n",
    "    # set seed for this program from model_options\n",
    "    np.random.seed(model_options['random_seed'])\n",
    "\n",
    "    # get grid search options for all classifiers\n",
    "    clfs, params = define_clfs_params(grid_options_file)\n",
    "\n",
    "    # run the models and generate the markdown reports\n",
    "    run_all_models(model_options, clfs, params, save_location)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadOptionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, values)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36m_process_args\u001b[1;34m(self, largs, rargs, values)\u001b[0m\n\u001b[0;32m   1429\u001b[0m                 \u001b[1;31m# value(s) for the last one only)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_short_opts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_interspersed_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36m_process_short_opts\u001b[1;34m(self, rargs, values)\u001b[0m\n\u001b[0;32m   1511\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mBadOptionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakes_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadOptionError\u001b[0m: no such option: -f",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-648c7afc5cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[0mrun_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-648c7afc5cd3>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    428\u001b[0m         help=\"location for saving output reports; default 'Reports/' \")\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;31m### Parameters to entered from the options or use default####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, values)\u001b[0m\n\u001b[0;32m   1386\u001b[0m             \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlargs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         \"\"\"\n\u001b[0;32m   1567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1568\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s: error: %s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_prog_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1570\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/optparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, msg)\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
