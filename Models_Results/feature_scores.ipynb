{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/home/jtorrenc/mvesc/ETL')\n",
    "sys.path.insert(0, '/home/jtorrenc/mvesc/ModelsResults')\n",
    "sys.path.insert(0, '/home/jtorrenc/mvesc/Features')\n",
    "\n",
    "from mvesc_utility_functions import *\n",
    "from estimate_prediction_model import build_outcomes_plus_features,temporal_cohort_test_split,impute_missing_values\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from functools import partial\n",
    "import itertools\n",
    "from my_timer import Timer \n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def student_list(filename):\n",
    "    model_name = filename.split('_')[-3]\n",
    "    with open('/mnt/data/mvesc/Models_Results/pkls/'+filename+'_'+ model_name + '.pkl', \"rb\" ) as f:\n",
    "        d = pickle.load(f)\n",
    "    train = d['train_y'].index\n",
    "    val = d['val_y'].index\n",
    "    test = d['test_y'].index\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scale_features(train, val, test, strategy):\n",
    "    \"\"\"                                                                         \n",
    "    Scales features based on the training values with the given strategy   \n",
    "    Modified here to also return the scaler\n",
    "                                                                                \n",
    "    :param pd.DataFrame train:                                                  \n",
    "    :param pd.DataFrame val:                                                    \n",
    "    :param pd.DataFrame test:                                                   \n",
    "    :param str strategy:                                                        \n",
    "    :returns: scaled training, val, and test sets                               \n",
    "    :rtype: pd.DataFrame, pd.DataFrame, pd.DataFrame                            \n",
    "    \"\"\"\n",
    "    zero_variance_columns = [x for x in train.columns if len(train[x].unique()) == 1]\n",
    "    train.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "    val.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "    test.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "\n",
    "    if (strategy == 'none'):\n",
    "        return train, val, test\n",
    "\n",
    "    elif(strategy == 'standard' or strategy == 'robust'):\n",
    "        non_binary_columns = [x for x in train.columns if  len(train[x].unique())>2]\n",
    "        if (len(non_binary_columns) > 0):\n",
    "            scaler = StandardScaler() if strategy == 'standard' \\\n",
    "                     else RobustScaler()\n",
    "            train_non_binary = train[non_binary_columns]\n",
    "            val_non_binary = val[non_binary_columns]\n",
    "            test_non_binary = test[non_binary_columns]\n",
    "            scaler.fit(train_non_binary)\n",
    "            train_non_binary = pd.DataFrame(scaler.transform(train_non_binary),\n",
    "                columns = non_binary_columns, index = train.index)\n",
    "            val_non_binary = pd.DataFrame(scaler.transform(val_non_binary),\n",
    "                columns = non_binary_columns, index = val.index)\n",
    "            test_non_binary = pd.DataFrame(scaler.transform(test_non_binary),\n",
    "                columns = non_binary_columns, index = test.index)\n",
    "            train_scaled = train.drop(non_binary_columns, axis=1)\n",
    "            val_scaled = val.drop(non_binary_columns, axis=1)\n",
    "            test_scaled = test.drop(non_binary_columns, axis=1)\n",
    "            train_scaled = train_scaled.merge(train_non_binary,\n",
    "                left_index=True, right_index=True)\n",
    "            val_scaled = val_scaled.merge(val_non_binary,\n",
    "                left_index=True, right_index=True)\n",
    "            test_scaled = test_scaled.merge(test_non_binary,\n",
    "                left_index=True, right_index=True)\n",
    "            return train_scaled,val_scaled, test_scaled, scaler\n",
    "        else:\n",
    "            return train, val, test, scaler\n",
    "\n",
    "    else:\n",
    "        print('unknown feature scaling strategy. try \"{}\", \"{}\", or \"{}\"'\\\n",
    "              .format('standard', 'robust', 'none'))\n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_and_preprocess(filename):\n",
    "    model_name = filename.split('_')[-3]\n",
    "    with open('/mnt/data/mvesc/Models_Results/pkls/'+filename+'_'+ model_name + '.pkl', \"rb\" ) as f:\n",
    "        d = pickle.load(f)\n",
    "    model_options = d['model_options']\n",
    "    model = d['estimator']\n",
    "    columns = d['estimator_features']\n",
    "    outcome_plus_features = build_outcomes_plus_features(model_options,None)\n",
    "    outcome_plus_features.dropna(subset=[model_options['outcome_name'],\n",
    "            model_options['cohort_grade_level_begin']], inplace=True)\n",
    "    train, val, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "            model_options['cohort_grade_level_begin'],\n",
    "            model_options['cohorts_test'],\n",
    "            model_options['cohorts_val'],\n",
    "            model_options['cohorts_training'])\n",
    "    train_X_pre = train.drop([model_options['outcome_name'],\n",
    "                      model_options['cohort_grade_level_begin']],axis=1)\n",
    "    test_X_pre = test.drop([model_options['outcome_name'],\n",
    "                        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    val_X_pre = val.drop([model_options['outcome_name'],\n",
    "                      model_options['cohort_grade_level_begin']],axis=1)\n",
    "    train_y = train[model_options['outcome_name']]\n",
    "    test_y = test[model_options['outcome_name']]\n",
    "    val_y = val[model_options['outcome_name']]\n",
    "    train_X, val_X, test_X = impute_missing_values(train_X_pre, val_X_pre, test_X_pre,\\\n",
    "    model_options['missing_impute_strategy'])\n",
    "    train_X = train_X.filter(columns)\n",
    "    val_X = val_X.filter(columns)\n",
    "    test_X = test_X.filter(columns)\n",
    "    train_X, val_X, test_X, scaler = scale_features(train_X, val_X, test_X,\n",
    "                                                    model_options['feature_scaling'])\n",
    "    X = pd.concat([train_X,val_X,test_X])\n",
    "    X_pre = pd.concat([train_X_pre,val_X_pre,test_X_pre])\n",
    "\n",
    "    return X, X_pre, scaler, columns, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_feature_scores(filename):\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"select feature,importance from model.feature_scores\n",
    "                                    where filename = '{}'; \"\"\".format(filename))\n",
    "            temp = cursor.fetchall()\n",
    "    scores = pd.DataFrame(temp, columns = ['feature','importance'])\n",
    "    scores.set_index('feature', inplace=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def split_columns(X, columns):\n",
    "    binary_features = pd.DataFrame(~X.apply(lambda x: len(x.unique()),axis=0).gt(2), columns = ['binary'])\n",
    "    cts_columns = [c for c in columns if not binary_features['binary'].loc[c]]\n",
    "    binary_columns = [c for c in columns if binary_features['binary'].loc[c]]\n",
    "    return cts_columns, binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def categorical_feature_dict(all_features_path, binary_columns):\n",
    "    with open(all_features_path, 'r') as f:\n",
    "            all_features = yaml.load(f)\n",
    "    feature_base = itertools.chain.from_iterable([a  for a in all_features.values()])\n",
    "    feature_base = [y[:-1] if '*' in y else y for y in feature_base]\n",
    "    binary_base = set()\n",
    "    for f in feature_base:\n",
    "        for b in binary_columns:\n",
    "            if f in b and 'null' not in b:\n",
    "                base = []\n",
    "                flag=False\n",
    "                if 'gr' in b:\n",
    "                    for a in b.split('_'):\n",
    "                        if flag:\n",
    "                            base.append(a)\n",
    "                            break\n",
    "                        base.append(a)\n",
    "                        if a=='gr':\n",
    "                            flag=True\n",
    "                    binary_base.add('_'.join(base))\n",
    "                else:\n",
    "                    binary_base.add(f)\n",
    "    binary_base = list(binary_base)\n",
    "    binary_dict = {}\n",
    "    for b in binary_base:\n",
    "        binary_dict[b] = [f for f in binary_columns if b == f[:len(b)]]\n",
    "    return binary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_binary_features(model, student, binary_dict, train_X, plot):\n",
    "    X_student = train_X.loc[student]\n",
    "    I = pd.DataFrame(columns = ['delta','direction', 'current_val','var_type', 'was_null'], index=binary_dict.keys())\n",
    "    \n",
    "    for base, features in binary_dict.items():\n",
    "        if len(features)>1: # for categorical\n",
    "            X = pd.DataFrame(np.tile(X_student,[len(features),1]).transpose(),index=X_student.index) # reset X matrix\n",
    "            current_val = 'other'\n",
    "            for i,f in enumerate(features):\n",
    "                if train_X[f].loc[student]:\n",
    "                    current_val = f[len(base)+1:]\n",
    "                for g in features:\n",
    "                    X[i].loc[g] = 1 if g == f else 0\n",
    "            if current_val == 'other': # for dropped features\n",
    "                X[i+1] = X[i]\n",
    "                for g in features:\n",
    "                    X[i+1].loc[g] = 0\n",
    "                current_val_ind = len(features)\n",
    "                features.append(current_val)\n",
    "            else:\n",
    "                current_val_ind = [i for i,f in enumerate(features) if current_val in f][0]\n",
    "            prob = [a[1] for a in model.predict_proba(X.transpose())]\n",
    "            I['delta'].loc[base] = abs(np.mean([p - prob[current_val_ind] \n",
    "                                                 for i, p in enumerate(prob)\n",
    "                                                if i != current_val_ind ]))\n",
    "            I['direction'].loc[base] = 'protective' if prob[current_val_ind] < np.mean(prob) else 'risky'\n",
    "            I['current_val'].loc[base] = current_val\n",
    "            I['var_type'].loc[base] = 'categorical'\n",
    "            I['was_null'].loc[base] = np.bool('null' in current_val)\n",
    "            if plot:\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.scatter( np.arange(len(features)), prob);\n",
    "                plt.scatter( current_val_ind , prob[current_val_ind], label=current_val, color = 'red');\n",
    "                ax.set_xticks( np.arange(len(features)))\n",
    "                ax.set_xticklabels( [f[len(base)+1:] for f in features], rotation=90 ) ;\n",
    "                plt.ylim([0,1])\n",
    "                plt.title('{0} for student {1}'.format(base,student));\n",
    "        else: # for truly binary features\n",
    "            f= features[0]\n",
    "            X = pd.DataFrame(np.tile(X_student,[2,1]).transpose(),index=X_student.index) # reset X matrix\n",
    "            current_val = train_X[f].loc[student]\n",
    "            X[0].loc[f] = 0 \n",
    "            X[1].loc[f] = 1 \n",
    "            prob = [a[1] for a in model.predict_proba(X.transpose())]\n",
    "            diff = prob[int(current_val)] -  prob[int(not  bool(current_val))]\n",
    "            I['delta'].loc[base] = abs(diff)\n",
    "            I['current_val'].loc[base] = current_val\n",
    "            I['var_type'].loc[base] = 'binary'\n",
    "            I['was_null'].loc[base] = np.isnan(current_val) \n",
    "            if diff > 0:\n",
    "                I['direction'].loc[base] = 'protective'   \n",
    "            else:\n",
    "                I['direction'].loc[base] = 'risky' \n",
    "            if plot:\n",
    "                fig, ax = plt.subplots()\n",
    "                plt.scatter( [0,1], prob);\n",
    "                plt.scatter( current_val , prob[int(current_val)], label=current_val, color = 'red');\n",
    "                ax.set_xticks([0,1] )\n",
    "                ax.set_xticklabels( ['False', 'True'], rotation=90 ) ;\n",
    "                plt.ylim([0,1])\n",
    "                plt.title('{0} for student {1}'.format(f,student));\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_cts_features(model, student, cts_columns, train_X_pre, train_X, scaler):\n",
    "    X_student = train_X.loc[student]\n",
    "    n_steps = 100\n",
    "    for feature in cts_columns:\n",
    "        X = pd.DataFrame(np.tile(X_student,[n_steps,1]).transpose(),index=X_student.index) # reset X matrix\n",
    "        current_val = train_X_pre[feature].loc[student]\n",
    "\n",
    "        if not np.isnan(current_val): # skip null values\n",
    "            values = np.linspace(min(train_X[feature]), max(train_X[feature]), n_steps)\n",
    "            for i,v in enumerate(values):\n",
    "                X[i].loc[feature] = v\n",
    "            prob = [a[1] for a in model.predict_proba(X.transpose())]\n",
    "            values_pre = pd.DataFrame(scaler.inverse_transform(X.loc[cts_columns].transpose()).transpose(),\n",
    "                                index = cts_columns,\n",
    "                                columns = X.columns)\n",
    "            values_pre = values_pre.loc[feature]\n",
    "            plt.figure()\n",
    "            plt.hold='on'\n",
    "            plt.vlines(current_val,0,1,label=str(current_val))\n",
    "            plt.plot(values_pre, prob);\n",
    "            plt.ylim([0,1])\n",
    "            plt.xlim([min(values_pre)-1,max(values_pre)+1])\n",
    "            #plt.legend()\n",
    "            plt.title('{0} for student {1}'.format(feature,student));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cts_feature_importance(model, student, cts_columns, train_X_pre, train_X, scaler, shift):\n",
    "    X_student = train_X.loc[student]\n",
    "    I = pd.DataFrame(columns = ['delta', 'direction', 'current_val','var_type','was_null'],index=cts_columns)\n",
    "    for feature in cts_columns:\n",
    "        s = shift*train_X[feature].std()\n",
    "        X = pd.DataFrame(np.tile(X_student,[3,1]).transpose(),index=X_student.index) # reset X matrix\n",
    "        X[0].loc[feature] = X[1].loc[feature] - s\n",
    "        X[2].loc[feature] = X[1].loc[feature] + s\n",
    "        prob = [a[1] for a in model.predict_proba(X.transpose())]\n",
    "        down = prob[1]-prob[0]\n",
    "        up = prob[1]-prob[2]\n",
    "        I['delta'].loc[feature] = max(up,down)\n",
    "        if prob[0] < prob[2]:\n",
    "            I['direction'].loc[feature] = 'risky'\n",
    "        else:\n",
    "            I['direction'].loc[feature] = 'protective'\n",
    "        I['current_val'].loc[feature] = X[1].loc[feature]\n",
    "        I['was_null'].loc[feature] = np.isnan(train_X_pre[feature].loc[student])\n",
    "    I['var_type'] = 'continuous'\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_features(model_filename, student, all_features_path):\n",
    "    X, X_pre, scaler, column_order, model = read_and_preprocess(filename)\n",
    "    cts_columns, binary_columns = split_columns(X, column_order)\n",
    "    binary_dict = categorical_feature_dict(all_features_path, binary_columns)\n",
    "    plot_cts_features(model, student, cts_columns, X_pre, X, scaler)\n",
    "    plot_binary_features(model, student, binary_dict, X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(model_filename, student, all_features_path, shift):\n",
    "    X, X_pre, scaler, column_order, model = read_and_preprocess(filename)\n",
    "    cts_columns, binary_columns = split_columns(X, column_order)\n",
    "    binary_dict = categorical_feature_dict(all_features_path, binary_columns)\n",
    "    I_cts = cts_feature_importance(model, student, cts_columns, X_pre, X, scaler, shift)\n",
    "    I_binary = plot_binary_features(model, student, binary_dict, X, False)\n",
    "    return pd.concat([I_cts,I_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features_path = '../Features/all_features.yaml'\n",
    "filename = '08_17_2016_grade_10_param_set_16_RF_jg_139'\n",
    "train_students, val_students, test_students = student_list(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_students\n",
    "student = 42556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with Timer('feature importances') as t:\n",
    "#     I = get_feature_importances(filename, student, all_features_path, 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I[np.logical_not(I['was_null'])].sort_values('delta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue with student 42985.0\n",
      "feature importances: 2.7e+04 seconds elapsed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0a6937618243>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstudent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_students\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mall_I\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_feature_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_features_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'issue with student'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstudent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-638d75c6be3b>\u001b[0m in \u001b[0;36mget_feature_importances\u001b[1;34m(model_filename, student, all_features_path, shift)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcts_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbinary_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategorical_feature_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_features_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mI_cts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcts_feature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcts_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mI_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_binary_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mI_cts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mI_binary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-7a2f1f412825>\u001b[0m in \u001b[0;36mcts_feature_importance\u001b[1;34m(model, student, cts_columns, train_X_pre, train_X, scaler, shift)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    545\u001b[0m             delayed(_parallel_helper)(e, 'predict_proba', X,\n\u001b[0;32m    546\u001b[0m                                       check_input=False)\n\u001b[1;32m--> 547\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/env/lib/python3.4/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with Timer('feature importances') as t:\n",
    "    all_I = []\n",
    "    c = 0\n",
    "    for student in val_students:\n",
    "        try:\n",
    "            all_I.append(get_feature_importances(filename, student, all_features_path, 1))\n",
    "        except:\n",
    "            print('issue with student',student)\n",
    "            raise\n",
    "        if c%20:\n",
    "            print('time elapsed: {0} sec (finished {1})'.format(t.time_check(),c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for student, I in zip(val_students[:len(all_I)], all_I):\n",
    "    I.columns = [c+'_'+str(student) for c in I.columns]\n",
    "I = all_I[0]\n",
    "for I_next in all_I[1:]:\n",
    "    I = I.join(I_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I[np.logical_not(I['was_null'])].sort_values('delta',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I_cts.sort_values('delta',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I_binary.sort_values('delta',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I_binary.sort_values('delta',ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_features(filename, student, all_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
