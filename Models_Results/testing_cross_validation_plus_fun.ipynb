{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "pathname = os.path.dirname(\"/home/jgutman/mvesc/Models_Results/\")\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mvesc_utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all model import statements\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, RobustScaler\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select * from model.outcome\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11777\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "            results = cursor.fetchall()\n",
    "            print(len(results))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df2num(rawdf):\n",
    "    \"\"\" Convert data frame with numeric variables and strings to numeric dataframe\n",
    "\n",
    "    :param pd.dataframe rawdf: raw data frame\n",
    "    :returns pd.dataframe df: a data frame with strings converted to dummies, other columns unchanged\n",
    "    :rtype: pd.dataframe\n",
    "    Rules:\n",
    "    - 1. numeric columns unchanged;\n",
    "    - 2. strings converted to dummeis;\n",
    "    - 3. the most frequent string is taken as reference\n",
    "    - 4. new column name is: \"ColumnName_Category\"\n",
    "    (e.g., column 'gender' with 80 'M' and 79 'F'; the dummy column left is 'gender_F')\n",
    "\n",
    "    \"\"\"\n",
    "    numeric_df = rawdf.select_dtypes(include=[np.number])\n",
    "    str_columns = [col for col in rawdf.columns if col not in numeric_df.columns]\n",
    "    dummy_col_df = pd.get_dummies(rawdf[str_columns], dummy_na=True)\n",
    "    numeric_df = numeric_df.join(dummy_col_df)\n",
    "    most_frequent_values = rawdf[str_columns].mode().loc[0].to_dict()\n",
    "    reference_cols = [\"{}_{}\".format(key, value) for key, value in most_frequent_values.items()]\n",
    "    numeric_df.drop(reference_cols, axis=1, inplace=True)\n",
    "    return numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_clfs_params():\n",
    "    # model_options[model_classes_selected] determines which of these models\n",
    "    # are actually run, all parameter options in grid run for each selected model\n",
    "\n",
    "    clfs = {\n",
    "        'logit': LogisticRegression(),\n",
    "        'LR_no_penalty': LogisticRegression(C=1e6),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=False),\n",
    "        'GB': GradientBoostingClassifier(\n",
    "            learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3)\n",
    "    }\n",
    "\n",
    "    grid = {\n",
    "        'logit': {'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1.0,10.0]},\n",
    "        'LR_no_penalty': {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'SGD': {'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'ET': {'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,\n",
    "            'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],\n",
    "            'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "        'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],\n",
    "            'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "    }\n",
    "    return clfs, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_loop(clfs, params, train_X, train_y,\n",
    "        criterion, models_to_run, cv_folds):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where the keys are model nicknames (strings)\n",
    "    and the values are GridSearchCV objects containing attributes like\n",
    "    model.best_score_ and model.best_estimator_\n",
    "\n",
    "    :param dict(str:estimator) clfs: clfs as returned by define_clfs_params\n",
    "    :param dict(str:dict) params: grid of classifier hyperparameter options\n",
    "        to grid search over as returned by define_clfs_params\n",
    "    :param pandas.DataFrame train_X: index is student_lookup, columns are all\n",
    "        features to train over in the model\n",
    "    :param pandas.Series(int) train_y: index is student_lookup, value is 0 or 1\n",
    "        for outcome label\n",
    "    :param string criterion: evaluation criterion for model selection on the\n",
    "        validation set, to be read in from model_options (e.g. 'f1')\n",
    "    :param list[string] models_to_run: which models to actually run as read in\n",
    "        from model_options (e.g. ['logit', 'DT'])\n",
    "    :param sklearn.KFolds cv_folds: a KFolds generator object over the index\n",
    "        given in train_X and train_y (a list of lists of student_lookups)\n",
    "    :rtype dict(string: GridSearchCV)\n",
    "    \"\"\"\n",
    "    best_validated_models = dict()\n",
    "    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "        model_name=models_to_run[index]\n",
    "        print(model_name)\n",
    "        parameter_values = params[model_name]\n",
    "        #param_grid = ParameterGrid(parameter_values)\n",
    "        best_validated_models[model_name] = GridSearchCV(clf, parameter_values, scoring=criterion, cv=cv_folds)\n",
    "        best_validated_models[model_name].fit(train_X, train_y)\n",
    "\n",
    "        model_cv_score = best_validated_models[model_name].best_score_\n",
    "        print(\"model: {model} cv_score: {score}\".format(\n",
    "            model=model_name, score=model_cv_score))\n",
    "    return best_validated_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temporal_cohort_test_split(joint_df, cohort_grade_level_begin,\n",
    "    cohorts_held_out, cohorts_training):\n",
    "    \"\"\" Splits the given joint_df of features & outcomes and\n",
    "    returns a train/test dataset\n",
    "    :param pd.DataFrame joint_df:\n",
    "    :param list[int] cohorts_held_out:\n",
    "    \"\"\"\n",
    "    if (cohorts_training=='all'):\n",
    "        train = joint_df[~joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    else:\n",
    "        train = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_training)]\n",
    "    test = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_performance(outcomes, predictions):\n",
    "    \"\"\" Returns a dict of model performance objects\n",
    "    :param list[int] outcomes:\n",
    "    :param list[float] predictions:\n",
    "    \"\"\"\n",
    "    performance_objects = {}\n",
    "    performance_objects['pr_curve'] = precision_recall_curve(outcomes, predictions)\n",
    "    performance_objects['roc_curve'] = roc_curve(outcomes, predictions)\n",
    "    #performance_objects['confusion_matrix'] = confusion_matrix(outcomes,predictions)\n",
    "    return performance_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_outcomes_plus_features(model_options):\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        # get labeled outcomes\n",
    "        # Assumes:\n",
    "        # model.outcome table contains a column (name given in cohort_grade_level_begin) for each cohort base year we choose\n",
    "        # e.g. 'cohort_9th' contains the year each student is seen in 9th grade\n",
    "        # and contains an outcome column (name given in outcome_name)\n",
    "        # and 'student_lookup' columns\n",
    "        # Usage:\n",
    "        # select train, validation, and test based on values in column\n",
    "        # 'cohort_grade_level_begin' according to value in 'cohorts_held_out'\n",
    "        outcomes_with_student_lookup = read_table_to_df(connection,\n",
    "            table_name = 'outcome', schema = 'model', nrows = -1,\n",
    "            columns = ['student_lookup', model_options['outcome_name'], model_options['cohort_grade_level_begin']])\n",
    "        # drop students without student_lookup, outcome, or cohort identifier\n",
    "        # can use subset = [colnames] to drop based on NAs in certain columns only\n",
    "        outcomes_with_student_lookup.dropna(inplace=True)\n",
    "        joint_label_features = outcomes_with_student_lookup.copy()\n",
    "\n",
    "        # get all requested input features\n",
    "        # Assumes:\n",
    "        # every features table contains 'student_lookup'\n",
    "        # plus a column for the requested possible features\n",
    "\n",
    "        for table, column_names in model_options['features_included'].items():\n",
    "            features = read_table_to_df(connection, table_name = table,\n",
    "                schema = 'model', nrows = -1,\n",
    "                columns=(['student_lookup'] + column_names))\n",
    "        # join to only keep features that have labeled outcomes\n",
    "            joint_label_features = pd.merge(joint_label_features, features,\n",
    "                how = 'left', on = 'student_lookup')\n",
    "\n",
    "    # build dataframe containing student_lookup, outcome, cohort,\n",
    "    # and all features as numeric non-categorical values\n",
    "    joint_label_features.set_index('student_lookup', inplace=True)\n",
    "    joint_label_features = df2num(joint_label_features)\n",
    "    return joint_label_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in_yaml(filename=os.path.join(base_pathname,\n",
    "        'Models_Results', 'model_options.yaml')):\n",
    "    with open(filename, 'r') as f:\n",
    "        model_options = yaml.load(f)\n",
    "\n",
    "    # Maybe we want to have default values for these options and replace\n",
    "    # from a new yaml file as necessary\n",
    "    assert(type(model_options) == dict), \"bad formatting in yaml file\"\n",
    "    required_keys = set(('validation_criterion', 'features_included', 'cohorts_training',\n",
    "        'cohorts_held_out', 'file_save_name', 'model_classes_selected', 'outcome_name',\n",
    "        'cohort_grade_level_begin', 'model_test_holdout', 'random_seed'))\n",
    "    assert(all([key in model_options.keys() for key in required_keys])), \\\n",
    "        \"missing model specifications in yaml file\"\n",
    "\n",
    "    assert(type(model_options['features_included']) == dict), \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['model_classes_selected']) == list), \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['cohorts_held_out']) == list), \"bad formatting in yaml file\"\n",
    "    assert(type(model_options['cohorts_training']) == list or\n",
    "        model_options['cohorts_training'] == 'all'), \"bad formatting in yaml file\"\n",
    "    return model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_null_dummies(data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data_null_columns = data[data.columns[data.isnull().sum() > 0]]\n",
    "    data_null_dummies = data_null_columns.isnull()*1.0\n",
    "    data_null_dummies.rename(columns=lambda x: x + '_isnull', inplace=True)\n",
    "    data_plus_dummies = data.merge(data_null_dummies, left_index=True, right_index=True)\n",
    "    return data_plus_dummies\n",
    "\n",
    "def impute_missing_values(train, test, strategy):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if (strategy=='none'):\n",
    "        return train, test\n",
    "        \n",
    "    elif(strategy == 'mean_plus_dummies' or strategy == 'median_plus_dummies'):\n",
    "        train = add_null_dummies(train) # add feature_isnull columns 0 or 1\n",
    "        test = add_null_dummies(test)\n",
    "\n",
    "        imputer = Imputer(strategy=strategy.split(\"_\")[0])\n",
    "        imputer.fit(train)\n",
    "        train = pd.DataFrame(imputer.transform(train), columns = train.columns, index = train.index)\n",
    "        test = pd.DataFrame(imputer.transform(test), columns = test.columns, index = test.index)\n",
    "        return train, test\n",
    "\n",
    "    else:\n",
    "        print('unknown imputation strategy. try \"{}\", \"{}\", or \"{}\"'.format(\n",
    "            'mean_plus_dummies', 'median_plus_dummies', 'none'))\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_features(train, test, strategy):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    num_values_by_column = {x: len(train[x].unique()) for x in train.columns}\n",
    "    zero_variance_columns = [k for k,v in num_values_by_column.items() if v == 1]\n",
    "    train.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "    test.drop(zero_variance_columns, axis=1, inplace=True)\n",
    "\n",
    "    if (strategy == 'none'):\n",
    "        return train, test\n",
    "        \n",
    "    elif(strategy == 'standard' or strategy == 'robust'):\n",
    "        non_binary_columns = [k for k, v in num_values_by_column.items() if v > 2]\n",
    "        scaler = StandardScaler() if strategy == 'standard' else RobustScaler()\n",
    "        train_non_binary = train[non_binary_columns]\n",
    "        test_non_binary = test[non_binary_columns]\n",
    "        scaler.fit(train_non_binary)\n",
    "        train_non_binary = pd.DataFrame(scaler.transform(train_non_binary),\n",
    "            columns = non_binary_columns, index = train.index)\n",
    "        test_non_binary = pd.DataFrame(scaler.transform(test_non_binary),\n",
    "            columns = non_binary_columns, index = test.index)\n",
    "\n",
    "        train_scaled = train.drop(non_binary_columns, axis=1)\n",
    "        test_scaled = test.drop(non_binary_columns, axis=1)\n",
    "        train_scaled = train_scaled.merge(train_non_binary,\n",
    "            left_index=True, right_index=True)\n",
    "        test_scaled = test_scaled.merge(test_non_binary,\n",
    "            left_index=True, right_index=True)\n",
    "        return train_scaled, test_scaled\n",
    "\n",
    "    else:\n",
    "        print('unknown feature scaling strategy. try \"{}\", \"{}\", or \"{}\"'.format(\n",
    "            'standard', 'robust', 'none'))\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cohorts_training': 'all', 'features_included': {'grades': ['gpa_gr_3', 'gpa_gr_4', 'gpa_gr_5', 'gpa_gr_6', 'gpa_gr_7', 'gpa_gr_8', 'gpa_gr_9'], 'demographics': ['ethnicity', 'gender']}, 'validation_criterion': 'accuracy', 'cohorts_held_out': [2012], 'cohort_grade_level_begin': 'cohort_9th', 'outcome_name': 'not_on_time', 'missing_impute_strategy': 'median_plus_dummies', 'model_test_holdout': 'temporal_cohort', 'user_description': 'initial_skeleton_pipeline_test', 'model_classes_selected': ['logit', 'DT'], 'feature_scaling': 'robust', 'n_folds': 10, 'write_predictions_to_database': False, 'random_seed': 2187, 'parameter_cross_validation_scheme': 'leave_cohort_out', 'file_save_name': 'test_gpa_gender_ethnicity_imputed'}\n"
     ]
    }
   ],
   "source": [
    "model_options = read_in_yaml()\n",
    "print(model_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set seed for this program from model_options\n",
    "np.random.seed(model_options['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_options['write_predictions_to_database'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on options, draw in data and select the appropriate\n",
    "# labeled outcome column (outcome_name)\n",
    "# cohort identification column (cohort_grade_level_begin)\n",
    "# subset of various feature columns from various tables (features_included)\n",
    "\n",
    "outcome_plus_features = build_outcomes_plus_features(model_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>cohort_9th</th>\n",
       "      <th>gpa_gr_3</th>\n",
       "      <th>gpa_gr_4</th>\n",
       "      <th>gpa_gr_5</th>\n",
       "      <th>gpa_gr_6</th>\n",
       "      <th>gpa_gr_7</th>\n",
       "      <th>gpa_gr_8</th>\n",
       "      <th>gpa_gr_9</th>\n",
       "      <th>ethnicity_A</th>\n",
       "      <th>ethnicity_B</th>\n",
       "      <th>ethnicity_H</th>\n",
       "      <th>ethnicity_I</th>\n",
       "      <th>ethnicity_M</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_lookup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57296.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58652.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.529032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57294.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69065.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63909.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                not_on_time  cohort_9th  gpa_gr_3  gpa_gr_4  gpa_gr_5  \\\n",
       "student_lookup                                                          \n",
       "57296.0                   0        2006       NaN       NaN       NaN   \n",
       "58652.0                   0        2006       NaN       NaN       NaN   \n",
       "57294.0                   0        2006       NaN       NaN       NaN   \n",
       "69065.0                   1        2006       NaN       NaN       NaN   \n",
       "63909.0                   1        2006       NaN       NaN       NaN   \n",
       "\n",
       "                gpa_gr_6  gpa_gr_7  gpa_gr_8  gpa_gr_9  ethnicity_A  \\\n",
       "student_lookup                                                        \n",
       "57296.0              NaN       NaN       NaN  1.266667          0.0   \n",
       "58652.0              NaN       NaN       NaN  3.529032          0.0   \n",
       "57294.0              NaN       NaN       NaN  1.205000          0.0   \n",
       "69065.0              NaN       NaN       NaN       NaN          0.0   \n",
       "63909.0              NaN       NaN       NaN       NaN          0.0   \n",
       "\n",
       "                ethnicity_B  ethnicity_H  ethnicity_I  ethnicity_M  \\\n",
       "student_lookup                                                       \n",
       "57296.0                 0.0          0.0          0.0          0.0   \n",
       "58652.0                 0.0          0.0          0.0          0.0   \n",
       "57294.0                 0.0          0.0          0.0          0.0   \n",
       "69065.0                 0.0          0.0          0.0          0.0   \n",
       "63909.0                 1.0          0.0          0.0          0.0   \n",
       "\n",
       "                ethnicity_nan  gender_F  gender_nan  \n",
       "student_lookup                                       \n",
       "57296.0                   0.0       0.0         0.0  \n",
       "58652.0                   0.0       0.0         0.0  \n",
       "57294.0                   0.0       0.0         0.0  \n",
       "69065.0                   0.0       0.0         0.0  \n",
       "63909.0                   0.0       0.0         0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_plus_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_options['model_test_holdout'] == 'temporal_cohort':\n",
    "    # if using temporal cohort model performance validation,\n",
    "    # we choose the cohorts in cohorts_held_out for the test set\n",
    "    train, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "        model_options['cohort_grade_level_begin'],\n",
    "        model_options['cohorts_held_out'],\n",
    "        model_options['cohorts_training'])\n",
    "\n",
    "else:\n",
    "    # if not using temporal test set, split randomly\n",
    "    train, test = train_test_split(outcome_plus_features, test_size=0.20,\n",
    "        random_state=model_options['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006 2007 2008 2009 2010 2011]\n",
      "[2012]\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(train.cohort_9th))\n",
    "print(pd.unique(test.cohort_9th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get subtables for each for easy reference\n",
    "train_X = train.drop([model_options['outcome_name'],\n",
    "    model_options['cohort_grade_level_begin']],axis=1)\n",
    "test_X = test.drop([model_options['outcome_name'],\n",
    "    model_options['cohort_grade_level_begin']],axis=1)\n",
    "train_y = train[model_options['outcome_name']]\n",
    "test_y = test[model_options['outcome_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do missing value feature imputation here\n",
    "train_X, test_X = impute_missing_values(train_X, test_X,\n",
    "    model_options['missing_impute_strategy'])\n",
    "assert(all(train_X.columns == test_X.columns)), \"train and test have different columns\"\n",
    "\n",
    "# do feature scaling here\n",
    "train_X, test_X = scale_features(train_X, test_X,\n",
    "    model_options['feature_scaling'])\n",
    "assert(all(train_X.columns == test_X.columns)), \"train and test have different columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs, params = define_clfs_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave_cohort_out\n"
     ]
    }
   ],
   "source": [
    "if model_options['parameter_cross_validation_scheme'] == 'none':\n",
    "    # no need to further manipulate train dataset\n",
    "    cohort_kfolds = 2 # hacky way to have GridSearchCV fit to 2 k-folds\n",
    "elif model_options['parameter_cross_validation_scheme'] == 'leave_cohort_out':\n",
    "    # choose another validation set amongst the training set to\n",
    "    # estimate parameters and model selection across cohort folds\n",
    "    print('leave_cohort_out')\n",
    "    cohort_kfolds = LeaveOneLabelOut(train[model_options['cohort_grade_level_begin']])\n",
    "elif model_options['parameter_cross_validation_scheme'] == 'k_fold':\n",
    "    # ignore cohorts and use random folds to estimate parameter\n",
    "    print('k_fold_parameter_estimation')\n",
    "    cohort_kfolds = LabelKFold(train.index, n_folds=model_options['n_folds'])\n",
    "else:\n",
    "    print('unknown cross-validation strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006 2006 2006 ..., 2011 2011 2011]\n",
      "train:  [2007 2008 2009 2010 2011]\n",
      "validation:  [2006]\n",
      "train:  [2006 2008 2009 2010 2011]\n",
      "validation:  [2007]\n",
      "train:  [2006 2007 2009 2010 2011]\n",
      "validation:  [2008]\n",
      "train:  [2006 2007 2008 2010 2011]\n",
      "validation:  [2009]\n",
      "train:  [2006 2007 2008 2009 2011]\n",
      "validation:  [2010]\n",
      "train:  [2006 2007 2008 2009 2010]\n",
      "validation:  [2011]\n"
     ]
    }
   ],
   "source": [
    "print(cohort_kfolds.labels)\n",
    "for train_fold, val_fold in cohort_kfolds:\n",
    "    print('train: ', np.unique(train.iloc[train_fold].cohort_9th))\n",
    "    print('validation: ', np.unique(train.iloc[val_fold].cohort_9th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_options['validation_criterion'] = 'accuracy' # 'average_precision' #' log_loss' # 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit\n",
      "model: logit cv_score: 0.7719510851602952\n",
      "DT\n",
      "model: DT cv_score: 0.7806544012338879\n"
     ]
    }
   ],
   "source": [
    "best_validated_models = clf_loop(clfs, params, train_X, train_y,\n",
    "    criterion=model_options['validation_criterion'],\n",
    "    models_to_run=model_options['model_classes_selected'],\n",
    "    cv_folds=cohort_kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, model in best_validated_models.items():\n",
    "    clf = model.best_estimator_\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        test_set_scores = clf.decision_function(test_X)\n",
    "    else:\n",
    "        test_set_scores = clf.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_train = best_validated_models['logit'].predict_proba(train_X)\n",
    "predicted_test = best_validated_models['logit'].predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([probs == [0.5, 0.5] for probs in predicted_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([probs == [0.5, 0.5] for probs in predicted_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.61073809,  0.38926191],\n",
       "       [ 0.90002904,  0.09997096],\n",
       "       [ 0.59935857,  0.40064143],\n",
       "       ..., \n",
       "       [ 0.62209806,  0.37790194],\n",
       "       [ 0.62209806,  0.37790194],\n",
       "       [ 0.62209806,  0.37790194]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89440181,  0.10559819],\n",
       "       [ 0.79661955,  0.20338045],\n",
       "       [ 0.91974039,  0.08025961],\n",
       "       ..., \n",
       "       [ 0.89720486,  0.10279514],\n",
       "       [ 0.85081305,  0.14918695],\n",
       "       [ 0.76903548,  0.23096452]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_coefs = best_validated_models['logit'].best_estimator_.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ethnicity_A', 'ethnicity_B', 'ethnicity_H', 'ethnicity_I',\n",
       "       'ethnicity_M', 'ethnicity_nan', 'gender_F', 'gpa_gr_3_isnull',\n",
       "       'gpa_gr_4_isnull', 'gpa_gr_5_isnull', 'gpa_gr_6_isnull',\n",
       "       'gpa_gr_7_isnull', 'gpa_gr_8_isnull', 'gpa_gr_9_isnull', 'gpa_gr_9',\n",
       "       'gpa_gr_7', 'gpa_gr_8', 'gpa_gr_6', 'gpa_gr_5', 'gpa_gr_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ethnicity_A': 0.0,\n",
       " 'ethnicity_B': 0.0,\n",
       " 'ethnicity_H': 0.0,\n",
       " 'ethnicity_I': 0.0,\n",
       " 'ethnicity_M': 0.0,\n",
       " 'ethnicity_nan': 0.0,\n",
       " 'gender_F': 0.0,\n",
       " 'gpa_gr_3_isnull': -1.6012998923350741,\n",
       " 'gpa_gr_4': 0.0,\n",
       " 'gpa_gr_4_isnull': 0.0,\n",
       " 'gpa_gr_5': 0.0,\n",
       " 'gpa_gr_5_isnull': 0.0,\n",
       " 'gpa_gr_6': 0.0,\n",
       " 'gpa_gr_6_isnull': 0.0,\n",
       " 'gpa_gr_7': 0.0,\n",
       " 'gpa_gr_7_isnull': 0.0,\n",
       " 'gpa_gr_8': -0.14462472382581903,\n",
       " 'gpa_gr_8_isnull': 0.0,\n",
       " 'gpa_gr_9': -0.58884723669969719,\n",
       " 'gpa_gr_9_isnull': 1.1028368947351592}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(train_X.columns, logit_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns) == len(logit_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.75245, std: 0.01053, params: {'C': 1e-05, 'penalty': 'l1'},\n",
       " mean: 0.75708, std: 0.01358, params: {'C': 1e-05, 'penalty': 'l2'},\n",
       " mean: 0.75245, std: 0.01053, params: {'C': 0.0001, 'penalty': 'l1'},\n",
       " mean: 0.75719, std: 0.01497, params: {'C': 0.0001, 'penalty': 'l2'},\n",
       " mean: 0.75432, std: 0.01214, params: {'C': 0.001, 'penalty': 'l1'},\n",
       " mean: 0.76270, std: 0.01661, params: {'C': 0.001, 'penalty': 'l2'},\n",
       " mean: 0.77195, std: 0.01636, params: {'C': 0.01, 'penalty': 'l1'},\n",
       " mean: 0.77173, std: 0.01571, params: {'C': 0.01, 'penalty': 'l2'},\n",
       " mean: 0.72711, std: 0.07758, params: {'C': 0.1, 'penalty': 'l1'},\n",
       " mean: 0.75047, std: 0.04894, params: {'C': 0.1, 'penalty': 'l2'},\n",
       " mean: 0.73020, std: 0.07834, params: {'C': 1.0, 'penalty': 'l1'},\n",
       " mean: 0.72976, std: 0.07986, params: {'C': 1.0, 'penalty': 'l2'},\n",
       " mean: 0.73009, std: 0.07900, params: {'C': 10.0, 'penalty': 'l1'},\n",
       " mean: 0.72943, std: 0.07988, params: {'C': 10.0, 'penalty': 'l2'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validated_models['logit'].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(best_validated_models['logit'].predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89440181,  0.10559819],\n",
       "       [ 0.79661955,  0.20338045],\n",
       "       [ 0.91974039,  0.08025961],\n",
       "       ..., \n",
       "       [ 0.89720486,  0.10279514],\n",
       "       [ 0.85081305,  0.14918695],\n",
       "       [ 0.76903548,  0.23096452]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validated_models['logit'].predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
