{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "pathname = os.path.dirname(\"/home/jgutman/mvesc/Models_Results/\")\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mvesc_utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select * from model.outcome\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11777\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "            results = cursor.fetchall()\n",
    "            print(len(results))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(model_options['randomSeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_outcomes_plus_features(model_options):\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        # get labeled outcomes\n",
    "        # Assumes:\n",
    "        # model.outcome table contains a column (name given in cohort_grade_level_begin) for each cohort base year we choose\n",
    "        # e.g. 'cohort_9th' contains the year each student is seen in 9th grade\n",
    "        # and contains an outcome column (name given in outcome_name)\n",
    "        # and 'student_lookup' columns\n",
    "        # Usage:\n",
    "        # select train, validation, and test based on values in column\n",
    "        # 'cohort_grade_level_begin' according to value in 'cohorts_held_out'\n",
    "        outcomes_with_student_lookup = read_table_to_df(connection,\n",
    "            table_name = 'outcome', schema = 'model', nrows = -1,\n",
    "            columns = ['student_lookup', model_options['outcome_name'], model_options['cohort_grade_level_begin']])\n",
    "        # drop students without student_lookup, outcome, or cohort identifier\n",
    "        # can use subset = [colnames] to drop based on NAs in certain columns only\n",
    "        outcomes_with_student_lookup.dropna(inplace=True)\n",
    "        joint_label_features = outcomes_with_student_lookup.copy()\n",
    "\n",
    "        # get all requested input features\n",
    "        # Assumes:\n",
    "        # every features table contains 'student_lookup'\n",
    "        # plus a column for the requested possible features\n",
    "\n",
    "        for table, column_names in model_options['features_included'].items():\n",
    "            features = read_table_to_df(connection, table_name = table,\n",
    "                schema = 'model', nrows = -1,\n",
    "                columns=(['student_lookup'] + column_names))\n",
    "        # join to only keep features that have labeled outcomes\n",
    "            joint_label_features = pd.merge(joint_label_features, features,\n",
    "                how = 'left', on = 'student_lookup')\n",
    "\n",
    "    # build dataframe containing student_lookup, outcome, cohort,\n",
    "    # and all features as numeric non-categorical values\n",
    "    joint_label_features.set_index('student_lookup', inplace=True)\n",
    "    joint_label_features = df2num(joint_label_features)\n",
    "    return joint_label_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df2num(rawdf):\n",
    "    \"\"\" Convert data frame with numeric variables and strings to numeric dataframe\n",
    "\n",
    "    :param pd.dataframe rawdf: raw data frame\n",
    "    :returns pd.dataframe df: a data frame with strings converted to dummies, other columns unchanged\n",
    "    :rtype: pd.dataframe\n",
    "    Rules:\n",
    "    - 1. numeric columns unchanged;\n",
    "    - 2. strings converted to dummeis;\n",
    "    - 3. the most frequent string is taken as reference\n",
    "    - 4. new column name is: \"ColumnName_Category\"\n",
    "    (e.g., column 'gender' with 80 'M' and 79 'F'; the dummy column left is 'gender_F')\n",
    "\n",
    "    \"\"\"\n",
    "    numeric_df = rawdf.select_dtypes(include=[np.number])\n",
    "    str_columns = [col for col in rawdf.columns if col not in numeric_df.columns]\n",
    "    dummy_col_df = pd.get_dummies(rawdf[str_columns], dummy_na=True)\n",
    "    numeric_df = numeric_df.join(dummy_col_df)\n",
    "    most_frequent_values = rawdf[str_columns].mode().loc[0].to_dict()\n",
    "    reference_cols = [\"{}_{}\".format(key, value) for key, value in most_frequent_values.items()]\n",
    "    numeric_df.drop(reference_cols, axis=1, inplace=True)\n",
    "    return numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import LeaveOneLabelOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_kfolds = LeaveOneLabelOut(joint_label_features[modelOptions['cohort_grade_level_begin']])\n",
    "len(cohort_kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_clfs_params():\n",
    "    clfs = {'logit': LogisticRegression(),\n",
    "    'DT': DecisionTreeClassifier()\n",
    "    }\n",
    "\n",
    "    grid = {'logit': {'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]}\n",
    "    }\n",
    "    return clfs, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs, params = define_clfs_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import ParameterGrid, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid(params['logit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.LeaveOneLabelOut(labels=[2006 2006 ..., 2011 2011]),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV(clf, params['logit'], scoring=criterion, cv=cohort_kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_options.yaml', 'r') as f:\n",
    "    model_options = yaml.load(f)\n",
    "assert(type(model_options)==dict)\n",
    "assert(type(model_options['features_included']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "criterion='f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.LeaveOneLabelOut(labels=[2006 2006 2006 ..., 2011 2011 2011])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'demographics': ['ethnicity', 'gender']}, {'grades': ['gpa_8th']}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_options['features_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_options['features_included'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>cohort_9th</th>\n",
       "      <th>ethnicity_A</th>\n",
       "      <th>ethnicity_B</th>\n",
       "      <th>ethnicity_H</th>\n",
       "      <th>ethnicity_I</th>\n",
       "      <th>ethnicity_M</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_lookup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57296.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58652.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57294.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69065.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63909.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57292.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57290.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57288.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57285.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57284.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57282.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41726.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57279.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57278.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57277.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57276.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57275.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57274.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57273.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57271.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57270.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57268.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57266.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57265.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57264.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57259.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58523.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36739.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57255.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57254.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70804.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19548.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699419.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19149.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19123.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19061.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19055.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700797.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19044.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19040.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19039.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19038.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19037.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19036.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19035.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700539.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19033.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700311.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19032.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19028.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19027.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19026.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19025.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18545.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17827.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11777 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                not_on_time  cohort_9th  ethnicity_A  ethnicity_B  \\\n",
       "student_lookup                                                      \n",
       "57296.0                   0        2006          0.0          0.0   \n",
       "58652.0                   0        2006          0.0          0.0   \n",
       "57294.0                   0        2006          0.0          0.0   \n",
       "69065.0                   1        2006          0.0          0.0   \n",
       "63909.0                   1        2006          0.0          1.0   \n",
       "57292.0                   0        2006          0.0          0.0   \n",
       "57290.0                   0        2006          0.0          0.0   \n",
       "57288.0                   0        2006          0.0          0.0   \n",
       "57285.0                   0        2006          0.0          0.0   \n",
       "57284.0                   0        2006          0.0          0.0   \n",
       "57282.0                   0        2006          0.0          0.0   \n",
       "41726.0                   1        2006          0.0          0.0   \n",
       "57279.0                   0        2006          0.0          0.0   \n",
       "57278.0                   0        2006          0.0          0.0   \n",
       "57277.0                   0        2006          0.0          0.0   \n",
       "57276.0                   1        2006          0.0          0.0   \n",
       "57275.0                   0        2006          0.0          0.0   \n",
       "57274.0                   0        2006          0.0          0.0   \n",
       "57273.0                   0        2006          0.0          0.0   \n",
       "57271.0                   0        2006          0.0          0.0   \n",
       "57270.0                   0        2006          0.0          0.0   \n",
       "57268.0                   0        2006          0.0          0.0   \n",
       "57266.0                   0        2006          0.0          0.0   \n",
       "57265.0                   0        2006          0.0          0.0   \n",
       "57264.0                   0        2006          0.0          0.0   \n",
       "57259.0                   0        2006          0.0          0.0   \n",
       "58523.0                   0        2006          0.0          0.0   \n",
       "36739.0                   1        2006          0.0          0.0   \n",
       "57255.0                   0        2006          0.0          0.0   \n",
       "57254.0                   0        2006          0.0          0.0   \n",
       "...                     ...         ...          ...          ...   \n",
       "70804.0                   1        2012          0.0          0.0   \n",
       "19548.0                   0        2012          0.0          0.0   \n",
       "699419.0                  1        2012          0.0          0.0   \n",
       "19308.0                   1        2012          0.0          0.0   \n",
       "19154.0                   0        2012          0.0          0.0   \n",
       "19150.0                   1        2012          0.0          0.0   \n",
       "19149.0                   1        2012          0.0          0.0   \n",
       "19123.0                   1        2012          0.0          0.0   \n",
       "19061.0                   0        2012          0.0          0.0   \n",
       "19055.0                   0        2012          0.0          0.0   \n",
       "700797.0                  1        2012          0.0          0.0   \n",
       "19044.0                   0        2012          0.0          0.0   \n",
       "19040.0                   0        2012          0.0          0.0   \n",
       "19039.0                   0        2012          0.0          0.0   \n",
       "19038.0                   0        2012          0.0          0.0   \n",
       "19037.0                   1        2012          0.0          0.0   \n",
       "19036.0                   0        2012          0.0          0.0   \n",
       "19035.0                   0        2012          0.0          0.0   \n",
       "19034.0                   0        2012          0.0          0.0   \n",
       "700539.0                  1        2012          0.0          0.0   \n",
       "19033.0                   0        2012          0.0          0.0   \n",
       "700311.0                  1        2012          0.0          0.0   \n",
       "19032.0                   0        2012          0.0          0.0   \n",
       "19028.0                   0        2012          0.0          0.0   \n",
       "19027.0                   0        2012          0.0          0.0   \n",
       "19026.0                   0        2012          0.0          0.0   \n",
       "19025.0                   0        2012          0.0          0.0   \n",
       "18590.0                   0        2012          0.0          0.0   \n",
       "18545.0                   0        2012          0.0          0.0   \n",
       "17827.0                   0        2012          0.0          0.0   \n",
       "\n",
       "                ethnicity_H  ethnicity_I  ethnicity_M  ethnicity_nan  \\\n",
       "student_lookup                                                         \n",
       "57296.0                 0.0          0.0          0.0            0.0   \n",
       "58652.0                 0.0          0.0          0.0            0.0   \n",
       "57294.0                 0.0          0.0          0.0            0.0   \n",
       "69065.0                 0.0          0.0          0.0            0.0   \n",
       "63909.0                 0.0          0.0          0.0            0.0   \n",
       "57292.0                 0.0          0.0          0.0            0.0   \n",
       "57290.0                 0.0          0.0          0.0            0.0   \n",
       "57288.0                 0.0          0.0          0.0            0.0   \n",
       "57285.0                 0.0          0.0          0.0            0.0   \n",
       "57284.0                 0.0          0.0          0.0            0.0   \n",
       "57282.0                 0.0          0.0          0.0            0.0   \n",
       "41726.0                 0.0          0.0          0.0            0.0   \n",
       "57279.0                 0.0          0.0          0.0            0.0   \n",
       "57278.0                 0.0          0.0          0.0            0.0   \n",
       "57277.0                 0.0          0.0          0.0            0.0   \n",
       "57276.0                 0.0          0.0          0.0            0.0   \n",
       "57275.0                 0.0          0.0          0.0            0.0   \n",
       "57274.0                 0.0          0.0          0.0            0.0   \n",
       "57273.0                 0.0          0.0          0.0            0.0   \n",
       "57271.0                 0.0          0.0          0.0            0.0   \n",
       "57270.0                 0.0          0.0          0.0            0.0   \n",
       "57268.0                 0.0          0.0          0.0            0.0   \n",
       "57266.0                 0.0          0.0          0.0            0.0   \n",
       "57265.0                 0.0          0.0          0.0            0.0   \n",
       "57264.0                 0.0          0.0          0.0            0.0   \n",
       "57259.0                 0.0          0.0          0.0            0.0   \n",
       "58523.0                 0.0          0.0          0.0            0.0   \n",
       "36739.0                 0.0          0.0          0.0            0.0   \n",
       "57255.0                 0.0          0.0          1.0            0.0   \n",
       "57254.0                 0.0          0.0          0.0            0.0   \n",
       "...                     ...          ...          ...            ...   \n",
       "70804.0                 1.0          0.0          0.0            0.0   \n",
       "19548.0                 0.0          0.0          0.0            0.0   \n",
       "699419.0                0.0          0.0          0.0            0.0   \n",
       "19308.0                 0.0          0.0          0.0            0.0   \n",
       "19154.0                 0.0          0.0          0.0            0.0   \n",
       "19150.0                 0.0          0.0          0.0            0.0   \n",
       "19149.0                 0.0          0.0          0.0            0.0   \n",
       "19123.0                 0.0          0.0          0.0            0.0   \n",
       "19061.0                 0.0          0.0          0.0            0.0   \n",
       "19055.0                 0.0          0.0          1.0            0.0   \n",
       "700797.0                0.0          0.0          0.0            0.0   \n",
       "19044.0                 0.0          0.0          0.0            0.0   \n",
       "19040.0                 0.0          0.0          0.0            0.0   \n",
       "19039.0                 0.0          0.0          0.0            0.0   \n",
       "19038.0                 0.0          0.0          0.0            0.0   \n",
       "19037.0                 0.0          0.0          0.0            0.0   \n",
       "19036.0                 0.0          0.0          0.0            0.0   \n",
       "19035.0                 0.0          0.0          0.0            0.0   \n",
       "19034.0                 0.0          0.0          0.0            0.0   \n",
       "700539.0                0.0          0.0          0.0            0.0   \n",
       "19033.0                 0.0          0.0          0.0            0.0   \n",
       "700311.0                0.0          0.0          0.0            0.0   \n",
       "19032.0                 0.0          0.0          0.0            0.0   \n",
       "19028.0                 0.0          0.0          0.0            0.0   \n",
       "19027.0                 0.0          0.0          0.0            0.0   \n",
       "19026.0                 0.0          0.0          0.0            0.0   \n",
       "19025.0                 0.0          0.0          0.0            0.0   \n",
       "18590.0                 0.0          0.0          0.0            0.0   \n",
       "18545.0                 0.0          0.0          0.0            0.0   \n",
       "17827.0                 0.0          0.0          0.0            0.0   \n",
       "\n",
       "                gender_F  gender_nan  \n",
       "student_lookup                        \n",
       "57296.0              0.0         0.0  \n",
       "58652.0              0.0         0.0  \n",
       "57294.0              0.0         0.0  \n",
       "69065.0              0.0         0.0  \n",
       "63909.0              0.0         0.0  \n",
       "57292.0              1.0         0.0  \n",
       "57290.0              1.0         0.0  \n",
       "57288.0              0.0         0.0  \n",
       "57285.0              0.0         0.0  \n",
       "57284.0              1.0         0.0  \n",
       "57282.0              1.0         0.0  \n",
       "41726.0              1.0         0.0  \n",
       "57279.0              0.0         0.0  \n",
       "57278.0              1.0         0.0  \n",
       "57277.0              1.0         0.0  \n",
       "57276.0              0.0         0.0  \n",
       "57275.0              0.0         0.0  \n",
       "57274.0              1.0         0.0  \n",
       "57273.0              1.0         0.0  \n",
       "57271.0              0.0         0.0  \n",
       "57270.0              1.0         0.0  \n",
       "57268.0              1.0         0.0  \n",
       "57266.0              1.0         0.0  \n",
       "57265.0              1.0         0.0  \n",
       "57264.0              0.0         0.0  \n",
       "57259.0              1.0         0.0  \n",
       "58523.0              1.0         0.0  \n",
       "36739.0              0.0         0.0  \n",
       "57255.0              0.0         0.0  \n",
       "57254.0              0.0         0.0  \n",
       "...                  ...         ...  \n",
       "70804.0              0.0         0.0  \n",
       "19548.0              1.0         0.0  \n",
       "699419.0             1.0         0.0  \n",
       "19308.0              0.0         0.0  \n",
       "19154.0              0.0         0.0  \n",
       "19150.0              0.0         0.0  \n",
       "19149.0              1.0         0.0  \n",
       "19123.0              0.0         0.0  \n",
       "19061.0              0.0         0.0  \n",
       "19055.0              0.0         0.0  \n",
       "700797.0             1.0         0.0  \n",
       "19044.0              0.0         0.0  \n",
       "19040.0              1.0         0.0  \n",
       "19039.0              0.0         0.0  \n",
       "19038.0              0.0         0.0  \n",
       "19037.0              0.0         0.0  \n",
       "19036.0              0.0         0.0  \n",
       "19035.0              0.0         0.0  \n",
       "19034.0              1.0         0.0  \n",
       "700539.0             0.0         0.0  \n",
       "19033.0              0.0         0.0  \n",
       "700311.0             1.0         0.0  \n",
       "19032.0              1.0         0.0  \n",
       "19028.0              0.0         0.0  \n",
       "19027.0              0.0         0.0  \n",
       "19026.0              1.0         0.0  \n",
       "19025.0              1.0         0.0  \n",
       "18590.0              0.0         0.0  \n",
       "18545.0              0.0         0.0  \n",
       "17827.0              0.0         0.0  \n",
       "\n",
       "[11777 rows x 10 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_plus_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temporal_cohort_test_split(joint_df, cohort_grade_level_begin,\n",
    "    cohorts_held_out):\n",
    "    \"\"\" Splits the given joint_df of features & outcomes and\n",
    "    returns a train/test dataset\n",
    "    :param pd.DataFrame joint_df:\n",
    "    :param list[int] cohorts_held_out:\n",
    "    \"\"\"\n",
    "    train = joint_df[~joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    test = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "    model_options['cohort_grade_level_begin'],\n",
    "    model_options['cohorts_held_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006 2007 2008 2009 2010 2011]\n",
      "[2012]\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(train.cohort_9th))\n",
    "print(pd.unique(test.cohort_9th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cohort_kfolds = LeaveOneLabelOut(train[model_options['cohort_grade_level_begin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_kfolds = LabelKFold(train.index, n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_loop(clfs, params, criterion, models_to_run, cv_folds, X_train, X_test, y_train, y_test):\n",
    "    best_validated_models = dict()\n",
    "    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "        model_name=models_to_run[index]\n",
    "        print(model_name)\n",
    "        parameter_values = params[models_to_run[index]]\n",
    "        param_grid = ParameterGrid(parameter_values)\n",
    "        best_validated_models[model_name] = GridSearchCV(clf, param_grid, scoring=criterion, cv=cv_folds)\n",
    "        model_cv_score = best_validated_models[model_name].best_score_\n",
    "        print(\"model: {model} score: {score}\".format(model=model_name), score=model_cv_score)\n",
    "    return best_validated_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # get subtables for each for easy reference\n",
    "    train_X = train.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    test_X = test.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    train_y = train[model_options['outcome_name']]\n",
    "    test_y = test[model_options['outcome_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_lookup\n",
       "57296.0     0\n",
       "58652.0     0\n",
       "57294.0     0\n",
       "69065.0     1\n",
       "63909.0     1\n",
       "57292.0     0\n",
       "57290.0     0\n",
       "57288.0     0\n",
       "57285.0     0\n",
       "57284.0     0\n",
       "57282.0     0\n",
       "41726.0     1\n",
       "57279.0     0\n",
       "57278.0     0\n",
       "57277.0     0\n",
       "57276.0     1\n",
       "57275.0     0\n",
       "57274.0     0\n",
       "57273.0     0\n",
       "57271.0     0\n",
       "57270.0     0\n",
       "57268.0     0\n",
       "57266.0     0\n",
       "57265.0     0\n",
       "57264.0     0\n",
       "57259.0     0\n",
       "58523.0     0\n",
       "36739.0     1\n",
       "57255.0     0\n",
       "57254.0     0\n",
       "           ..\n",
       "701016.0    1\n",
       "701036.0    1\n",
       "701037.0    1\n",
       "701041.0    1\n",
       "701046.0    1\n",
       "701056.0    1\n",
       "701058.0    1\n",
       "701067.0    1\n",
       "701084.0    1\n",
       "701090.0    1\n",
       "701091.0    1\n",
       "701093.0    1\n",
       "701097.0    1\n",
       "701098.0    1\n",
       "701099.0    1\n",
       "701100.0    1\n",
       "701101.0    1\n",
       "701105.0    1\n",
       "701108.0    1\n",
       "701110.0    1\n",
       "701115.0    1\n",
       "701121.0    1\n",
       "701130.0    1\n",
       "701139.0    1\n",
       "701145.0    1\n",
       "701148.0    1\n",
       "701157.0    1\n",
       "701163.0    1\n",
       "701165.0    1\n",
       "701168.0    1\n",
       "Name: not_on_time, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict()==dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dict():\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename=os.path.join(base_pathname, \n",
    "    'Models_Results', 'model_options.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jgutman/mvesc/Models_Results/model_options.yaml'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estimate_prediction_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jgutman/env/lib/python3.4/site-packages/ipykernel/mvesc/Models_Results/model_options.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jgutman/mvesc/Models_Results/estimate_prediction_model.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;31m# Also needs to read in an option to output all results to a database\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mmodel_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_in_yaml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;31m# set seed for this program from model_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jgutman/mvesc/Models_Results/estimate_prediction_model.py\u001b[0m in \u001b[0;36mread_in_yaml\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    173\u001b[0m def read_in_yaml(filename=os.path.join(base_pathname,\n\u001b[0;32m    174\u001b[0m     'Models_Results', 'model_options.yaml')):\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mmodel_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jgutman/env/lib/python3.4/site-packages/ipykernel/mvesc/Models_Results/model_options.yaml'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_options = read_in_yaml('model_options.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave_cohort_out\n",
      "logit\n",
      "model: logit score: 0.623774374793434\n",
      "logit\n"
     ]
    }
   ],
   "source": [
    "    # set seed for this program from model_options\n",
    "    np.random.seed(model_options['random_seed'])\n",
    "\n",
    "    # Based on options, draw in data and select the appropriate\n",
    "    # labeled outcome column (outcome_name)\n",
    "    # cohort identification column (cohort_grade_level_begin)\n",
    "    # subset of various feature columns from various tables (features_included)\n",
    "\n",
    "    outcome_plus_features = build_outcomes_plus_features(model_options)\n",
    "\n",
    "    # Use the gathered DataFrame in a predictive model\n",
    "    # Steps:\n",
    "    #   - (A) manage test and validation folds\n",
    "    #   - (B) run the prediction technique across all validation folds\n",
    "    #   - (C) record the inputs and parameters used\n",
    "\n",
    "    # (4A) Choose cohort(s) for test and validation data\n",
    "    # Validation Process\n",
    "    # Use temporal split for creating the test set\n",
    "    # Use cohort-fold cross-validation for parameter search and model selection\n",
    "    #    - temporal (using recent cohorts as a validation set)\n",
    "    #    - k-fold cross (using all cohorts and all years of features)\n",
    "    #    - cohort-fold cross validation (leave one cohort out)\n",
    "\n",
    "    if model_options['model_test_holdout'] == 'temporal_cohort':\n",
    "        # if using temporal cohort model performance validation,\n",
    "        # we choose the cohorts in cohorts_held_out for the test set\n",
    "        train, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "            model_options['cohort_grade_level_begin'],\n",
    "            model_options['cohorts_held_out'])\n",
    "\n",
    "    else:\n",
    "        # if not using temporal test set, split randomly\n",
    "        train, test = train_test_split(outcome_plus_features, test_size=0.20,\n",
    "            random_state=model_options['random_seed'])\n",
    "\n",
    "    # get subtables for each for easy reference\n",
    "    train_X = train.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    test_X = test.drop([model_options['outcome_name'],\n",
    "        model_options['cohort_grade_level_begin']],axis=1)\n",
    "    train_y = train[model_options['outcome_name']]\n",
    "    test_y = test[model_options['outcome_name']]\n",
    "\n",
    "    ####\n",
    "    # From now on, we IGNORE the `test`, `test_X`, `test_y` data until we evaluate the model\n",
    "    ####\n",
    "\n",
    "    ## (4B) Fit on Training ##\n",
    "    # if we require cross-validation of parameters, we can either\n",
    "    #    (a) hold out another cohort in each fold for cross-validation\n",
    "    #    (b) fold all cohorts together for k-fold parameter estimation\n",
    "    clfs, params = define_clfs_params()\n",
    "\n",
    "    if model_options['parameter_cross_validation_scheme'] == 'none':\n",
    "        # no need to further manipulate train dataset\n",
    "        cohort_kfolds = 2 # hacky way to have GridSearchCV fit to 2 k-folds\n",
    "\n",
    "    elif model_options['parameter_cross_validation_scheme'] == 'leave_cohort_out':\n",
    "        # choose another validation set amongst the training set to\n",
    "        # estimate parameters and model selection across cohort folds\n",
    "        print('leave_cohort_out')\n",
    "        cohort_kfolds = LeaveOneLabelOut(train[\n",
    "                model_options['cohort_grade_level_begin']])\n",
    "\n",
    "    elif model_options['parameter_cross_validation_scheme'] == 'k_fold':\n",
    "        # ignore cohorts and use random folds to estimate parameter\n",
    "        print('k_fold_parameter_estimation')\n",
    "        cohort_kfolds = LabelKFold(train.index,\n",
    "            n_folds=model_options[n_folds])\n",
    "\n",
    "    else:\n",
    "        print('unknown cross-validation strategy')\n",
    "\n",
    "    # best_validated_models is a dictionary whose keys are the model\n",
    "    # nicknames in model_classes_selected and values are objects\n",
    "    # returned by GridSearchCV\n",
    "    best_validated_models = clf_loop(clfs, params, train_X, train_y,\n",
    "        criterion=model_options['validation_criterion'],\n",
    "        models_to_run=model_options['model_classes_selected'],\n",
    "        cv_folds=cohort_kfolds)\n",
    "\n",
    "    for model_name, model in best_validated_models.items():\n",
    "        print(model_name)\n",
    "        clf = model.best_estimator_\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            test_set_scores = clf.decision_function(test_X)\n",
    "        else:\n",
    "            test_set_scores = clf.predict_proba(test_X)\n",
    "\n",
    "        ## (4C) Save Results ##\n",
    "        # Save the recorded inputs, model, performance, and text description\n",
    "        #    into a results folder\n",
    "        #        according to sklearn documentation, use joblib instead of pickle\n",
    "        #            save as a .pkl extension\n",
    "        #        store option inputs (randomSeed, train/test split rules, features)\n",
    "        #        store time to completion [missing]\n",
    "\n",
    "        saved_outputs = {\n",
    "            'estimator' : model,\n",
    "            'model_options' : model_options, # this also contains cohort_grade_level_begin for train/test split\n",
    "            'test_y' : test_y,\n",
    "            'test_set_soft_preds' : test_set_scores,\n",
    "            'performance_objects' : measure_performance(test_y, test_set_scores)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set_scores = best_validated_models['logit'].predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pr_curve': (array([ 0.24518519,  1.        ]),\n",
       "  array([ 1.,  0.]),\n",
       "  array([ 0.5])),\n",
       " 'roc_curve': (array([ 0.,  1.]), array([ 0.,  1.]), array([ 1.5,  0.5]))}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_performance(test_y, test_set_scores[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700,)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_scores[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(test_y, test_set_scores[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24518519,  1.        ])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24518518518518517"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_y)/len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.62377, std: 0.00527, params: {'penalty': 'l1', 'C': 1e-05},\n",
       " mean: 0.34926, std: 0.09790, params: {'penalty': 'l2', 'C': 1e-05},\n",
       " mean: 0.62377, std: 0.00527, params: {'penalty': 'l1', 'C': 0.0001},\n",
       " mean: 0.34200, std: 0.03333, params: {'penalty': 'l2', 'C': 0.0001},\n",
       " mean: 0.62377, std: 0.00527, params: {'penalty': 'l1', 'C': 0.001},\n",
       " mean: 0.34299, std: 0.03393, params: {'penalty': 'l2', 'C': 0.001},\n",
       " mean: 0.56849, std: 0.09264, params: {'penalty': 'l1', 'C': 0.01},\n",
       " mean: 0.35608, std: 0.02978, params: {'penalty': 'l2', 'C': 0.01},\n",
       " mean: 0.35751, std: 0.02510, params: {'penalty': 'l1', 'C': 0.1},\n",
       " mean: 0.35617, std: 0.02687, params: {'penalty': 'l2', 'C': 0.1},\n",
       " mean: 0.35354, std: 0.03216, params: {'penalty': 'l1', 'C': 1},\n",
       " mean: 0.35449, std: 0.03231, params: {'penalty': 'l2', 'C': 1},\n",
       " mean: 0.34710, std: 0.02758, params: {'penalty': 'l1', 'C': 10},\n",
       " mean: 0.34712, std: 0.02759, params: {'penalty': 'l2', 'C': 10}]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validated_models['logit'].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(best_validated_models['logit'].predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2',C=1e-05)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.24754875,  0.24638326,  0.24102564,  0.2408359 ,  0.2398761 ,\n",
       "         0.26097046,  0.26076858,  0.2605113 ,  0.25734024,  0.24614338,\n",
       "         0.24550216,  0.2412037 ,  0.8       ,  1.        ,  1.        ]),\n",
       " array([  1.00000000e+00,   9.85313752e-01,   9.41255007e-01,\n",
       "          9.38584780e-01,   9.30574099e-01,   5.50511794e-01,\n",
       "          5.49621718e-01,   5.48731642e-01,   5.30485091e-01,\n",
       "          4.82866044e-01,   4.79750779e-01,   4.63729417e-01,\n",
       "          1.78015131e-03,   8.90075656e-04,   0.00000000e+00]),\n",
       " array([ 0.49157332,  0.49160378,  0.49161434,  0.49162305,  0.49162498,\n",
       "         0.49162635,  0.49162882,  0.49437676,  0.49440722,  0.49441779,\n",
       "         0.4944265 ,  0.49442843,  0.4944298 ,  0.49443227]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_curve(train_y, y_score[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_lookup\n",
       "57296.0     0\n",
       "58652.0     0\n",
       "57294.0     0\n",
       "69065.0     1\n",
       "63909.0     1\n",
       "57292.0     0\n",
       "57290.0     0\n",
       "57288.0     0\n",
       "57285.0     0\n",
       "57284.0     0\n",
       "57282.0     0\n",
       "41726.0     1\n",
       "57279.0     0\n",
       "57278.0     0\n",
       "57277.0     0\n",
       "57276.0     1\n",
       "57275.0     0\n",
       "57274.0     0\n",
       "57273.0     0\n",
       "57271.0     0\n",
       "57270.0     0\n",
       "57268.0     0\n",
       "57266.0     0\n",
       "57265.0     0\n",
       "57264.0     0\n",
       "57259.0     0\n",
       "58523.0     0\n",
       "36739.0     1\n",
       "57255.0     0\n",
       "57254.0     0\n",
       "           ..\n",
       "701016.0    1\n",
       "701036.0    1\n",
       "701037.0    1\n",
       "701041.0    1\n",
       "701046.0    1\n",
       "701056.0    1\n",
       "701058.0    1\n",
       "701067.0    1\n",
       "701084.0    1\n",
       "701090.0    1\n",
       "701091.0    1\n",
       "701093.0    1\n",
       "701097.0    1\n",
       "701098.0    1\n",
       "701099.0    1\n",
       "701100.0    1\n",
       "701101.0    1\n",
       "701105.0    1\n",
       "701108.0    1\n",
       "701110.0    1\n",
       "701115.0    1\n",
       "701121.0    1\n",
       "701130.0    1\n",
       "701139.0    1\n",
       "701145.0    1\n",
       "701148.0    1\n",
       "701157.0    1\n",
       "701163.0    1\n",
       "701165.0    1\n",
       "701168.0    1\n",
       "Name: not_on_time, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
