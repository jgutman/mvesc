{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "pathname = os.path.dirname(\"/home/jgutman/mvesc/Models_Results/\")\n",
    "full_pathname = os.path.abspath(pathname)\n",
    "split_pathname = full_pathname.split(sep=\"mvesc\")\n",
    "base_pathname = os.path.join(split_pathname[0], \"mvesc\")\n",
    "parentdir = os.path.join(base_pathname, \"ETL\")\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mvesc_utility_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all model import statements\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, RobustScaler\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select * from model.outcome\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11777\n"
     ]
    }
   ],
   "source": [
    "with postgres_pgconnection_generator() as connection:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(query)\n",
    "            results = cursor.fetchall()\n",
    "            print(len(results))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df2num(rawdf):\n",
    "    \"\"\" Convert data frame with numeric variables and strings to numeric dataframe\n",
    "\n",
    "    :param pd.dataframe rawdf: raw data frame\n",
    "    :returns pd.dataframe df: a data frame with strings converted to dummies, other columns unchanged\n",
    "    :rtype: pd.dataframe\n",
    "    Rules:\n",
    "    - 1. numeric columns unchanged;\n",
    "    - 2. strings converted to dummeis;\n",
    "    - 3. the most frequent string is taken as reference\n",
    "    - 4. new column name is: \"ColumnName_Category\"\n",
    "    (e.g., column 'gender' with 80 'M' and 79 'F'; the dummy column left is 'gender_F')\n",
    "\n",
    "    \"\"\"\n",
    "    numeric_df = rawdf.select_dtypes(include=[np.number])\n",
    "    str_columns = [col for col in rawdf.columns if col not in numeric_df.columns]\n",
    "    dummy_col_df = pd.get_dummies(rawdf[str_columns], dummy_na=True)\n",
    "    numeric_df = numeric_df.join(dummy_col_df)\n",
    "    most_frequent_values = rawdf[str_columns].mode().loc[0].to_dict()\n",
    "    reference_cols = [\"{}_{}\".format(key, value) for key, value in most_frequent_values.items()]\n",
    "    numeric_df.drop(reference_cols, axis=1, inplace=True)\n",
    "    return numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_clfs_params():\n",
    "    # model_options[model_classes_selected] determines which of these models\n",
    "    # are actually run, all parameter options in grid run for each selected model\n",
    "\n",
    "    clfs = {\n",
    "        'logit': LogisticRegression(),\n",
    "        'LR_no_penalty': LogisticRegression(C=1e6),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=False),\n",
    "        'GB': GradientBoostingClassifier(\n",
    "            learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3)\n",
    "    }\n",
    "\n",
    "    grid = {\n",
    "        'logit': {'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1.0,10.0]},\n",
    "        'LR_no_penalty': {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'SGD': {'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'ET': {'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,\n",
    "            'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],\n",
    "            'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],\n",
    "            'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "        'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],\n",
    "            'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "    }\n",
    "    return clfs, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_loop(clfs, params, train_X, train_y,\n",
    "        criterion, models_to_run, cv_folds):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where the keys are model nicknames (strings)\n",
    "    and the values are GridSearchCV objects containing attributes like\n",
    "    model.best_score_ and model.best_estimator_\n",
    "\n",
    "    :param dict(str:estimator) clfs: clfs as returned by define_clfs_params\n",
    "    :param dict(str:dict) params: grid of classifier hyperparameter options\n",
    "        to grid search over as returned by define_clfs_params\n",
    "    :param pandas.DataFrame train_X: index is student_lookup, columns are all\n",
    "        features to train over in the model\n",
    "    :param pandas.Series(int) train_y: index is student_lookup, value is 0 or 1\n",
    "        for outcome label\n",
    "    :param string criterion: evaluation criterion for model selection on the\n",
    "        validation set, to be read in from model_options (e.g. 'f1')\n",
    "    :param list[string] models_to_run: which models to actually run as read in\n",
    "        from model_options (e.g. ['logit', 'DT'])\n",
    "    :param sklearn.KFolds cv_folds: a KFolds generator object over the index\n",
    "        given in train_X and train_y (a list of lists of student_lookups)\n",
    "    :rtype dict(string: GridSearchCV)\n",
    "    \"\"\"\n",
    "    best_validated_models = dict()\n",
    "    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "        model_name=models_to_run[index]\n",
    "        print(model_name)\n",
    "        parameter_values = params[model_name]\n",
    "        #param_grid = ParameterGrid(parameter_values)\n",
    "        best_validated_models[model_name] = GridSearchCV(clf, parameter_values, scoring=criterion, cv=cv_folds)\n",
    "        best_validated_models[model_name].fit(train_X, train_y)\n",
    "\n",
    "        model_cv_score = best_validated_models[model_name].best_score_\n",
    "        print(\"model: {model} cv_score: {score}\".format(\n",
    "            model=model_name, score=model_cv_score))\n",
    "    return best_validated_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temporal_cohort_test_split(joint_df, cohort_grade_level_begin,\n",
    "    cohorts_held_out, cohorts_training):\n",
    "    \"\"\" Splits the given joint_df of features & outcomes and\n",
    "    returns a train/test dataset\n",
    "    :param pd.DataFrame joint_df:\n",
    "    :param list[int] cohorts_held_out:\n",
    "    \"\"\"\n",
    "    if (cohorts_training=='all'):\n",
    "        train = joint_df[~joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    else:\n",
    "        train = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_training)]\n",
    "    test = joint_df[joint_df[cohort_grade_level_begin].isin(cohorts_held_out)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_performance(outcomes, predictions):\n",
    "    \"\"\" Returns a dict of model performance objects\n",
    "    :param list[int] outcomes:\n",
    "    :param list[float] predictions:\n",
    "    \"\"\"\n",
    "    performance_objects = {}\n",
    "    performance_objects['pr_curve'] = precision_recall_curve(outcomes, predictions)\n",
    "    performance_objects['roc_curve'] = roc_curve(outcomes, predictions)\n",
    "    #performance_objects['confusion_matrix'] = confusion_matrix(outcomes,predictions)\n",
    "    return performance_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_outcomes_plus_features(model_options):\n",
    "    with postgres_pgconnection_generator() as connection:\n",
    "        # get labeled outcomes\n",
    "        # Assumes:\n",
    "        # model.outcome table contains a column (name given in cohort_grade_level_begin) for each cohort base year we choose\n",
    "        # e.g. 'cohort_9th' contains the year each student is seen in 9th grade\n",
    "        # and contains an outcome column (name given in outcome_name)\n",
    "        # and 'student_lookup' columns\n",
    "        # Usage:\n",
    "        # select train, validation, and test based on values in column\n",
    "        # 'cohort_grade_level_begin' according to value in 'cohorts_held_out'\n",
    "        outcomes_with_student_lookup = read_table_to_df(connection,\n",
    "            table_name = 'outcome', schema = 'model', nrows = -1,\n",
    "            columns = ['student_lookup', model_options['outcome_name'], model_options['cohort_grade_level_begin']])\n",
    "        # drop students without student_lookup, outcome, or cohort identifier\n",
    "        # can use subset = [colnames] to drop based on NAs in certain columns only\n",
    "        outcomes_with_student_lookup.dropna(inplace=True)\n",
    "        joint_label_features = outcomes_with_student_lookup.copy()\n",
    "\n",
    "        # get all requested input features\n",
    "        # Assumes:\n",
    "        # every features table contains 'student_lookup'\n",
    "        # plus a column for the requested possible features\n",
    "\n",
    "        for table, column_names in model_options['features_included'].items():\n",
    "            features = read_table_to_df(connection, table_name = table,\n",
    "                schema = 'model', nrows = -1,\n",
    "                columns=(['student_lookup'] + column_names))\n",
    "        # join to only keep features that have labeled outcomes\n",
    "            joint_label_features = pd.merge(joint_label_features, features,\n",
    "                how = 'left', on = 'student_lookup')\n",
    "\n",
    "    # build dataframe containing student_lookup, outcome, cohort,\n",
    "    # and all features as numeric non-categorical values\n",
    "    joint_label_features.set_index('student_lookup', inplace=True)\n",
    "    joint_label_features = df2num(joint_label_features)\n",
    "    return joint_label_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in_yaml(filename=os.path.join(base_pathname,\n",
    "    'Models_Results', 'model_options.yaml')):\n",
    "    with open(filename, 'r') as f:\n",
    "        model_options = yaml.load(f)\n",
    "    assert(type(model_options)==dict)\n",
    "    assert(type(model_options['features_included']==dict))\n",
    "    assert(type(model_options['model_classes_selected']==list))\n",
    "    assert(type(model_options['cohorts_held_out']==list))\n",
    "    return model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation_criterion': 'accuracy', 'n_folds': 10, 'features_included': {'demographics': ['ethnicity', 'gender']}, 'user_description': 'initial_skeleton_pipeline_test', 'cohorts_training': 'all', 'cohort_grade_level_begin': 'cohort_9th', 'random_seed': 2187, 'missing_impute_strategy': 'default_mean_mode', 'feature_scaling': 'none', 'model_test_holdout': 'temporal_cohort', 'file_save_name': 'gender_ethnicity', 'model_classes_selected': ['logit', 'DT', 'SVM'], 'cohorts_held_out': [2012], 'parameter_cross_validation_scheme': 'leave_cohort_out', 'outcome_name': 'not_on_time'}\n"
     ]
    }
   ],
   "source": [
    "model_options = read_in_yaml()\n",
    "print(model_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set seed for this program from model_options\n",
    "np.random.seed(model_options['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on options, draw in data and select the appropriate\n",
    "# labeled outcome column (outcome_name)\n",
    "# cohort identification column (cohort_grade_level_begin)\n",
    "# subset of various feature columns from various tables (features_included)\n",
    "\n",
    "outcome_plus_features = build_outcomes_plus_features(model_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>cohort_9th</th>\n",
       "      <th>ethnicity_A</th>\n",
       "      <th>ethnicity_B</th>\n",
       "      <th>ethnicity_H</th>\n",
       "      <th>ethnicity_I</th>\n",
       "      <th>ethnicity_M</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_lookup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57296.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58652.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57294.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69065.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63909.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                not_on_time  cohort_9th  ethnicity_A  ethnicity_B  \\\n",
       "student_lookup                                                      \n",
       "57296.0                   0        2006          0.0          0.0   \n",
       "58652.0                   0        2006          0.0          0.0   \n",
       "57294.0                   0        2006          0.0          0.0   \n",
       "69065.0                   1        2006          0.0          0.0   \n",
       "63909.0                   1        2006          0.0          1.0   \n",
       "\n",
       "                ethnicity_H  ethnicity_I  ethnicity_M  ethnicity_nan  \\\n",
       "student_lookup                                                         \n",
       "57296.0                 0.0          0.0          0.0            0.0   \n",
       "58652.0                 0.0          0.0          0.0            0.0   \n",
       "57294.0                 0.0          0.0          0.0            0.0   \n",
       "69065.0                 0.0          0.0          0.0            0.0   \n",
       "63909.0                 0.0          0.0          0.0            0.0   \n",
       "\n",
       "                gender_F  gender_nan  \n",
       "student_lookup                        \n",
       "57296.0              0.0         0.0  \n",
       "58652.0              0.0         0.0  \n",
       "57294.0              0.0         0.0  \n",
       "69065.0              0.0         0.0  \n",
       "63909.0              0.0         0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_plus_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_options['model_test_holdout'] == 'temporal_cohort':\n",
    "    # if using temporal cohort model performance validation,\n",
    "    # we choose the cohorts in cohorts_held_out for the test set\n",
    "    train, test = temporal_cohort_test_split(outcome_plus_features,\n",
    "        model_options['cohort_grade_level_begin'],\n",
    "        model_options['cohorts_held_out'],\n",
    "        model_options['cohorts_training'])\n",
    "\n",
    "else:\n",
    "    # if not using temporal test set, split randomly\n",
    "    train, test = train_test_split(outcome_plus_features, test_size=0.20,\n",
    "        random_state=model_options['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006 2007 2008 2009 2010 2011]\n",
      "[2012]\n"
     ]
    }
   ],
   "source": [
    "print(pd.unique(train.cohort_9th))\n",
    "print(pd.unique(test.cohort_9th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get subtables for each for easy reference\n",
    "train_X = train.drop([model_options['outcome_name'],\n",
    "    model_options['cohort_grade_level_begin']],axis=1)\n",
    "test_X = test.drop([model_options['outcome_name'],\n",
    "    model_options['cohort_grade_level_begin']],axis=1)\n",
    "train_y = train[model_options['outcome_name']]\n",
    "test_y = test[model_options['outcome_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs, params = define_clfs_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leave_cohort_out\n"
     ]
    }
   ],
   "source": [
    "if model_options['parameter_cross_validation_scheme'] == 'none':\n",
    "    # no need to further manipulate train dataset\n",
    "    cohort_kfolds = 2 # hacky way to have GridSearchCV fit to 2 k-folds\n",
    "elif model_options['parameter_cross_validation_scheme'] == 'leave_cohort_out':\n",
    "    # choose another validation set amongst the training set to\n",
    "    # estimate parameters and model selection across cohort folds\n",
    "    print('leave_cohort_out')\n",
    "    cohort_kfolds = LeaveOneLabelOut(train[model_options['cohort_grade_level_begin']])\n",
    "elif model_options['parameter_cross_validation_scheme'] == 'k_fold':\n",
    "    # ignore cohorts and use random folds to estimate parameter\n",
    "    print('k_fold_parameter_estimation')\n",
    "    cohort_kfolds = LabelKFold(train.index, n_folds=model_options['n_folds'])\n",
    "else:\n",
    "    print('unknown cross-validation strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006 2006 2006 ..., 2011 2011 2011]\n",
      "train:  [2007 2008 2009 2010 2011]\n",
      "validation:  [2006]\n",
      "train:  [2006 2008 2009 2010 2011]\n",
      "validation:  [2007]\n",
      "train:  [2006 2007 2009 2010 2011]\n",
      "validation:  [2008]\n",
      "train:  [2006 2007 2008 2010 2011]\n",
      "validation:  [2009]\n",
      "train:  [2006 2007 2008 2009 2011]\n",
      "validation:  [2010]\n",
      "train:  [2006 2007 2008 2009 2010]\n",
      "validation:  [2011]\n"
     ]
    }
   ],
   "source": [
    "print(cohort_kfolds.labels)\n",
    "for train_fold, val_fold in cohort_kfolds:\n",
    "    print('train: ', np.unique(train.iloc[train_fold].cohort_9th))\n",
    "    print('validation: ', np.unique(train.iloc[val_fold].cohort_9th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_options['model_classes_selected'] = ['LR_no_penalty'] #'log_loss' #'accuracy' #  # 'f1'\n",
    "model_options['validation_criterion'] = 'average_precision' #'log_loss' #'accuracy' #  # 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB': AdaBoostClassifier(algorithm='SAMME',\n",
       "           base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "             max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'),\n",
       "           learning_rate=1.0, n_estimators=200, random_state=None),\n",
       " 'DT': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=None, splitter='best'),\n",
       " 'ET': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " 'GB': GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
       "               max_depth=6, max_features=None, max_leaf_nodes=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "               presort='auto', random_state=None, subsample=0.5, verbose=0,\n",
       "               warm_start=False),\n",
       " 'KNN': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "            weights='uniform'),\n",
       " 'LR_no_penalty': LogisticRegression(C=1000000.0, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " 'NB': GaussianNB(),\n",
       " 'RF': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'SGD': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False),\n",
       " 'SVM': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'logit': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_no_penalty\n",
      "model: LR_no_penalty cv_score: 0.34711971229428645\n"
     ]
    }
   ],
   "source": [
    "best_validated_models = clf_loop(clfs, params, train_X, train_y,\n",
    "    criterion=model_options['validation_criterion'],\n",
    "    models_to_run=model_options['model_classes_selected'],\n",
    "    cv_folds=cohort_kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, model in best_validated_models.items():\n",
    "    clf = model.best_estimator_\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        test_set_scores = clf.decision_function(test_X)\n",
    "    else:\n",
    "        test_set_scores = clf.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.34712, std: 0.02759, params: {}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validated_models['LR_no_penalty'].grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69831928,  1.14873057,  1.11487351,  1.52102882,  0.75204177,\n",
       "         2.6156949 , -0.14418855,  0.        ]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validated_models['LR_no_penalty'].best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['not_on_time', 'cohort_9th', 'ethnicity_A', 'ethnicity_B',\n",
       "       'ethnicity_H', 'ethnicity_I', 'ethnicity_M', 'ethnicity_nan',\n",
       "       'gender_F', 'gender_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_plus_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_train = best_validated_models['DT'].predict_proba(train_X)\n",
    "predicted_test = best_validated_models['DT'].predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([probs == [0.5, 0.5] for probs in predicted_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([probs == [0.5, 0.5] for probs in predicted_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76382782,  0.23617218],\n",
       "       [ 0.76382782,  0.23617218],\n",
       "       [ 0.76382782,  0.23617218],\n",
       "       ..., \n",
       "       [ 0.76382782,  0.23617218],\n",
       "       [ 0.76382782,  0.23617218],\n",
       "       [ 0.76382782,  0.23617218]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gender_F</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_on_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4502</td>\n",
       "      <td>4366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1566</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender_F      0.0   1.0\n",
       "not_on_time            \n",
       "0            4502  4366\n",
       "1            1566  1343"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(outcome_plus_features.not_on_time, outcome_plus_features.gender_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ethnicity_B</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_on_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8799</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2847</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ethnicity_B   0.0  1.0\n",
       "not_on_time           \n",
       "0            8799   69\n",
       "1            2847   62"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(outcome_plus_features.not_on_time, outcome_plus_features.ethnicity_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_on_time          2909.0\n",
       "cohort_9th       23666760.0\n",
       "ethnicity_A            50.0\n",
       "ethnicity_B           131.0\n",
       "ethnicity_H           712.0\n",
       "ethnicity_I            11.0\n",
       "ethnicity_M           267.0\n",
       "ethnicity_nan           7.0\n",
       "gender_F             5709.0\n",
       "gender_nan              0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_plus_features.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(outcome_plus_features.ethnicity_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_on_time      0\n",
       "cohort_9th       0\n",
       "ethnicity_A      0\n",
       "ethnicity_B      0\n",
       "ethnicity_H      0\n",
       "ethnicity_I      0\n",
       "ethnicity_M      0\n",
       "ethnicity_nan    0\n",
       "gender_F         0\n",
       "gender_nan       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(outcome_plus_features).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_null = outcome_plus_features.replace({'cohort_9th': {2006: np.nan}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = temporal_cohort_test_split(test_null,\n",
    "    model_options['cohort_grade_level_begin'],\n",
    "    model_options['cohorts_held_out'],\n",
    "    model_options['cohorts_training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_null.dropna(subset=['not_on_time', 'cohort_9th'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_on_time</th>\n",
       "      <th>cohort_9th</th>\n",
       "      <th>ethnicity_A</th>\n",
       "      <th>ethnicity_B</th>\n",
       "      <th>ethnicity_H</th>\n",
       "      <th>ethnicity_I</th>\n",
       "      <th>ethnicity_M</th>\n",
       "      <th>ethnicity_nan</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_lookup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37133.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37132.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37131.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37130.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37129.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37128.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37127.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37126.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37125.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37122.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37121.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37120.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37119.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37118.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37117.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37116.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37115.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37114.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37113.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37112.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37111.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37110.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37109.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37108.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37107.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37106.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37105.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37104.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37103.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37102.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70804.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19548.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699419.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19149.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19123.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19061.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19055.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700797.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19044.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19040.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19039.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19038.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19037.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19036.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19035.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700539.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19033.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700311.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19032.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19028.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19027.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19026.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19025.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18545.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17827.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                not_on_time  cohort_9th  ethnicity_A  ethnicity_B  \\\n",
       "student_lookup                                                      \n",
       "37133.0                   0      2007.0          0.0          0.0   \n",
       "37132.0                   0      2007.0          0.0          0.0   \n",
       "37131.0                   0      2007.0          0.0          0.0   \n",
       "37130.0                   0      2007.0          0.0          0.0   \n",
       "37129.0                   0      2007.0          0.0          0.0   \n",
       "37128.0                   0      2007.0          0.0          0.0   \n",
       "37127.0                   0      2007.0          0.0          0.0   \n",
       "37126.0                   0      2007.0          0.0          0.0   \n",
       "37125.0                   0      2007.0          0.0          0.0   \n",
       "37122.0                   0      2007.0          0.0          0.0   \n",
       "37121.0                   0      2007.0          0.0          0.0   \n",
       "37120.0                   0      2007.0          0.0          0.0   \n",
       "37119.0                   0      2007.0          0.0          0.0   \n",
       "37118.0                   0      2007.0          0.0          0.0   \n",
       "37117.0                   0      2007.0          0.0          0.0   \n",
       "37116.0                   0      2007.0          0.0          0.0   \n",
       "37115.0                   0      2007.0          0.0          0.0   \n",
       "37114.0                   0      2007.0          0.0          0.0   \n",
       "37113.0                   0      2007.0          0.0          0.0   \n",
       "37112.0                   0      2007.0          0.0          0.0   \n",
       "37111.0                   0      2007.0          0.0          0.0   \n",
       "37110.0                   0      2007.0          0.0          0.0   \n",
       "37109.0                   0      2007.0          0.0          0.0   \n",
       "37108.0                   0      2007.0          0.0          0.0   \n",
       "37107.0                   0      2007.0          0.0          0.0   \n",
       "37106.0                   0      2007.0          0.0          0.0   \n",
       "37105.0                   0      2007.0          0.0          0.0   \n",
       "37104.0                   0      2007.0          0.0          0.0   \n",
       "37103.0                   0      2007.0          0.0          0.0   \n",
       "37102.0                   0      2007.0          0.0          0.0   \n",
       "...                     ...         ...          ...          ...   \n",
       "70804.0                   1      2012.0          0.0          0.0   \n",
       "19548.0                   0      2012.0          0.0          0.0   \n",
       "699419.0                  1      2012.0          0.0          0.0   \n",
       "19308.0                   1      2012.0          0.0          0.0   \n",
       "19154.0                   0      2012.0          0.0          0.0   \n",
       "19150.0                   1      2012.0          0.0          0.0   \n",
       "19149.0                   1      2012.0          0.0          0.0   \n",
       "19123.0                   1      2012.0          0.0          0.0   \n",
       "19061.0                   0      2012.0          0.0          0.0   \n",
       "19055.0                   0      2012.0          0.0          0.0   \n",
       "700797.0                  1      2012.0          0.0          0.0   \n",
       "19044.0                   0      2012.0          0.0          0.0   \n",
       "19040.0                   0      2012.0          0.0          0.0   \n",
       "19039.0                   0      2012.0          0.0          0.0   \n",
       "19038.0                   0      2012.0          0.0          0.0   \n",
       "19037.0                   1      2012.0          0.0          0.0   \n",
       "19036.0                   0      2012.0          0.0          0.0   \n",
       "19035.0                   0      2012.0          0.0          0.0   \n",
       "19034.0                   0      2012.0          0.0          0.0   \n",
       "700539.0                  1      2012.0          0.0          0.0   \n",
       "19033.0                   0      2012.0          0.0          0.0   \n",
       "700311.0                  1      2012.0          0.0          0.0   \n",
       "19032.0                   0      2012.0          0.0          0.0   \n",
       "19028.0                   0      2012.0          0.0          0.0   \n",
       "19027.0                   0      2012.0          0.0          0.0   \n",
       "19026.0                   0      2012.0          0.0          0.0   \n",
       "19025.0                   0      2012.0          0.0          0.0   \n",
       "18590.0                   0      2012.0          0.0          0.0   \n",
       "18545.0                   0      2012.0          0.0          0.0   \n",
       "17827.0                   0      2012.0          0.0          0.0   \n",
       "\n",
       "                ethnicity_H  ethnicity_I  ethnicity_M  ethnicity_nan  \\\n",
       "student_lookup                                                         \n",
       "37133.0                 0.0          0.0          0.0            0.0   \n",
       "37132.0                 0.0          0.0          0.0            0.0   \n",
       "37131.0                 0.0          0.0          0.0            0.0   \n",
       "37130.0                 0.0          0.0          0.0            0.0   \n",
       "37129.0                 0.0          0.0          0.0            0.0   \n",
       "37128.0                 0.0          0.0          0.0            0.0   \n",
       "37127.0                 0.0          0.0          0.0            0.0   \n",
       "37126.0                 0.0          0.0          0.0            0.0   \n",
       "37125.0                 0.0          0.0          0.0            0.0   \n",
       "37122.0                 0.0          0.0          0.0            0.0   \n",
       "37121.0                 0.0          0.0          0.0            0.0   \n",
       "37120.0                 0.0          0.0          0.0            0.0   \n",
       "37119.0                 0.0          0.0          0.0            0.0   \n",
       "37118.0                 0.0          0.0          0.0            0.0   \n",
       "37117.0                 0.0          0.0          0.0            0.0   \n",
       "37116.0                 0.0          0.0          0.0            0.0   \n",
       "37115.0                 0.0          0.0          0.0            0.0   \n",
       "37114.0                 0.0          0.0          0.0            0.0   \n",
       "37113.0                 0.0          0.0          0.0            0.0   \n",
       "37112.0                 0.0          0.0          0.0            0.0   \n",
       "37111.0                 0.0          0.0          0.0            0.0   \n",
       "37110.0                 0.0          0.0          0.0            0.0   \n",
       "37109.0                 0.0          0.0          0.0            0.0   \n",
       "37108.0                 0.0          0.0          0.0            0.0   \n",
       "37107.0                 0.0          0.0          0.0            0.0   \n",
       "37106.0                 0.0          0.0          0.0            0.0   \n",
       "37105.0                 0.0          0.0          0.0            0.0   \n",
       "37104.0                 0.0          0.0          0.0            0.0   \n",
       "37103.0                 0.0          0.0          0.0            0.0   \n",
       "37102.0                 0.0          0.0          0.0            0.0   \n",
       "...                     ...          ...          ...            ...   \n",
       "70804.0                 1.0          0.0          0.0            0.0   \n",
       "19548.0                 0.0          0.0          0.0            0.0   \n",
       "699419.0                0.0          0.0          0.0            0.0   \n",
       "19308.0                 0.0          0.0          0.0            0.0   \n",
       "19154.0                 0.0          0.0          0.0            0.0   \n",
       "19150.0                 0.0          0.0          0.0            0.0   \n",
       "19149.0                 0.0          0.0          0.0            0.0   \n",
       "19123.0                 0.0          0.0          0.0            0.0   \n",
       "19061.0                 0.0          0.0          0.0            0.0   \n",
       "19055.0                 0.0          0.0          1.0            0.0   \n",
       "700797.0                0.0          0.0          0.0            0.0   \n",
       "19044.0                 0.0          0.0          0.0            0.0   \n",
       "19040.0                 0.0          0.0          0.0            0.0   \n",
       "19039.0                 0.0          0.0          0.0            0.0   \n",
       "19038.0                 0.0          0.0          0.0            0.0   \n",
       "19037.0                 0.0          0.0          0.0            0.0   \n",
       "19036.0                 0.0          0.0          0.0            0.0   \n",
       "19035.0                 0.0          0.0          0.0            0.0   \n",
       "19034.0                 0.0          0.0          0.0            0.0   \n",
       "700539.0                0.0          0.0          0.0            0.0   \n",
       "19033.0                 0.0          0.0          0.0            0.0   \n",
       "700311.0                0.0          0.0          0.0            0.0   \n",
       "19032.0                 0.0          0.0          0.0            0.0   \n",
       "19028.0                 0.0          0.0          0.0            0.0   \n",
       "19027.0                 0.0          0.0          0.0            0.0   \n",
       "19026.0                 0.0          0.0          0.0            0.0   \n",
       "19025.0                 0.0          0.0          0.0            0.0   \n",
       "18590.0                 0.0          0.0          0.0            0.0   \n",
       "18545.0                 0.0          0.0          0.0            0.0   \n",
       "17827.0                 0.0          0.0          0.0            0.0   \n",
       "\n",
       "                gender_F  gender_nan  \n",
       "student_lookup                        \n",
       "37133.0              1.0         0.0  \n",
       "37132.0              0.0         0.0  \n",
       "37131.0              1.0         0.0  \n",
       "37130.0              0.0         0.0  \n",
       "37129.0              0.0         0.0  \n",
       "37128.0              0.0         0.0  \n",
       "37127.0              0.0         0.0  \n",
       "37126.0              1.0         0.0  \n",
       "37125.0              0.0         0.0  \n",
       "37122.0              1.0         0.0  \n",
       "37121.0              0.0         0.0  \n",
       "37120.0              0.0         0.0  \n",
       "37119.0              0.0         0.0  \n",
       "37118.0              1.0         0.0  \n",
       "37117.0              1.0         0.0  \n",
       "37116.0              0.0         0.0  \n",
       "37115.0              0.0         0.0  \n",
       "37114.0              1.0         0.0  \n",
       "37113.0              0.0         0.0  \n",
       "37112.0              0.0         0.0  \n",
       "37111.0              1.0         0.0  \n",
       "37110.0              0.0         0.0  \n",
       "37109.0              1.0         0.0  \n",
       "37108.0              0.0         0.0  \n",
       "37107.0              0.0         0.0  \n",
       "37106.0              0.0         0.0  \n",
       "37105.0              0.0         0.0  \n",
       "37104.0              0.0         0.0  \n",
       "37103.0              1.0         0.0  \n",
       "37102.0              1.0         0.0  \n",
       "...                  ...         ...  \n",
       "70804.0              0.0         0.0  \n",
       "19548.0              1.0         0.0  \n",
       "699419.0             1.0         0.0  \n",
       "19308.0              0.0         0.0  \n",
       "19154.0              0.0         0.0  \n",
       "19150.0              0.0         0.0  \n",
       "19149.0              1.0         0.0  \n",
       "19123.0              0.0         0.0  \n",
       "19061.0              0.0         0.0  \n",
       "19055.0              0.0         0.0  \n",
       "700797.0             1.0         0.0  \n",
       "19044.0              0.0         0.0  \n",
       "19040.0              1.0         0.0  \n",
       "19039.0              0.0         0.0  \n",
       "19038.0              0.0         0.0  \n",
       "19037.0              0.0         0.0  \n",
       "19036.0              0.0         0.0  \n",
       "19035.0              0.0         0.0  \n",
       "19034.0              1.0         0.0  \n",
       "700539.0             0.0         0.0  \n",
       "19033.0              0.0         0.0  \n",
       "700311.0             1.0         0.0  \n",
       "19032.0              1.0         0.0  \n",
       "19028.0              0.0         0.0  \n",
       "19027.0              0.0         0.0  \n",
       "19026.0              1.0         0.0  \n",
       "19025.0              1.0         0.0  \n",
       "18590.0              0.0         0.0  \n",
       "18545.0              0.0         0.0  \n",
       "17827.0              0.0         0.0  \n",
       "\n",
       "[10535 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cohorts_training = [2006, 2007, 2008]\n",
    "cohorts_heldout = [2011, 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(max(cohorts_training) < min(cohorts_heldout)), \"Training years do not completely precede test years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train.cohort_9th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cohort_grade_level_begin = 'cohort_9th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['validation_criterion', 'n_folds', 'features_included', 'user_description', 'cohorts_training', 'cohort_grade_level_begin', 'random_seed', 'missing_impute_strategy', 'feature_scaling', 'model_test_holdout', 'file_save_name', 'model_classes_selected', 'cohorts_held_out', 'parameter_cross_validation_scheme', 'outcome_name'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_options.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "required_keys = set(('validation_criterion', 'features_included', 'cohorts_training', 'cohorts_held_out', \n",
    "                   'file_save_name', 'model_classes_selected', 'outcome_name', 'cohort_grade_level_begin',\n",
    "                    'model_test_holdout', 'random_seed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(all([key in model_options.keys() for key in required_keys])), \\\n",
    "    \"error message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
