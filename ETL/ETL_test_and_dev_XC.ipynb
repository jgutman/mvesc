{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development of OAAOGT cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mvesc_utility_functions import postgres_pgconnection_generator\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Script to upload IRN_DORP_GRAD_RATE1415.xls\n",
    "import pandas as pd\n",
    "irn_file = \"/mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.xls\"\n",
    "irn_df = pd.read_excel(irn_file, sheetname=0)\n",
    "raw_irn_newoldcol_dict = {old:'_'.join(old.lower().split(' '))\\\n",
    " .replace('graduation', 'grad').replace('-_class_of_', 'class').replace('class_of_', 'class')\\\n",
    " .replace('percent', 'pct').replace('of_', '')\\\n",
    " .replace('(','').replace(')','')\\\n",
    " for old in irn_df.columns}\n",
    "raw_irn_newoldcol_dict['Percent of 4 Year Graduation Cohort (Class of 2014) Earning 3 or More Dual Enrollment Credits']\\\n",
    "= 'pct_4year_grad_class2014_earning_3_or_more_credits'\n",
    "raw_irn_newoldcol_dict['Percent of 4 Year Graduation Cohort (Class of 2014) Earning Industry Recognized Credentials']\\\n",
    "= 'pct_4_year_grad_class2014_earning_industry_recog_credentials'\n",
    "raw_irn_newoldcol_dict['Phone #'] = 'phone'\n",
    "\n",
    "new_irn_df = irn_df.rename(columns=raw_irn_newoldcol_dict)\n",
    "new_irn_df.to_csv(irn_file.split('.')[0]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'(abc)'.replace('(', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- processing:  /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.xls\n",
      "Excel file column names corrected and saved as  /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv\n",
      "Preparing file /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv to upload to postgresql\n",
      "File \"IRN_DORP_GRAD_RATE1415.csv\" already in json with table name \"IRN_DORP_GRAD_RATE1415\" \n",
      "uploading data file \"IRN_DORP_GRAD_RATE1415.csv\" \n",
      "Table already in mvesc: IRN_DORP_GRAD_RATE1415\n",
      "Table uploaded: IRN_DORP_GRAD_RATE1415\n",
      "\n",
      "Preparing file /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv to upload to postgresql\n",
      "File \"IRN_DORP_GRAD_RATE1415.csv\" already in json with table name \"IRN_DORP_GRAD_RATE1415\" \n",
      "uploading data file \"IRN_DORP_GRAD_RATE1415.csv\" \n",
      "Table already in mvesc: IRN_DORP_GRAD_RATE1415\n",
      "Table uploaded: IRN_DORP_GRAD_RATE1415\n",
      "\n",
      "\n",
      "--- processing:  /mnt/data/mvesc/PartnerData/MVESC_DistrictRatings.xlsx\n",
      "sheet-table uploaded to mvesc:  DistrictRating1415\n",
      "sheet-table uploaded to mvesc:  DistrictRating1314\n",
      "sheet-table uploaded to mvesc:  DistrictRating1213\n",
      "sheet-table uploaded to mvesc:  DistrictRating1112\n",
      "sheet-table uploaded to mvesc:  DistrictRating1011\n",
      "\n",
      "--- processing:  /mnt/data/mvesc/PartnerData/MVESC_Mobility.xlsx\n",
      "table uploaded to mvesc:  Mobility_2010_2015\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Script to process and upload excel files to postgres\n",
    "- will be updated regularly\n",
    "- each section marked by '#++++++' is for one excel file\n",
    "- procedure is commented briefly in script and more in ETL_README (coming after Jul 8)\n",
    "\"\"\" \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from csv2postgres_mvesc import postgresql_engine_generator_mvesc\n",
    "\n",
    "#++++++ Functions only for the Excel files ++++++#\n",
    "def combine_colnames(col1, col2):\n",
    "    \"\"\"combine the colnames from 2 rows: !! Only works in this specific case\n",
    "    :param str col1: first column-name\n",
    "    :param str col2: second column-name\n",
    "    :return str new_col: combined new column name\n",
    "    :return str\n",
    "    \"\"\"\n",
    "    new_col = \"pct_same_\"\n",
    "    schoolyear = col2[2:4] + col2[7:9]\n",
    "    if \"district\" in col1.lower():\n",
    "        dist_school = \"district_\"\n",
    "    else:\n",
    "        dist_school = \"school_\"\n",
    "    \n",
    "    if \"less\" in col1.lower():\n",
    "        more_less = \"less_\"\n",
    "    else:\n",
    "        more_less = \"more_\"\n",
    "    new_col = new_col+dist_school+more_less+'a_year_'+schoolyear  \n",
    "    return new_col\n",
    "\n",
    "\n",
    "\n",
    "def df2postgres(df, table_name, nrows=-1, if_exists='fail', schema='raw'):\n",
    "    \"\"\" dump dataframe object to postgres database\n",
    "    \n",
    "    :param pandas.DataFrame df: dataframe\n",
    "    :param int nrows: number of rows to write to table;\n",
    "    :return str table_name: table name of the sql table\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    # create a postgresql engine to wirte to postgres\n",
    "    engine = postgresql_engine_generator_mvesc()\n",
    "    \n",
    "    #write the data frame to postgres\n",
    "    if nrows==-1:\n",
    "        df.to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "    else:\n",
    "        df.iloc[:nrows, :].to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "    return table_name\n",
    "\n",
    "\n",
    "#++++++ ~/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.xls ++++++#\n",
    "# -1. produce a `.csv` file with correct column names\n",
    "# -2. call terminal command to use `csv2postgres_mvesc.py` in python\n",
    "irn_file = \"/mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.xls\"\n",
    "print('\\n--- processing: ', irn_file)\n",
    "irn_df = pd.read_excel(irn_file, sheetname=0)\n",
    "raw_irn_newoldcol_dict = {old:'_'.join(old.lower().split(' '))\\\n",
    " .replace('graduation', 'grad').replace('-_class_of_', 'class').replace('class_of_', 'class')\\\n",
    " .replace('percent', 'pct').replace('of_', '')\\\n",
    " .replace('(','').replace(')','')\\\n",
    " for old in irn_df.columns}\n",
    "raw_irn_newoldcol_dict['Percent of 4 Year Graduation Cohort (Class of 2014) Earning 3 or More Dual Enrollment Credits']\\\n",
    "= 'pct_4year_grad_class2014_earning_3_or_more_credits'\n",
    "raw_irn_newoldcol_dict['Percent of 4 Year Graduation Cohort (Class of 2014) Earning Industry Recognized Credentials']\\\n",
    "= 'pct_4_year_grad_class2014_earning_industry_recog_credentials'\n",
    "raw_irn_newoldcol_dict['Phone #'] = 'phone'\n",
    "\n",
    "new_irn_df = irn_df.rename(columns=raw_irn_newoldcol_dict)\n",
    "new_irn_csv_name = irn_file.split('.')[0]+'.csv'\n",
    "new_irn_df.to_csv(new_irn_csv_name)\n",
    "print('Excel file column names corrected and saved as ', new_irn_csv_name)\n",
    "print(os.popen(\"/home/jgutman/env/bin/python csv2postgres_mvesc.py -f\\\n",
    "/mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv -s public\").read())\n",
    "print(os.popen(\"/home/jgutman/env/bin/python csv2postgres_mvesc.py -f\\\n",
    "/mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv -s raw\").read())\n",
    "\n",
    "\n",
    "#++++++ ~/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.xls ++++++#\n",
    "# -1. read Excel parser \n",
    "# -2. upload sheets one by one\n",
    "filepath = '/mnt/data/mvesc/PartnerData/MVESC_DistrictRatings.xlsx'\n",
    "excel_name = \"DistrictRating\"\n",
    "schema='raw'\n",
    "print('\\n--- processing: ', filepath)\n",
    "xl = pd.ExcelFile(filepath)\n",
    "for sheet_name in xl.sheet_names:\n",
    "    tab_name = excel_name + sheet_name[-4:]\n",
    "    df = xl.parse(sheet_name)\n",
    "    names = list(df.columns)\n",
    "    newnames = ['_'.join(re.split('[, _\\-#\\(\\)]+', name)).replace(\"%\", 'pct').lower() for name in names ]\n",
    "    def check_name_long(names, length=63):\n",
    "        long_names = filter(lambda x: len(x)>length, names)\n",
    "        return list(long_names)\n",
    "    #print(\"Long column names:\\n\", check_name_long(newnames))\n",
    "    newnames = [name[:63] for name in newnames]\n",
    "    newnames_dict={names[i]:newnames[i] for i in range(len(names))}\n",
    "    df = df.rename(columns=newnames_dict)\n",
    "    table_name = df2postgres(df, tab_name, nrows=-1, if_exists='replace', schema=schema)\n",
    "    print(\"sheet-table uploaded to mvesc: \", table_name)\n",
    "\n",
    "\n",
    "#++++++ ~/PartnerData/MVESC_Mobility.xlsx ++++++#\n",
    "# -1. read Excel parser \n",
    "# -2. upload sheets one by one\n",
    "filepath='/mnt/data/mvesc/PartnerData/MVESC_Mobility.xlsx'\n",
    "schema = 'raw'\n",
    "print('\\n--- processing: ', filepath)\n",
    "df_Mobility = pd.read_excel(filepath, skiprows=1)\n",
    "df_Mobility2 = pd.read_excel(filepath)\n",
    "first3cols = ['district_code', 'district', 'metrics']\n",
    "col1=df_Mobility.columns[3:] # only columns which need to be combined\n",
    "col2=df_Mobility2.columns[3:]\n",
    "\n",
    "new_colnames = first3cols + [combine_colnames(col1[i], col2[i]) for i in range(len(col1)) ]\n",
    "new_colnames_dict = {df_Mobility.columns[i]:new_colnames[i] for i in range(len(new_colnames))}\n",
    "df_Mobility=df_Mobility.rename(columns=new_colnames_dict)\n",
    "df_Mobility=df_Mobility.drop('metrics', axis=1)\n",
    "table_name = df2postgres(df_Mobility, \"Mobility_2010_2015\", nrows=-1, if_exists='replace', schema=schema)\n",
    "print(\"table uploaded to mvesc: \", table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing file /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv to upload to postgresql\n",
      "File \"IRN_DORP_GRAD_RATE1415.csv\" already in json with table name \"IRN_DORP_GRAD_RATE1415\" \n",
      "uploading data file \"IRN_DORP_GRAD_RATE1415.csv\" \n",
      "Table already in mvesc: IRN_DORP_GRAD_RATE1415\n",
      "Table uploaded: IRN_DORP_GRAD_RATE1415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(os.popen(\"/home/jgutman/env/bin/python csv2postgres_mvesc.py -f /mnt/data/mvesc/PartnerData/IRNSandWithdrawalCodes/IRN_DORP_GRAD_RATE1415.csv -s public\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetch_or_add_file2table_jsonfile(datafile, jsonfile='file_to_table_name_test.json'):\n",
    "    \"\"\" Fetch table name from json file OR Add file:table to json\n",
    "    \n",
    "    step 1: check whether file and table exist in json file;\n",
    "    step 2: if exist, return table_name; \n",
    "    if not exist, add file:table to json, then return table_name\n",
    "    \n",
    "    :param str datafile: datafile name, either absolute or relative path\n",
    "    :param str jsonfile: json file name, default: 'file_to_table_name.json'\n",
    "    :return str table_name\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    # load json, keys, values\n",
    "    with open(jsonfile, 'r') as f:\n",
    "        file_table_names = json.load(f)\n",
    "    existing_keys = list(file_table_names.keys())\n",
    "    existing_values = list(file_table_names.values())\n",
    "    \n",
    "    # check datafile in json\n",
    "    if '/' in datafile:\n",
    "        datafile = datafile.split('/')[-1]\n",
    "    if datafile in existing_keys:\n",
    "        print(\"\"\"File \"{}\" already in json with table name \"{}\" \"\"\".format(datafile, file_table_names[datafile]))\n",
    "        return(file_table_names[datafile])\n",
    "    else:\n",
    "        table_name = datafile.split('.')[0]\n",
    "        if table_name in existing_values:\n",
    "            print(\"\"\"Table \"{}\" already in json for a file \"\"\".format(table_name))\n",
    "            return(None)\n",
    "        else:\n",
    "            file_table_names[datafile] = table_name\n",
    "            with open(jsonfile, 'w') as f:\n",
    "                json.dump(file_table_names, f, ensure_ascii=True, sort_keys=True, indent=4)\n",
    "            print(\"\"\"file:table \"{}\":\"{}\" added to json file \"\"\".format(datafile, file_table_names[datafile]))\n",
    "            return table_name\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note before use:\n",
    "The code is using 2 python-SQL connection interfaces: psycopg2 and sqlalchemy\n",
    "    * In the functions, no worries because the function will look for credential and connections itself\n",
    "    * In the scripts, run the script of \"connection to database\" first to set up the connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database\n",
    "Just a test the connection; not necessary to run the csv-to-sql dump "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    table_name\n",
      "0            DistrictSchoolIDs\n",
      "1                   all_lookup\n",
      "2       CoshoctonGrades2006_16\n",
      "3           Mobility_2010_2015\n",
      "4     Ridgewoodgrades2007_2016\n",
      "5   WestMuskingumgrades2006_16\n",
      "6                  OAAOGT_0616\n",
      "7        Franklingrades2006_16\n",
      "8           MATVWMAbsences1415\n",
      "9         CCFRRWRVabsence09_16\n",
      "10          MATVWMAbsences1516\n",
      "11      TriValleyGrades2006_16\n",
      "12               Districts0607\n",
      "13               Districts0708\n",
      "14               Districts0809\n",
      "15               Districts0910\n",
      "16          DistrictRating1314\n",
      "17          DistrictRating1011\n",
      "18               Districts1011\n",
      "19               Districts1112\n",
      "20               Districts1213\n",
      "21             CurrentMobility\n",
      "22             CurrentStudents\n",
      "23               ASQ_Preschool\n",
      "24                   ActScores\n",
      "25            AllDistricts1112\n",
      "26                    HSGrades\n",
      "27            AllDistricts1213\n",
      "28               Districts1314\n",
      "29                   AIRScores\n",
      "30            AllDistricts1314\n",
      "31    CurrentAbsenceDiscipline\n",
      "32                    DIBELSv2\n",
      "33            AllDistricts1415\n",
      "34               AllGradsTotal\n",
      "35                      OAAOGT\n",
      "36                       PARCC\n",
      "37                    StarRead\n",
      "38                      StarEL\n",
      "39                    StarMath\n",
      "40                   TerraNova\n",
      "41               Districts1415\n",
      "42               Districts1516\n",
      "43      Maysvillegrades2006_16\n",
      "44      RiverViewgrades2006_16\n",
      "45          DistrictRating1213\n",
      "46          DistrictRating1415\n",
      "47          DistrictRating1112\n"
     ]
    }
   ],
   "source": [
    "# Connect to database; doesn't required for the next session of dumping csv to sql\n",
    "pass_file = \"/mnt/data/mvesc/pgpass\" # username, db information\n",
    "with open(pass_file, 'r') as f:\n",
    "    passinfo = f.read()\n",
    "passinfo = passinfo.strip().split(':')\n",
    "\n",
    "host_address = passinfo[0]\n",
    "port = passinfo[1]\n",
    "user_name = passinfo[2]\n",
    "name_of_database = passinfo[3]\n",
    "user_password = passinfo[4]\n",
    "sqlcmd_table_names = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
    "connection = pg.connect(host=host_address, database=name_of_database, user=user_name, password=user_password)\n",
    "all_table_names = pd.read_sql(sqlcmd_table_names, connection)\n",
    "cursor = connection.cursor()\n",
    "#sql alchemy format: dialect+driver://username:password@host:port/database\n",
    "                  # 'postgresql://scott:tiger@localhost:5432/mydatabase'\n",
    "sqlalchemy_eng = \"postgresql://\"+user_name+\":\"+user_password+\"@\"+host_address+'/'+name_of_database\n",
    "engine = create_engine(sqlalchemy_eng)\n",
    "print(all_table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping CSV to postgresql\n",
    "No column names changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to read and dump csv to sql server\n",
    "def postgresql_engine_generator_mvesc():\n",
    "    \"\"\" generate a string to create postgres engine\n",
    "    Note: you can only run it on the mvesc-AWS-server\n",
    "    :param None: None\n",
    "    :return str sql_eng_str: string for function create_engine() in sqlalchemy\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    pass_file = \"/mnt/data/mvesc/pgpass\" # username, db information\n",
    "    with open(pass_file, 'r') as f:\n",
    "        passinfo = f.read()\n",
    "    passinfo = passinfo.strip().split(':')\n",
    "    host_address = passinfo[0]\n",
    "    port = passinfo[1]\n",
    "    user_name = passinfo[2]\n",
    "    name_of_database = passinfo[3]\n",
    "    user_password = passinfo[4]\n",
    "    sql_eng_str = \"postgresql://\"+user_name+\":\"+user_password+\"@\"+host_address+'/'+name_of_database\n",
    "    return sql_eng_str\n",
    "\n",
    "def read_csv_noheader(filepath):\n",
    "    \"\"\" read a csv file with no header\n",
    "    \n",
    "    :param str filepath: file path name\n",
    "    :return pandas.DataFrame with header 'col1', 'col2', ...\n",
    "    :rtype pandas.DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, header=None, low_memory=False) # read csv data with no header\n",
    "    colnames = {i:'col'+str(i) for i in df.columns} # column names of col0, col1, col2, ... \n",
    "    df = df.rename(columns=colnames)\n",
    "    return df\n",
    "\n",
    "def csv2postgres_file(filepath, header=False, nrows=-1, if_exists='fail', schema=\"raw\"):\n",
    "    \"\"\" upload csv file to postgres database\n",
    "    \n",
    "    :param str filepath: file path name\n",
    "    :param bool header: True means there is header;\n",
    "    :return str table_name: table name of the sql table\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    # read the data frame \n",
    "    if header:\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "    else:\n",
    "        df = read_csv_noheader(filepath) # header: col0, col1, col2\n",
    "    \n",
    "    # create a postgresql engine to wirte to postgres\n",
    "    from sqlalchemy import create_engine\n",
    "    import json\n",
    "    sqlalchemy_eng = postgresql_engine_generator_mvesc() # a string with info to create engine\n",
    "    engine = create_engine(sqlalchemy_eng)\n",
    "    \n",
    "    sqlcmd_table_names = \"SELECT table_name FROM information_schema.tables WHERE table_schema = '%s'\" % schema\n",
    "    connection = pg.connect(host=host_address, database=name_of_database, user=user_name, password=user_password)\n",
    "    all_table_names = list(pd.read_sql(sqlcmd_table_names, connection).table_name)\n",
    "    \n",
    "    #write the data frame to postgres\n",
    "    file_name = filepath.split('/')[-1]\n",
    "    file_table_names = json.load(open('file_to_table_name.json','r'))\n",
    "    #table_name = filepath.split('/')[-1].split('.')[0] # table name is filename without .txt or other extension\n",
    "    table_name = file_table_names[file_name]\n",
    "    \n",
    "    # check existing tables in sql first to avoid errors\n",
    "    if table_name not in all_table_names or if_exists=='replace':\n",
    "        if nrows==-1:\n",
    "            df.to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "        else:\n",
    "            df.iloc[:nrows, :].to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "    else:\n",
    "        print(\"Table already in mvesc: \", table_name)\n",
    "    return table_name\n",
    "\n",
    "\n",
    "def csv2postgres_dir(directory, header=False, nrows=-1, if_exists='fail', schema='raw'):\n",
    "    \"\"\" upload a directory of csv files to postgres database\n",
    "    \n",
    "    :param str filepath: file path name\n",
    "    :param bool header: True means there is header;\n",
    "    :return str table_name: table name of the sql table\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    data_dir = directory\n",
    "    data_file_names = os.listdir(data_dir)\n",
    "    # full path name of filenames\n",
    "    fnames = [data_dir + fn for fn in data_file_names]\n",
    "    table_names = []\n",
    "    for filepath in fnames:\n",
    "        print(\"working on \", filepath)\n",
    "        tab_name = csv2postgres_file(filepath, header=header, nrows=nrows, if_exists=if_exists, schema=schema)\n",
    "        table_names.append(tab_name)\n",
    "    return table_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  /mnt/data/mvesc/PartnerData/AbsenceDaysDetail/MATVWMAbsences1415.txt\n",
      "Table already in mvesc:  MATVWMAbsences1415\n",
      "working on  /mnt/data/mvesc/PartnerData/AbsenceDaysDetail/CCFRRWRVabsence09_16.txt\n",
      "Table already in mvesc:  CCFRRWRVabsence09_16\n",
      "working on  /mnt/data/mvesc/PartnerData/AbsenceDaysDetail/MATVWMAbsences1516.txt\n",
      "Table already in mvesc:  MATVWMAbsences1516\n",
      "['MATVWMAbsences1415', 'CCFRRWRVabsence09_16', 'MATVWMAbsences1516']\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/Maysvillegrades2006_16.txt\n",
      "Table already in mvesc:  Maysvillegrades2006_16\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/CoshoctonGrades2006_16.txt\n",
      "Table already in mvesc:  CoshoctonGrades2006_16\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/TriValleyGrades2006_16.txt\n",
      "Table already in mvesc:  TriValleyGrades2006_16\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/Ridgewoodgrades2007_2016.txt\n",
      "Table already in mvesc:  Ridgewoodgrades2007_2016\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/WestMuskingumgrades2006_16.txt\n",
      "Table already in mvesc:  WestMuskingumgrades2006_16\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/RiverViewgrades2006_16.txt\n",
      "Table already in mvesc:  RiverViewgrades2006_16\n",
      "working on  /mnt/data/mvesc/PartnerData/DistrictGrades2006_16/Franklingrades2006_16.txt\n",
      "Table already in mvesc:  Franklingrades2006_16\n",
      "['Maysvillegrades2006_16', 'CoshoctonGrades2006_16', 'TriValleyGrades2006_16', 'Ridgewoodgrades2007_2016', 'WestMuskingumgrades2006_16', 'RiverViewgrades2006_16', 'Franklingrades2006_16']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/data/mvesc/PartnerData/AbsenceDaysDetail/'\n",
    "abs_table_names = csv2postgres_dir(data_dir, header=False, nrows=-1, if_exists='fail', schema='raw')  \n",
    "print(abs_table_names)\n",
    "\n",
    "data_dir = '/mnt/data/mvesc/PartnerData/DistrictGrades2006_16/'\n",
    "grade_talbe_names = csv2postgres_dir(data_dir, header=True, nrows=-1, if_exists='fail', schema='raw')\n",
    "print(grade_talbe_names)\n",
    "\n",
    "### dump csv file by file\n",
    "# data_dir = '/mnt/data/mvesc/PartnerData/AbsenceDaysDetail/' # top level data directory\n",
    "# data_file_names = os.listdir(data_dir)\n",
    "# # full path name of filenames\n",
    "# fnames = [data_dir + fn for fn in data_file_names]\n",
    "# table_names = []\n",
    "# for filepath in fnames:\n",
    "#     print(\"working on \", filepath)\n",
    "#     tab_name = csv2postgres_file(filepath, header=False, nrows=-1, if_exists='replace')\n",
    "#     table_names.append(tab_name)\n",
    "    \n",
    "# table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAAOGT_0616.txt upload \n",
    "p.s. Ric said to replace the old OAAOGT table, but they are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already in mvesc:  OAAOGT_0616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OAAOGT_0616'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/mnt/data/mvesc/PartnerData/OAAOGT_0616.txt'\n",
    "csv2postgres_file(filepath, header=True, nrows=-1, if_exists='fail', schema='raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change column names\n",
    "##### 1. Only for tables with column names of col0, col1, col2\n",
    "##### 2. No function is written because we need to rename the columns names manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old table:\n",
      "    StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
      "0           2540  2016-01-20 00:00:00            1.0           A   \n",
      "1           2540  2016-02-02 00:00:00            1.0           A   \n",
      "2           2540  2015-12-03 00:00:00            1.0           A   \n",
      "3           2540  2016-02-18 00:00:00            1.0           A   \n",
      "4           2540  2016-02-23 00:00:00            1.0           A   \n",
      "\n",
      "       AbsenceDesc School  \n",
      "0  Excused Absence   RWAR  \n",
      "1  Excused Absence   RWAR  \n",
      "2  Excused Absence   RWAR  \n",
      "3  Excused Absence   RWAR  \n",
      "4  Excused Absence   RWAR  \n",
      "\n",
      "Name already changed!\n",
      "\n",
      "new table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentLookup</th>\n",
       "      <th>Date</th>\n",
       "      <th>AbsenceLength</th>\n",
       "      <th>AbsenceCode</th>\n",
       "      <th>AbsenceDesc</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2540</td>\n",
       "      <td>2016-01-20 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Excused Absence</td>\n",
       "      <td>RWAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2540</td>\n",
       "      <td>2016-02-02 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Excused Absence</td>\n",
       "      <td>RWAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2540</td>\n",
       "      <td>2015-12-03 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Excused Absence</td>\n",
       "      <td>RWAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2540</td>\n",
       "      <td>2016-02-18 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Excused Absence</td>\n",
       "      <td>RWAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2540</td>\n",
       "      <td>2016-02-23 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Excused Absence</td>\n",
       "      <td>RWAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
       "0           2540  2016-01-20 00:00:00            1.0           A   \n",
       "1           2540  2016-02-02 00:00:00            1.0           A   \n",
       "2           2540  2015-12-03 00:00:00            1.0           A   \n",
       "3           2540  2016-02-18 00:00:00            1.0           A   \n",
       "4           2540  2016-02-23 00:00:00            1.0           A   \n",
       "\n",
       "       AbsenceDesc School  \n",
       "0  Excused Absence   RWAR  \n",
       "1  Excused Absence   RWAR  \n",
       "2  Excused Absence   RWAR  \n",
       "3  Excused Absence   RWAR  \n",
       "4  Excused Absence   RWAR  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = 'raw'\n",
    "all_table_names = pd.read_sql(sqlcmd_table_names, connection)\n",
    "cursor = connection.cursor()\n",
    "tab_names = ['MATVWMAbsences1415', 'CCFRRWRVabsence09_16', 'MATVWMAbsences1516']\n",
    "\n",
    "def read_sql_topN(table, conn, N=10, schema='raw'):\n",
    "    sqlcmd = \"SELECT * FROM %s.\\\"%s\\\" LIMIT %d;\" % (schema, table, N);\n",
    "    df = pd.read_sql(sqlcmd, conn)\n",
    "    return df\n",
    "\n",
    "# Change column names of a specific table\n",
    "tab_name = tab_names[1] # table name\n",
    "df = read_sql_topN(tab_name, connection, 5, schema=schema) # read the top N line to see the columns\n",
    "oldcol = list(df.columns) # list of column names\n",
    "newcol = ['StudentLookup', 'Date', 'AbsenceLength', 'AbsenceCode', 'AbsenceDesc', 'School'] # new names after checing df\n",
    "sqlcmds = ['alter table %s.\\\"%s\\\" rename column \\\"%s\\\" to \\\"%s\\\";' % (schema, tab_name, oldcol[i], newcol[i]) for i in range(len(oldcol))]\n",
    "#print(sqlcmds)\n",
    "print(\"old table:\\n\", df)\n",
    "if set(newcol) != set(oldcol):\n",
    "    for sql in sqlcmds:\n",
    "        cursor.execute(sql)\n",
    "else:\n",
    "    print(\"\\nName already changed!\\n\")\n",
    "connection.commit() # commit the column name change\n",
    "print(\"new table:\")\n",
    "read_sql_topN(tab_name, connection, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old table:\n",
      "    StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
      "0           5672  2014-09-02 00:00:00            0.0           R   \n",
      "1           5672  2014-11-04 00:00:00            0.5           A   \n",
      "2           5672  2014-11-05 00:00:00            1.0           A   \n",
      "3           5672  2014-12-17 00:00:00            0.5           A   \n",
      "4           5672  2015-02-23 00:00:00            1.0           A   \n",
      "\n",
      "       AbsenceDesc School   District  \n",
      "0  UNEXCUSED TARDY   MAES  Maysville  \n",
      "1  EXCUSED ABSENCE   MAES  Maysville  \n",
      "2  EXCUSED ABSENCE   MAES  Maysville  \n",
      "3  EXCUSED ABSENCE   MAES  Maysville  \n",
      "4  EXCUSED ABSENCE   MAES  Maysville  \n",
      "\n",
      "Name already changed!\n",
      "\n",
      "new table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentLookup</th>\n",
       "      <th>Date</th>\n",
       "      <th>AbsenceLength</th>\n",
       "      <th>AbsenceCode</th>\n",
       "      <th>AbsenceDesc</th>\n",
       "      <th>School</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5672</td>\n",
       "      <td>2014-09-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>UNEXCUSED TARDY</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5672</td>\n",
       "      <td>2014-11-04 00:00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5672</td>\n",
       "      <td>2014-11-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5672</td>\n",
       "      <td>2014-12-17 00:00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5672</td>\n",
       "      <td>2015-02-23 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
       "0           5672  2014-09-02 00:00:00            0.0           R   \n",
       "1           5672  2014-11-04 00:00:00            0.5           A   \n",
       "2           5672  2014-11-05 00:00:00            1.0           A   \n",
       "3           5672  2014-12-17 00:00:00            0.5           A   \n",
       "4           5672  2015-02-23 00:00:00            1.0           A   \n",
       "\n",
       "       AbsenceDesc School   District  \n",
       "0  UNEXCUSED TARDY   MAES  Maysville  \n",
       "1  EXCUSED ABSENCE   MAES  Maysville  \n",
       "2  EXCUSED ABSENCE   MAES  Maysville  \n",
       "3  EXCUSED ABSENCE   MAES  Maysville  \n",
       "4  EXCUSED ABSENCE   MAES  Maysville  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change column names of a specific table\n",
    "tab_name = tab_names[0]\n",
    "df = read_sql_topN(tab_name, connection, 5, schema='raw')\n",
    "oldcol = list(df.columns)\n",
    "newcol = ['StudentLookup', 'Date', 'AbsenceLength', 'AbsenceCode', 'AbsenceDesc', 'School', 'District']\n",
    "sqlcmds = ['alter table %s.\\\"%s\\\" rename column \\\"%s\\\" to \\\"%s\\\";' % (schema, tab_name, oldcol[i], newcol[i]) for i in range(len(oldcol))]\n",
    "#print(sqlcmds)\n",
    "print(\"old table:\\n\", df)\n",
    "if set(newcol) != set(oldcol):\n",
    "    for sql in sqlcmds:\n",
    "        cursor.execute(sql)\n",
    "else:\n",
    "    print(\"\\nName already changed!\\n\")\n",
    "connection.commit()\n",
    "print(\"new table:\")\n",
    "read_sql_topN(tab_name, connection, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old table:\n",
      "    StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
      "0           9885  2015-11-06 00:00:00            1.0           A   \n",
      "1           9885  2015-11-10 00:00:00            1.0           A   \n",
      "2           9885  2015-11-17 00:00:00            1.0           A   \n",
      "3           9885  2016-02-05 00:00:00            1.0           A   \n",
      "4           9885  2016-02-29 00:00:00            0.5           A   \n",
      "\n",
      "       AbsenceDesc School   District  \n",
      "0  EXCUSED ABSENCE   MAES  Maysville  \n",
      "1  EXCUSED ABSENCE   MAES  Maysville  \n",
      "2  EXCUSED ABSENCE   MAES  Maysville  \n",
      "3  EXCUSED ABSENCE   MAES  Maysville  \n",
      "4  EXCUSED ABSENCE   MAES  Maysville  \n",
      "\n",
      "Name already changed!\n",
      "\n",
      "new table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentLookup</th>\n",
       "      <th>Date</th>\n",
       "      <th>AbsenceLength</th>\n",
       "      <th>AbsenceCode</th>\n",
       "      <th>AbsenceDesc</th>\n",
       "      <th>School</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9885</td>\n",
       "      <td>2015-11-06 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9885</td>\n",
       "      <td>2015-11-10 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9885</td>\n",
       "      <td>2015-11-17 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9885</td>\n",
       "      <td>2016-02-05 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9885</td>\n",
       "      <td>2016-02-29 00:00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCUSED ABSENCE</td>\n",
       "      <td>MAES</td>\n",
       "      <td>Maysville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentLookup                 Date  AbsenceLength AbsenceCode  \\\n",
       "0           9885  2015-11-06 00:00:00            1.0           A   \n",
       "1           9885  2015-11-10 00:00:00            1.0           A   \n",
       "2           9885  2015-11-17 00:00:00            1.0           A   \n",
       "3           9885  2016-02-05 00:00:00            1.0           A   \n",
       "4           9885  2016-02-29 00:00:00            0.5           A   \n",
       "\n",
       "       AbsenceDesc School   District  \n",
       "0  EXCUSED ABSENCE   MAES  Maysville  \n",
       "1  EXCUSED ABSENCE   MAES  Maysville  \n",
       "2  EXCUSED ABSENCE   MAES  Maysville  \n",
       "3  EXCUSED ABSENCE   MAES  Maysville  \n",
       "4  EXCUSED ABSENCE   MAES  Maysville  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change column names of a specific table\n",
    "tab_name = tab_names[2]\n",
    "df = read_sql_topN(tab_name, connection, 5,schema=schema)\n",
    "oldcol = list(df.columns)\n",
    "newcol = ['StudentLookup', 'Date', 'AbsenceLength', 'AbsenceCode', 'AbsenceDesc', 'School', 'District']\n",
    "sqlcmds = ['alter table %s.\\\"%s\\\" rename column \\\"%s\\\" to \\\"%s\\\";' % (schema, tab_name, oldcol[i], newcol[i]) for i in range(len(oldcol))]\n",
    "#print(sqlcmds)\n",
    "print(\"old table:\\n\", df)\n",
    "if set(newcol) != set(oldcol):\n",
    "    for sql in sqlcmds:\n",
    "        cursor.execute(sql)\n",
    "else:\n",
    "    print(\"\\nName already changed!\\n\")\n",
    "connection.commit()\n",
    "print(\"new table:\")\n",
    "read_sql_topN(tab_name, connection, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel files processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/data/mvesc/PartnerData/MVESC_DistrictRatings.xlsx',\n",
       " '/mnt/data/mvesc/PartnerData/DistrictSchoolIDs.xls',\n",
       " '/mnt/data/mvesc/PartnerData/MVESC_Mobility.xlsx']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/mnt/data/mvesc/PartnerData/' # top level data directory\n",
    "filepaths = filter(lambda x: ('.xlsx' in x) or ('.xls' in x), os.listdir(data_dir))\n",
    "filepaths=[data_dir+f for f in filepaths]\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mobility file: MVESC_Mobility.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table uploaded to mvesc:  Mobility_2010_2015\n"
     ]
    }
   ],
   "source": [
    "def combine_colnames(col1, col2):\n",
    "    \"\"\"combine the colnames from 2 rows: !! Only works in this specific case\n",
    "    :param str col1: first column-name\n",
    "    :param str col2: second column-name\n",
    "    :return str new_col: combined new column name\n",
    "    :return str\n",
    "    \"\"\"\n",
    "    new_col = \"pct_same_\"\n",
    "    schoolyear = col2[2:4] + col2[7:9]\n",
    "    if \"district\" in col1.lower():\n",
    "        dist_school = \"district_\"\n",
    "    else:\n",
    "        dist_school = \"school_\"\n",
    "    \n",
    "    if \"less\" in col1.lower():\n",
    "        more_less = \"less_\"\n",
    "    else:\n",
    "        more_less = \"more_\"\n",
    "    new_col = new_col+dist_school+more_less+'a_year_'+schoolyear  \n",
    "    return new_col\n",
    "\n",
    "\n",
    "\n",
    "def df2postgres(df, table_name, nrows=-1, if_exists='fail', schema='raw'):\n",
    "    \"\"\" dump dataframe object to postgres database\n",
    "    \n",
    "    :param pandas.DataFrame df: dataframe\n",
    "    :param int nrows: number of rows to write to table;\n",
    "    :return str table_name: table name of the sql table\n",
    "    :rtype str\n",
    "    \"\"\"\n",
    "    # create a postgresql engine to wirte to postgres\n",
    "    from sqlalchemy import create_engine\n",
    "    sqlalchemy_eng = postgresql_engine_generator_mvesc()\n",
    "    engine = create_engine(sqlalchemy_eng)\n",
    "    \n",
    "    #write the data frame to postgres\n",
    "    if nrows==-1:\n",
    "        df.to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "    else:\n",
    "        df.iloc[:nrows, :].to_sql(table_name, engine, schema=schema, index=False, if_exists=if_exists)\n",
    "    return table_name\n",
    "\n",
    "schema = 'raw'\n",
    "df_Mobility = pd.read_excel(filepaths[1], skiprows=1)\n",
    "df_Mobility2 = pd.read_excel(filepaths[1])\n",
    "first3cols = ['district_code', 'district', 'metrics'] \n",
    "col1=df_Mobility.columns[3:] # only columns which need to be combined\n",
    "col2=df_Mobility2.columns[3:]\n",
    "\n",
    "new_colnames = first3cols + [combine_colnames(col1[i], col2[i]) for i in range(len(col1)) ]\n",
    "new_colnames_dict = {df_Mobility.columns[i]:new_colnames[i] for i in range(len(new_colnames))}\n",
    "df_Mobility=df_Mobility.rename(columns=new_colnames_dict)\n",
    "df_Mobility=df_Mobility.drop('metrics', axis=1)\n",
    "table_name = df2postgres(df_Mobility, \"Mobility_2010_2015\", nrows=-1, if_exists='replace', schema=schema)\n",
    "print(\"table uploaded to mvesc: \", table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DistrictRatings: MVESC_DistrictRatings.xlsx\n",
    "Small tables;\n",
    "You may replace all tables by setting `if_exists='replace'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long column names:\n",
      " ['social_studies_11th_grade_ogt_2014_15_pct_at_or_above_proficient', 'social_studies_11th_grade_ogt_2013_14_pct_at_or_above_proficient', 'social_studies_11th_grade_ogt_2012_13_pct_at_or_above_proficient']\n",
      "table uploaded to mvesc:  DistrictRating1415 \n",
      "\n",
      "Long column names:\n",
      " []\n",
      "table uploaded to mvesc:  DistrictRating1314 \n",
      "\n",
      "Long column names:\n",
      " []\n",
      "table uploaded to mvesc:  DistrictRating1213 \n",
      "\n",
      "Long column names:\n",
      " []\n",
      "table uploaded to mvesc:  DistrictRating1112 \n",
      "\n",
      "Long column names:\n",
      " []\n",
      "table uploaded to mvesc:  DistrictRating1011 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "excel_name = \"DistrictRating\"\n",
    "schema='raw'\n",
    "xl = pd.ExcelFile(filepaths[0])\n",
    "for sheet_name in xl.sheet_names:\n",
    "    tab_name = excel_name + sheet_name[-4:]\n",
    "    df = xl.parse(sheet_name)\n",
    "    names = list(df.columns)\n",
    "    newnames = ['_'.join(re.split('[, _\\-#\\(\\)]+', name)).replace(\"%\", 'pct').lower() for name in names ]\n",
    "    def check_name_long(names, length=63):\n",
    "        long_names = filter(lambda x: len(x)>length, names)\n",
    "        return list(long_names)\n",
    "    print(\"Long column names:\\n\", check_name_long(newnames))\n",
    "    newnames = [name[:63] for name in newnames]\n",
    "    newnames_dict={names[i]:newnames[i] for i in range(len(names))}\n",
    "    df = df.rename(columns=newnames_dict)\n",
    "    table_name = df2postgres(df, tab_name, nrows=-1, if_exists='replace', schema=schema)\n",
    "    print(\"table uploaded to mvesc: \", table_name, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
